{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkkU_68T1yAa"
      },
      "source": [
        "# Announcement\n",
        "\n",
        "As with wrangling, I switched this notebook over to use the Titanic dataset for consistency. The video uses the Pima dataset.\n",
        "\n",
        "The video ends rather abuptly. I hope the notebook is clear and what you need to do.\n",
        "\n",
        "One thing I introduce is Upsampling. I promised I would do this way back in Chapter 2. I do not expect you to use it but thought it was worth demonstrating.\n",
        "\n",
        "I also provide an optional make-up problem for you to get points back.\n",
        "\n",
        "At the end of the notebook, I explore several ways of combining the four models. The most sophisticated is something called stacking. In essence we build a meta-model that we train with the output of the existing models. So this meta-model attempts to learn how to interpret the existing models' output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDiYMkiYgRS"
      },
      "source": [
        "<center>\n",
        "<h1>Training and Tuning</h1>\n",
        "</center>\n",
        "\n",
        "<hr>\n",
        "\n",
        "Once you are done here, you are ready to start playing with your server. Cool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_cK-F4Az4XG"
      },
      "source": [
        "# How long does it take?\n",
        "\n",
        "I think tuning time is the biggest issue for you now.\n",
        "Using Pima data (training set = 614 rows) and what I consider an ok set of parameters to tune, this notebook takes me roughly 3 hours.\n",
        "\n",
        "Take away is that as you tune each model, be aware that you might need to leave it running while you do something else.\n",
        "\n",
        "The good news is that each model-tuning step is independent. Once you tune model X and save to GitHub, you are done with model X and can move on to model Y. The bad news is that if your dataset is larger, e.g., 5K rows, you can expect an increase in my times.\n",
        "\n",
        "The further bad news is that there is not an easy way to get a progress bar with HalvingSearch. So if you wait 30 minutes, you don't know if you are almost done or will take another 4 hours.\n",
        "\n",
        "Here are some strategies to consider:\n",
        "\n",
        "1. Use incremental tuning. Tune some subset of params. Get best values and fix them. Then take on new subset using fixed values from past. You can use this strategy with both halving search and keras tuner.\n",
        "\n",
        "2. I have factor=3. You could increase it to reduce wait time. But my experimentation tells me you may not gain that much.\n",
        "\n",
        "3. For keras_tuner, it's easier. You can play around with `max_trials`. Set it small to start, e.g., 5. You can count on linearity here. If 5 trials takes 10 minutes, 50 likely to take 100 minutes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZiquu_S3vZG"
      },
      "source": [
        "## Set-up\n",
        "\n",
        "First bring in your library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ6MOQmuVewi",
        "outputId": "4289e391-1db7-4aca-fbc9-aa1513176a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'library.py': No such file or directory\n",
            "--2025-06-06 04:52:02--  https://raw.githubusercontent.com/marvnc/cs523/main/library.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49866 (49K) [text/plain]\n",
            "Saving to: ‘library.py’\n",
            "\n",
            "library.py          100%[===================>]  48.70K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-06-06 04:52:02 (6.41 MB/s) - ‘library.py’ saved [49866/49866]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "github_name = 'marvnc'\n",
        "repo_name = 'cs523'\n",
        "source_file = 'library.py'\n",
        "url = f'https://raw.githubusercontent.com/{github_name}/{repo_name}/main/{source_file}'\n",
        "# !rm $source_file\n",
        "# !wget $url\n",
        "# %run -i $source_file\n",
        "from library import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXWcOKJN4y82"
      },
      "source": [
        "## You need to change this url to point to your own dataset\n",
        "\n",
        "And good idea to rename variables using \"titanic\" to something closer to your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZVTLBYampYbo",
        "outputId": "abc0776f-62a8-4bbc-ec1a-c960a345d33d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"approvals_trimmed\",\n  \"rows\": 690,\n  \"fields\": [\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.860244756156707,\n        \"min\": 13.75,\n        \"max\": 80.25,\n        \"num_unique_values\": 350,\n        \"samples\": [\n          41.75,\n          35.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Debt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.978163248528541,\n        \"min\": 0.0,\n        \"max\": 28.0,\n        \"num_unique_values\": 215,\n        \"samples\": [\n          10.415,\n          3.29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YearsEmployed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3465133592781333,\n        \"min\": 0.0,\n        \"max\": 28.5,\n        \"num_unique_values\": 132,\n        \"samples\": [\n          13.5,\n          2.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PriorDefault\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Employed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CreditScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 67,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          23,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DriversLicense\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5210,\n        \"min\": 0,\n        \"max\": 100000,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          100,\n          314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Approved\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "approvals_trimmed"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9c7b9679-330c-4890-a0f2-e6ff960c5db8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Debt</th>\n",
              "      <th>YearsEmployed</th>\n",
              "      <th>PriorDefault</th>\n",
              "      <th>Employed</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>DriversLicense</th>\n",
              "      <th>Income</th>\n",
              "      <th>Approved</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>560</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>824</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>3.75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>1.71</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c7b9679-330c-4890-a0f2-e6ff960c5db8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c7b9679-330c-4890-a0f2-e6ff960c5db8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c7b9679-330c-4890-a0f2-e6ff960c5db8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c7326e29-bf5c-4b09-86ec-57bab9f76950\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7326e29-bf5c-4b09-86ec-57bab9f76950')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c7326e29-bf5c-4b09-86ec-57bab9f76950 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Gender    Age   Debt  YearsEmployed  PriorDefault  Employed  CreditScore  \\\n",
              "0       1  30.83  0.000           1.25             1         1            1   \n",
              "1       0  58.67  4.460           3.04             1         1            6   \n",
              "2       0  24.50  0.500           1.50             1         0            0   \n",
              "3       1  27.83  1.540           3.75             1         1            5   \n",
              "4       1  20.17  5.625           1.71             1         0            0   \n",
              "\n",
              "   DriversLicense  Income  Approved  \n",
              "0               0       0         1  \n",
              "1               0     560         1  \n",
              "2               0     824         1  \n",
              "3               1       3         1  \n",
              "4               0       0         1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# url = 'https://raw.githubusercontent.com/fickas/asynch_models/main/datasets/titanic_trimmed.csv'  #trimmed version\n",
        "url = 'https://raw.githubusercontent.com/MarvNC/cs523/refs/heads/main/s25_final_cc_approvals_reduced.csv'\n",
        "\n",
        "approvals_trimmed = pd.read_csv(url)\n",
        "approvals_trimmed.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvZy9mwFVrGf",
        "outputId": "39a8b77c-54f5-4590-c519-65d06499b413"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(approvals_trimmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIHq9aUHNcxo"
      },
      "source": [
        "# Break out into features and labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nH0g0IVGauIa"
      },
      "outputs": [],
      "source": [
        "target_col = 'Approved'\n",
        "\n",
        "approvals_features = approvals_trimmed.drop(columns=target_col)\n",
        "labels = approvals_trimmed[target_col].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdQPZk3nU9cY",
        "outputId": "44b6d5c3-0900-4a89-caf6-4e6366f9b86f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4449275362318841"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels.count(1)/len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kXjRgNa2gnR"
      },
      "source": [
        "## Load pipeline from Wrangling notebook\n",
        "\n",
        "You will be doing this exact same thing in the server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kauuG1GQ7au-",
        "outputId": "f04ef87f-3880-41ef-d1ea-4a52819bbb73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 's25_final_fully_fitted_pipeline.pkl': No such file or directory\n",
            "--2025-06-06 04:56:16--  https://github.com/MarvNC/cs523/raw/refs/heads/main/s25_final_fully_fitted_pipeline.pkl\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MarvNC/cs523/refs/heads/main/s25_final_fully_fitted_pipeline.pkl [following]\n",
            "--2025-06-06 04:56:17--  https://raw.githubusercontent.com/MarvNC/cs523/refs/heads/main/s25_final_fully_fitted_pipeline.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1327 (1.3K) [application/octet-stream]\n",
            "Saving to: ‘s25_final_fully_fitted_pipeline.pkl’\n",
            "\n",
            "s25_final_fully_fit 100%[===================>]   1.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-06-06 04:56:17 (56.5 MB/s) - ‘s25_final_fully_fitted_pipeline.pkl’ saved [1327/1327]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# model_path = 'MarvNC/cs523/s25_'\n",
        "full_path = f'https://github.com/MarvNC/cs523/raw/refs/heads/main/s25_final_fully_fitted_pipeline.pkl'\n",
        "!rm 's25_final_fully_fitted_pipeline.pkl'\n",
        "!wget $full_path\n",
        "titanic_transformer = joblib.load(\"s25_final_fully_fitted_pipeline.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MElaQCi6qhnZ"
      },
      "source": [
        "# Step I. Break into numpy datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "g5XN6ImKT1qn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# rs = 74 #what you computed in wrangling notebook\n",
        "rs = approvals_variance_based_split\n",
        "# label_column = 'Survived'  #change to name of your label column\n",
        "label_column = target_col\n",
        "\n",
        "x_train,  x_test, y_train,  y_test = dataset_setup(approvals_trimmed, label_column, titanic_transformer, rs=rs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML3-iCwB0aHy",
        "outputId": "2d8cfbc8-8c58-4c7f-f3d5-1bd014ff6456"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "552"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7gaAYxB0ElV"
      },
      "source": [
        "# II. Upsampling\n",
        "\n",
        "In Chapter 2 I removed duplicates, giving us unique rows. However, it did shrink the table down to roughly 1000. I noted I would show you a way to build the table back up. I am going to use a popular method called SMOTE (Synthetic Minority Over-sampling Technique). I'll show you how to use it even though I do not expect you will need it here. But could come in handy later in your career.\n",
        "\n",
        "Note that I am only applying it to the training data. I'd like to keep the test data pure: augment training, let test data stand.\n",
        "\n",
        "You can find plenty of tutorials on SMOTE. Briefly, it generates new rows by\n",
        "using existing rows as starting places and then interpolating values. So it\n",
        "does not duplicate rows but tries to give you similar rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC-dGcVF0zz0",
        "outputId": "5287c0a4-b9f6-4f85-b92b-d2924696275c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New class distribution:\n",
            "Class 0: 1108 (55.43%)\n",
            "Class 1: 891 (44.57%)\n",
            "Total samples: 1999\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Calculate target numbers for 3000 total samples\n",
        "target_total = 2000\n",
        "pos_count = np.sum(y_train == 1)/len(y_train)\n",
        "neg_count = np.sum(y_train == 0)/len(y_train)\n",
        "target_0 = int(neg_count * target_total)  # 1950 samples\n",
        "target_1 = int(pos_count * target_total)  # 1050 samples\n",
        "\n",
        "# Create SMOTE instance with specified sampling strategy\n",
        "smote = SMOTE(sampling_strategy={0: target_0, 1: target_1}, random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)  #requires transformed data - cannot handle categorical columns\n",
        "\n",
        "# Verify the new distribution\n",
        "print(\"New class distribution:\")\n",
        "print(f\"Class 0: {sum(y_resampled == 0)} ({sum(y_resampled == 0)/len(y_resampled):.2%})\")\n",
        "print(f\"Class 1: {sum(y_resampled == 1)} ({sum(y_resampled == 1)/len(y_resampled):.2%})\")\n",
        "print(f\"Total samples: {len(y_resampled)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wZTVewpE4qBi"
      },
      "outputs": [],
      "source": [
        "#Uncomment if you want to use upsampled data\n",
        "\n",
        "x_train= x_resampled\n",
        "y_train = y_resampled\n",
        "\n",
        "# Prof said to upsample to 2k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Afm0d0Cp4XN"
      },
      "source": [
        "# III. Setup Lime\n",
        "\n",
        "Reminder: Lime will help us explain to the user why we come up with the predictions we do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3S-Te5VSvMgV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6tcUkahpax_Y"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "from lime import lime_tabular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zZk9bCU5OqU",
        "outputId": "0537bfd8-8383-4049-e324-e80f96e7e603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Gender', 'Age', 'Debt', 'YearsEmployed', 'PriorDefault', 'Employed', 'CreditScore', 'DriversLicense', 'Income']\n"
          ]
        }
      ],
      "source": [
        "feature_names = approvals_features.columns.to_list()\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q68oGAkzHwFp"
      },
      "source": [
        "### Set up the explainer before using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7W0wZRRJWP7t"
      },
      "outputs": [],
      "source": [
        "explainer = lime.lime_tabular.LimeTabularExplainer(x_train,\n",
        "                    feature_names=feature_names,\n",
        "                    training_labels=y_train,\n",
        "                    class_names=[0,1], #label values\n",
        "                    verbose=True,\n",
        "                    mode='classification')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGVwZoX6rBMr"
      },
      "source": [
        "# IV. Write out to file\n",
        "\n",
        "And move to GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVkCBYW69d0_",
        "outputId": "55a5bfa6-875a-47ad-ba7d-430d1b1cfa4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (0.3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install dill\n",
        "import dill as pickle\n",
        "with open('lime_explainer.pkl', 'wb') as file:\n",
        "    pickle.dump(explainer, file)\n",
        "\n",
        "#read it back in just as a test\n",
        "with open('lime_explainer.pkl', 'rb') as file:   #this will be in your webserver\n",
        "    explainer2 = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYoYsSCO9wso"
      },
      "source": [
        "# Minimal help from me with remainder of notebook\n",
        "\n",
        "I can remind you of the steps you need for each model's tuning:\n",
        "\n",
        "1. If using halving search, set up grid. If using Optuna, then set up model builder with hp code. With Optuna, will also need to define a validation set.\n",
        "\n",
        "2. Get the best model found by tuning.\n",
        "\n",
        "3. Run it on test set.\n",
        "\n",
        "4. Produce threshold table.\n",
        "\n",
        "5. Save both best model and threshold table out to GitHub so can load them back in with server.\n",
        "\n",
        "I would avoid Run All here. Each notebook can be tuned separately, really in any order. But once you finish steps above for one model, you don't want to waste time and repeat them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGD6ssbwd-DF"
      },
      "source": [
        "# V. KNN tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VkYLeNXHz9Gx"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxOsVk-yrslG"
      },
      "source": [
        "### Follow the steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4qOZb8O_bfR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNjvW2ZVhN6A"
      },
      "source": [
        "# VI. Logistic Regression tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX3iQcLFhiHB"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUx64rqs_skH"
      },
      "source": [
        "### Follow the steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhIvRXj5_skI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxe6XuYciUY-"
      },
      "source": [
        "# VII. LGB tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wwjo5E4_436"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeqVdrL4_5hW"
      },
      "source": [
        "### Follow the steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cjrLNnB_5hW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZFyuP1TjHih"
      },
      "source": [
        "# VIII. ANN tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo-LXsWhV-YN"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner -q\n",
        "import keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpnZFnTOv2Mx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UH8coL34r2q"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(1234)  #need this for replication\n",
        "tf.config.experimental.enable_op_determinism()  #ditto - https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism\n",
        "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "tf.config.threading.set_intra_op_parallelism_threads(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7GwTsJOTrQq"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "def string_to_seed(string):\n",
        "    # Create a hash of the string using SHA-256\n",
        "    hash_object = hashlib.sha256(string.encode())\n",
        "    # Convert first 8 bytes of hash to integer\n",
        "    hash_int = int.from_bytes(hash_object.digest()[:8], 'big')\n",
        "    return hash_int % (2**32 - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw8Xrev5vehN"
      },
      "outputs": [],
      "source": [
        "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    min_delta=0,\n",
        "    patience=10,\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE4_DJ-4Ab71"
      },
      "source": [
        "### Follow the steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2k5AoJnAb72"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXGHYrCpjLXl"
      },
      "source": [
        "# You should eventually have these files on GitHub\n",
        "\n",
        "* LIME explainer\n",
        "* tuned KNN model and associated threshold table\n",
        "* tuned logistic regression model and associated threshold table\n",
        "* tuned light boosting model and associated threshold table\n",
        "* tuned ANN model and associated threshold table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88r30GauhPsI"
      },
      "source": [
        "# Optional make-up: Random Forest model\n",
        "\n",
        "I will give you credit for one homework assignment in terms of points if you elect to take on this problem.\n",
        "\n",
        "You will need to do two things: (1) tune and save your threshold table and model below, and (2) add the model to your production notebook (your last notebook that is part of final.) The latter is the most tricky given you will actually have to change several places in the code I handed you for server. But it is doable if you get an early jump on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py2eUMQKT3ga"
      },
      "outputs": [],
      "source": [
        "#From chapter 12\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s_e216IBMoE"
      },
      "source": [
        "### Follow the steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fy5NQYMBMoE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM7WXZLzOgKr"
      },
      "source": [
        "## You still need to change the production notebook\n",
        "\n",
        "Find the places where you are loading models and thresholds and add the RF results. Find places where you are doing predictions and add RF prediction. Find place where you are showing prediction results in html and add RF prediction. Also add threshold table.\n",
        "\n",
        "This should not take long but will require you to pay attention to what you are doing to avoid screwing up what is already there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4bM31Y3BdM4"
      },
      "source": [
        "# Just for your interest\n",
        "\n",
        "There are several ways to combine the results of multiple models, four models in our case. We are using one of the ways in the server, but wanted to show you other options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5CR8tBBRJ9h"
      },
      "source": [
        "# IX. Voting - averaging binary\n",
        "\n",
        "There are two ways I can see of voting when have 4 models producing results. The first is to convert their output to binary. Then simply look for majority of either 0s or 1s. I added a twist that I fall back on probabilities for ties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb9Q5LN635__"
      },
      "outputs": [],
      "source": [
        "lgb_raw = final_lgb_model.predict_proba(x_test)[:,1]\n",
        "knn_raw = final_knn_model.predict_proba(x_test)[:,1]\n",
        "logreg_raw = final_logreg_model.predict_proba(x_test)[:,1]\n",
        "ann_raw = final_ann_model.predict(x_test)[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbMmM9nWRW6z"
      },
      "outputs": [],
      "source": [
        "yvotes = []\n",
        "for i in range(len(y_test)):\n",
        "  the_vote = (lgb_raw[i]>=.5+logreg_raw[i]>=.5+knn_raw[i]>=.5+ann_raw[i]>=.5)\n",
        "  if the_vote==2:\n",
        "    #tie breaker - go to probabilities\n",
        "    prob = (knn_yraw[i]+logreg_yraw[i]+xgb_yraw[i]+ann_yraw[i])/4\n",
        "    the_winner = 1 if prob>=.5 else 0\n",
        "  else:\n",
        "    the_winner = 1 if the_vote>2 else 0\n",
        "  yvotes.append(the_winner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZLERg9TVnMx"
      },
      "outputs": [],
      "source": [
        "sum([1 if p>=.5 else 0 for p in ann_raw])/len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA7UhZX_-tan"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, yvotes)\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl0yYW2Z-tao"
      },
      "outputs": [],
      "source": [
        "(cm[0,0]+cm[1,1])/len(y_test)  #accuracy 0.5665399239543726"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4uJuY39c0WY"
      },
      "source": [
        "Can now use it to compute precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnM0Ht9k-tao"
      },
      "outputs": [],
      "source": [
        "def precision_recall(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tp = cm[0,0]\n",
        "    fp = cm[0,1]\n",
        "    fn = cm[1,0]\n",
        "    prec = tp / (tp+fp)\n",
        "    rec = tp / (tp+fn)\n",
        "    return prec, rec\n",
        "\n",
        "precision, recall = precision_recall(y_test, yvotes)\n",
        "print(f'Precision: {precision} Recall {recall}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuFw_hPFZ-Jf"
      },
      "outputs": [],
      "source": [
        "f1 = 2*(precision*recall)/(precision+recall)\n",
        "f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feVTGvRT18qn"
      },
      "source": [
        "# X. Prob averaging\n",
        "\n",
        "The second voting approach is not actually voting. Instead, take average of 4 raw probabilities and use result as final probability. Can then run that through threshold table.\n",
        "\n",
        "This is what the server is doing to get the \"Ensemble\" value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfJSw7AS1A4Q"
      },
      "outputs": [],
      "source": [
        "avg_yraw = []\n",
        "for i in range(len(y_test)):\n",
        "  prob = (knn_raw[i]+logreg_raw[i]+lgb_raw[i]+ann_raw[i])/4\n",
        "  avg_yraw.append(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw_BS19r1dFC"
      },
      "outputs": [],
      "source": [
        "result_df, fancy_df = threshold_results(np.linspace(0,1,19,endpoint=True), y_test, avg_yraw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUh2Bh6T0acf"
      },
      "source": [
        "# XI. Stacking\n",
        "\n",
        "This is interesting in that it builds a whole separate model (a meta model) that takes the output of other base models, three in example below, and uses that as a row. So a row of 3 feature values, one from each of the base models.\n",
        "\n",
        "I kind of like it. The meta model learns how to combine the outputs of base models, e.g., when to weight KNN higher than LGB, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMtgikB00cdL"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "estimators = [\n",
        "     ('knn', KNeighborsClassifier(15, algorithm='ball_tree', p=1, weights='distance')),\n",
        "    ('logreg', LogisticRegressionCV(Cs= 5, class_weight= None, cv= 5, max_iter= 500, solver= 'saga', penalty='l1', random_state=1234)),\n",
        "    ('lgb', LGBMClassifier(boosting_type= 'gbdt',\n",
        "                          class_weight= 'balanced',\n",
        "                          learning_rate= 0.3,\n",
        "                          max_depth= 5,\n",
        "                          min_child_samples= 10,\n",
        "                          n_estimators= 10,\n",
        "                          num_leaves= 7,\n",
        "                          random_state=1234),\n",
        "    )\n",
        "]\n",
        "final_estimator = LogisticRegressionCV(random_state=1234)   #this is choice for meta model\n",
        "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeVYuX2K3vaZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "clf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctgU56kc39bh"
      },
      "outputs": [],
      "source": [
        "yraw = clf.predict_proba(x_test)[:,1]\n",
        "result_df, fancy_df = threshold_results(np.linspace(0,1,19,endpoint=True), y_test, yraw)\n",
        "fancy_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dPcoUS7R1nV"
      },
      "source": [
        "<img src='https://www.dropbox.com/scl/fi/zilmy2diy1lg1tva9vurx/Screenshot-2025-02-07-at-8.38.53-AM.png?rlkey=006szbv5t0daha005eotxt9k2&raw=1' height=400>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SXGHYrCpjLXl"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
