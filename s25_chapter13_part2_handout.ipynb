{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3jHBphnsfYh"
      },
      "source": [
        "#Announcement\n",
        "\n",
        "I will carry over changes made in Part 1 that differ from video. I believe this will lead to replicable results but they will not match video given changes made.\n",
        "\n",
        "Also note changes to Challenges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDiYMkiYgRS"
      },
      "source": [
        "<center>\n",
        "<h1>Chapter 13 - Part 2</h1>\n",
        "</center>\n",
        "\n",
        "<hr>\n",
        "\n",
        "Using the tensorflow library to build and tune ANNs. A complicated chapter that we will cover mostly at surface level. I'll try to give you links to deeper discussion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZiquu_S3vZG"
      },
      "source": [
        "##Set-up\n",
        "\n",
        "First bring in your library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ1mf3Sm6ZxA",
        "outputId": "b421a373-5b51-49b1-c935-83116e5225d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'library.py': No such file or directory\n",
            "--2025-05-28 17:02:38--  https://raw.githubusercontent.com/marvnc/cs523/main/library.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48297 (47K) [text/plain]\n",
            "Saving to: ‘library.py’\n",
            "\n",
            "library.py          100%[===================>]  47.17K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-05-28 17:02:39 (3.12 MB/s) - ‘library.py’ saved [48297/48297]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "github_name = 'marvnc'\n",
        "repo_name = 'cs523'\n",
        "source_file = 'library.py'\n",
        "url = f'https://raw.githubusercontent.com/{github_name}/{repo_name}/main/{source_file}'\n",
        "!rm $source_file\n",
        "!wget $url\n",
        "%run -i $source_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZVTLBYampYbo",
        "outputId": "1579763f-eb38-4b45-d6e2-fedb61c2f33a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Age Gender Class       Joined  Married  Fare  Survived\n",
              "0  41.0   Male    C3  Southampton      0.0   7.0         0\n",
              "1  21.0   Male  Crew  Southampton      0.0   0.0         0\n",
              "2  13.0   Male    C3  Southampton      NaN  20.0         0\n",
              "3  16.0   Male    C3  Southampton      0.0   NaN         0\n",
              "4   NaN   Male    C2    Cherbourg      0.0  24.0         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b85fc1d8-fa32-4a66-b5c7-be6e29b5a72d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Class</th>\n",
              "      <th>Joined</th>\n",
              "      <th>Married</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>C3</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Crew</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>C3</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>C3</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>C2</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b85fc1d8-fa32-4a66-b5c7-be6e29b5a72d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b85fc1d8-fa32-4a66-b5c7-be6e29b5a72d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b85fc1d8-fa32-4a66-b5c7-be6e29b5a72d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-54882611-0949-40f3-b942-b885e0c5e4fe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54882611-0949-40f3-b942-b885e0c5e4fe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-54882611-0949-40f3-b942-b885e0c5e4fe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "titanic_trimmed",
              "summary": "{\n  \"name\": \"titanic_trimmed\",\n  \"rows\": 1313,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.346944998228604,\n        \"min\": 1.0,\n        \"max\": 74.0,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          4.0,\n          41.0,\n          60.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Crew\",\n          \"C1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Joined\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Cherbourg\",\n          \"Queenstown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Married\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4751399890067327,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.58480450638799,\n        \"min\": 0.0,\n        \"max\": 512.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          19.0,\n          110.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/fickas/asynch_models/main/datasets/titanic_trimmed.csv'  #trimmed version\n",
        "\n",
        "titanic_trimmed = pd.read_csv(url)\n",
        "titanic_trimmed.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvZy9mwFVrGf",
        "outputId": "73a76ab7-3adb-4058-c420-9d3075a0bcb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1313"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(titanic_trimmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FVECbpjaNUkq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "x_train, x_test, y_train, y_test = titanic_setup(titanic_trimmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAaszQUlQ95l",
        "outputId": "3629a5f7-b026-4c0a-bfdc-9dbe94024835"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.78947368,  1.        ,  1.        ,  0.40075188,  0.        ,\n",
              "        -0.26086957]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x_train[:1]  #[[ 0.78947368,  1.        ,  1.        ,  0.40075188,  0.        ,-0.26086957]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdsIiE9lRDZz",
        "outputId": "3df28e88-45d8-4370-c5df-76212748d0a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_train[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEACCFSodbEy"
      },
      "source": [
        "#I. Review chapters\n",
        "\n",
        "We will be running into concepts we have seen in past chapters. In particular, I would recommend reviewing these:\n",
        "\n",
        "* Chapter 8 for gradient descent, learning rate, batch, epochs\n",
        "\n",
        "* Chapter 9 for weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zVtPEjMvN3X"
      },
      "source": [
        "#II. We will use the tensorflow library to build (and tune) our ANNs\n",
        "\n",
        "We began to explore tensorflow in the last chapter and noted a\n",
        "major alternative would be PyTorch. I have not really used it but I have had students who say they like it. Concepts are same but syntax and methods different.\n",
        "\n",
        "We will also use a sub-package of tensorflow called keras, which claims to add an easier front-end. I mostly agree, it does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FFIVRVZJvIPq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivBo351kjx1w"
      },
      "source": [
        "###Now Jump through some hoops to get replicable results\n",
        "\n",
        "I'm a little worried about this. Normally it works with straight ahead tensorflow. However we are introducing a tuning library later where I am concerned. If your results don't match up with mine, let me know. They should in theory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9UH8coL34r2q"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(1234)  #need this for replication\n",
        "tf.config.experimental.enable_op_determinism()  #ditto - https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism\n",
        "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "tf.config.threading.set_intra_op_parallelism_threads(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-OpV8mt0JTr"
      },
      "source": [
        "##Ready to build an ANN\n",
        "\n",
        "I am going to somewhat randomly chose to build an ANN that has two hidden layers. The first layer has 16 nodes and the second layer has 8 nodes. Other than that, it pretty much matches what we saw in the last chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJNGHDKNEMxo"
      },
      "source": [
        "###I'm using a weight initializer\n",
        "\n",
        "Again, I am skimming this topic but can point you to a [pretty good tutorial](https://towardsdatascience.com/weight-initialization-and-activation-functions-in-deep-learning-50aac05c3533). It discusses why we might want to use the `HeNormal` initializer to set the initial values of our weights on a layer.\n",
        "\n",
        "<pre>\n",
        "he_initializer = tf.keras.initializers.HeNormal(seed=1234)  #works well with our activation functions\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-Yc6OkHaTbT"
      },
      "source": [
        "###I'm using a weight regularizer.\n",
        "\n",
        " We saw the need for this when looking at gradient descent and logistic regression (Chapter 9).\n",
        "Remember that it penalizes weights that grow too large. The `L2` says we square the weights, i.e., really punish the large ones.\n",
        "\n",
        "<pre>\n",
        "l2_regu = tf.keras.regularizers.L2(0.01)  #weight regularization - tune the (reverse) lambda parameter\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1USFC7G0SCG"
      },
      "source": [
        "###I'll chose `Relu` from last chapter as our activation function\n",
        "\n",
        "Note I can use the string `'relu'`. Tensorflow has string short-cuts for some activation functions but not all. Depends if they have parameters or not. Relu does not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c_E_N8pm0csI"
      },
      "outputs": [],
      "source": [
        "act_fn = 'relu'  #long version: tf.keras.activations.relu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1_lhmHRzZj2"
      },
      "source": [
        "###Not using Dropout to avoid nondeterminism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K-KI_y0z6_Q",
        "outputId": "e922658a-7ed4-4ca8-acc3-87d1559755ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "feature_n = x_train.shape[1]\n",
        "feature_n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6t8Wu-I4axX"
      },
      "source": [
        "###We will need a way to turn strings into ints to use as seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rn274Bbm0JzQ"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "def string_to_seed(string):\n",
        "    # Create a hash of the string using SHA-256\n",
        "    hash_object = hashlib.sha256(string.encode())\n",
        "    # Convert first 8 bytes of hash to integer\n",
        "    hash_int = int.from_bytes(hash_object.digest()[:8], 'big')\n",
        "    return hash_int % (2**32 - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdr2C6w04miU"
      },
      "source": [
        "###Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IWOK4bAVvehF"
      },
      "outputs": [],
      "source": [
        "ann_model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "ann_model.add(Input(shape=(feature_n,), name=\"input_layer\"))\n",
        "#could add Dropout here but too few features to start with so bad idea\n",
        "\n",
        "#hidden layer 1\n",
        "layer_name = \"hidden_layer_1\"  #unique to each layer\n",
        "ann_model.add(Dense(units=16,\n",
        "                   activation=act_fn,\n",
        "                   name=layer_name+'_dense',\n",
        "                   kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "                   kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense'))\n",
        "))\n",
        "#ann_model.add(Dropout(.2, name='dropout1', seed=string_to_seed('dropout1')))  #Dropout currently causes non-replicalbe results :(\n",
        "\n",
        "#hidden layer 2\n",
        "layer_name = \"hidden_layer_2\"\n",
        "ann_model.add(Dense(units=8,\n",
        "                   activation=act_fn,\n",
        "                   name=layer_name+'_dense',\n",
        "                   kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "                   kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense'))\n",
        "))\n",
        "#ann_model.add(Dropout(.2, name='dropout2', seed=string_to_seed('dropout2')))\n",
        "\n",
        "#could add more hidden layers if you wanted.\n",
        "\n",
        "#hidden layer 3\n",
        "\n",
        "#hidden layer 4\n",
        "\n",
        "#etc\n",
        "\n",
        "#output layer for binary classification\n",
        "ann_model.add(Dense(units=1, name='output', activation='sigmoid'))  #only 1 node and using sigmoid (just like with logistic regression!)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTi0RZrT26yE"
      },
      "source": [
        "##The model is now structured but not built\n",
        "\n",
        "We have to compile it and provide some parameters:\n",
        "\n",
        "* I'm going to continue to use `roc_auc` for scoring. This is consistent with what we have been using for other models.\n",
        "\n",
        "* I considered using a special optimizer:\n",
        "<pre>\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9)\n",
        "ann_model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=.1),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "</pre>\n",
        "The optimizer is a special version of Stochastic Gradient Descent. If you remember, we used partial differential equations to update the weights in Logistic Regression. Well, we do the same here! Do you remember the learning rate that was part of the weight-update formula? The twist I am adding here are several mechanisms that focus on that rate. They adjust it as epochs roll by. They look at how loss is changing. A simple example is they may increase the rate if they think we are in a divot (false minimum) to claw our way out. If they believe we are getting close to the minimum, they may decrease the rate. This is an open area of research. I'll give you a [discussion of the `Adam/ExponentialDecay` combo](https://stats.stackexchange.com/questions/200063/adam-optimizer-with-exponential-decay). Many others possible. But in end I thought it was overly complicated for our simple data so omitted it.\n",
        "\n",
        "* For loss, Binary Crossentropy is the standard for binary classification problems. [Here is a pretty dang good tutorial](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a). I am using something called smoothing. I'll give you examples with and without:\n",
        "<pre>\n",
        "BCE = -[y * log(ŷ) + (1-y) * log(1-ŷ)]  #without smoothing\n",
        "</pre>\n",
        "where:\n",
        "  - y is the true label (0 or 1)\n",
        "  - ŷ is the model's prediction (between 0 and 1)\n",
        "\n",
        " With Label Smoothing (α):\n",
        "<pre>\n",
        "BCE = -[(y * (1-α) + α/2) * log(ŷ) + ((1-y) * (1-α) + α/2) * log(1-ŷ)]  #with smoothing\n",
        "</pre>\n",
        "where:\n",
        "  - α is the smoothing parameter (like 0.1)\n",
        "  - y is original label (0 or 1)\n",
        "  - ŷ is model's prediction\n",
        "\n",
        " Example with α = 0.1:\n",
        "  - For y = 1: (1 * 0.9 + 0.05) = 0.95\n",
        "  - For y = 0: (0 * 0.9 + 0.05) = 0.05\n",
        "\n",
        " This smooths the labels from {0,1} to {0.05, 0.95}. This helps because:\n",
        "\n",
        "  - It prevents the model from being overconfident\n",
        "  - Makes training more stable since the model doesn't try to predict exact 0s and 1s\n",
        "  - Can improve generalization by adding a small amount of uncertainty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6trvpc-m22uU"
      },
      "outputs": [],
      "source": [
        "ann_model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=.1),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001),\n",
        "                  metrics=['auc', 'accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luHQ_EMnsl9V"
      },
      "source": [
        "###Code to test if we have replicable results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcHqBe9AjgN9",
        "outputId": "fa5f7b04-bf6c-4b7c-a415-cb3e5041a296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients match: True\n"
          ]
        }
      ],
      "source": [
        "x_batch = x_train[:32]\n",
        "y_batch = y_train[:32].reshape(-1, 1)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    pred1 = ann_model(x_batch, training=True)\n",
        "    loss1 = tf.keras.losses.binary_crossentropy(y_batch, pred1)\n",
        "grads1 = tape.gradient(loss1, ann_model.trainable_variables)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    pred2 = ann_model(x_batch, training=True)\n",
        "    loss2 = tf.keras.losses.binary_crossentropy(y_batch, pred2)\n",
        "grads2 = tape.gradient(loss2, ann_model.trainable_variables)\n",
        "\n",
        "print(\"Gradients match:\", all(np.array_equal(g1, g2) for g1, g2 in zip(grads1, grads2)))  #should be True if replicable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCdeBUmHvehF"
      },
      "source": [
        "## Train an ANN\n",
        "\n",
        "Ok, we now have a compiled model ready for training. We still have to decide on the batch size and the number of epochs. I am also going to use the callback we saw in last chapter. This allows me to set the epochs to a fairly large size knowing early stopping will cut things off if necessary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Rw8Xrev5vehN"
      },
      "outputs": [],
      "source": [
        "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='auc',\n",
        "    mode='max',\n",
        "    min_delta=0,\n",
        "    patience=15,  #Wait 15 epochs for loss to improve - if no decrease, stop\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lCtARN1VvehN"
      },
      "outputs": [],
      "source": [
        "batch = 32  #https://ai.stackexchange.com/questions/8560/how-do-i-choose-the-optimal-batch-size\n",
        "epochs = 100  #mostly a guess\n",
        "training = ann_model.fit(x=x_train,\n",
        "                        y=y_train,\n",
        "                         batch_size=batch,\n",
        "                         epochs=epochs,\n",
        "                         verbose=0,\n",
        "                         callbacks=[early_stop_cb])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp2CxEJ_E4a_"
      },
      "source": [
        "###Did we stop early?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nuDpPM1E7B2",
        "outputId": "a574b774-ff52-416c-fbd1-817825546698"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "batch, len(training.history['auc'])  #looks like no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPuD0SWPUGp7",
        "outputId": "c0578f79-209f-40df-9943-b3d82673122d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8187116384506226"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "training.history['auc'][-1]  #0.8187116384506226"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "aVAt4hIQvehN",
        "outputId": "3c951ed6-d8a5-4672-ec08-37c74dd408e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHHCAYAAABtF1i4AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWVhJREFUeJzt3Xd8FHX+x/HXluymkYQQSAiEDlINCIIUFU88ROXEgih6YL2figpixYLlVLzz8PAUz3IgeoLYEAueiigq0gSJivQiiUAINT2bZHd+f8xmSSCUTZuU9/PxmMdMZmdmPzvcue/9fr8zYzMMw0BERETEInarCxAREZGGTWFERERELKUwIiIiIpZSGBERERFLKYyIiIiIpRRGRERExFIKIyIiImIphRERERGxlMKIiIiIWEphRERERCylMCLSwMyaNQubzRaYnE4nLVq04Nprr2Xnzp3l7mMYBv/9738566yziImJITw8nB49evD444+Tm5t7zPf64IMPGDZsGHFxcbhcLhITE7niiiv46quvTrreQ4cOERoais1mY/369eVuM3jwYLp3717ua/v27cNms/Hoo48e9drWrVv5v//7P9q1a0doaChRUVEMHDiQ5557jvz8/JOuUUQqx2l1ASJijccff5y2bdtSUFDA8uXLmTVrFkuWLGHt2rWEhoYGtvN6vYwePZp33nmHM888k0cffZTw8HC+++47HnvsMd59912+/PJL4uPjA/sYhsH111/PrFmz6NWrFxMnTiQhIYHdu3fzwQcfcO655/L9998zYMCAE9b57rvvYrPZSEhIYPbs2TzxxBNV8vkXLFjAyJEjcbvdjBkzhu7du1NYWMiSJUu45557+PXXX3nllVeq5L1E5AQMEWlQXnvtNQMwfvjhhzLr77vvPgMw3n777TLrn3rqKQMw7r777qOO9dFHHxl2u904//zzy6x/5plnDMCYMGGC4fP5jtrvjTfeMFasWHFS9Z511lnGpZdeatx5551G27Zty93m7LPPNrp161bua3v37jUA45FHHgms27ZtmxEZGWl07tzZ2LVr11H7bN682Zg2bdpJ1SciladuGhEB4MwzzwTMrosS+fn5PPPMM3Tq1IkpU6Yctc/w4cMZO3Ysn332GcuXLw/sM2XKFDp37sw//vEPbDbbUfv9+c9/pm/fviesKTU1le+++44rr7ySK6+8ku3bt7N06dKKfsSAv//97+Tk5DBjxgyaN29+1OsdOnRg/PjxlX4fETk5CiMiAsBvv/0GQOPGjQPrlixZwsGDBxk9ejROZ/m9umPGjAHgk08+Cexz4MABRo8ejcPhqFRNb731FhEREVx00UX07duX9u3bM3v27EodE+Djjz+mXbt2J9VNJCLVT2FEpIHKzMxk3759/P7777z//vs89thjuN1uLrroosA269atAyA5OfmYxyl5rWRwacm8R48ela5x9uzZXHzxxYSFhQEwatQo3nnnHYqLiyt8zKysLHbu3Fkl9YlI1VAYEWmghgwZQtOmTUlKSuLyyy8nIiKCjz76iJYtWwa2yc7OBqBRo0bHPE7Ja1lZWWXmx9vnZPz888/88ssvXHXVVYF1V111Ffv27ePzzz+v8HGrqj4RqToKIyIN1PTp01m4cCHvvfceF1xwAfv27cPtdpfZpuQLuySUlOfIwBIVFXXCfU7Gm2++SUREBO3atWPLli1s2bKF0NBQ2rRpU6GumpKxK1VVn4hUHV3aK9JA9e3blz59+gAwYsQIBg0axOjRo9m4cSORkZEAdOnSBTBbKUaMGFHucX7++WcAunbtCkDnzp0B+OWXX465z4kYhsFbb71Fbm5u4LilZWRkkJOTE6gzNDT0mPcFycvLC2wDZhhJTExk7dq1FapNRKqeWkZEBIfDwZQpU9i1axcvvPBCYP2gQYOIiYlhzpw5eL3ecvd94403AAJjTQYNGkTjxo156623jrnPiXzzzTf8/vvvPP7447z77rtlpldeeYW8vDzmz58f2L5169akpaWVG0g2btwY2KbERRddxNatW1m2bFmF6hORKmb1tcUiUrOOdZ8RwzCMvn37GvHx8UZ+fn5g3RNPPGEAxn333XfU9p988olht9uNoUOHlln/9NNPG4Bx1113lXufkf/+97/Hvc/IDTfcYERERJSpo7SOHTuWubfJ/PnzDcD45z//WWY7r9drXHLJJYbL5TIyMjIC67ds2WJEREQYXbt2NdLT0486/pYtW3SfEZEapG4aEQm45557GDlyJLNmzeLmm28G4P7772fNmjX87W9/Y9myZVx22WWEhYWxZMkS3nzzTbp06cLrr79+1HF+/fVXpk6dytdff83ll19OQkIC6enpzJ8/n5UrVx7zfiEej4f333+f8847r8ydYEv705/+xHPPPUdGRgbNmjVj+PDh/PGPf+TOO+9k5cqVDBgwgLy8PD766CO+//57nnjiCZo2bRrYv3379syZM4dRo0bRpUuXMndgXbp0Ke+++y7XXntt1ZxUETkxq9OQiNSs47WMeL1eo3379kb79u2N4uLiMutfe+01Y+DAgUZUVJQRGhpqdOvWzXjssceMnJycY77Xe++9Z/zxj380YmNjDafTaTRv3twYNWqUsXjx4mPu8/777xuAMWPGjGNus3jxYgMwnnvuucC6goIC49FHHzU6d+5suN1uIyIiwjjjjDOMN99885jH2bRpk3HTTTcZbdq0MVwul9GoUSNj4MCBxvPPP28UFBQccz8RqVo2wzAMi/OQiIiINGAawCoiIiKWUhgRERERSymMiIiIiKUURkRERMRSCiMiIiJiKYURERERsVSduOmZz+dj165dNGrUKPCwKxEREandDMMgOzubxMRE7PZjt3/UiTCya9cukpKSrC5DREREKiAtLY2WLVse8/U6EUZKHk2elpYWePy3iIiI1G5ZWVkkJSUFvsePpU6EkZKumaioKIURERGROuZEQyw0gFVEREQspTAiIiIillIYEREREUvViTEjJ8vr9VJUVGR1GRKkkJAQHA6H1WWIiIhF6kUYMQyD9PR0Dh06ZHUpUkExMTEkJCToPjIiIg1QvQgjJUGkWbNmhIeH6wutDjEMg7y8PDIyMgBo3ry5xRWJiEhNq/NhxOv1BoJIkyZNrC5HKiAsLAyAjIwMmjVrpi4bEZEGps4PYC0ZIxIeHm5xJVIZJf9+GvMjItLw1PkwUkJdM3Wb/v1ERBquehNGREREpG5SGBERERFLKYxY5Nprr8Vms2Gz2QgJCaFt27bce++9FBQUHLXtJ598wtlnn02jRo0IDw/n9NNPZ9asWeUe9/3332fw4MFER0cTGRnJqaeeyuOPP86BAwdOWNP//d//4XA4ePfdd8utd8SIEUetX7x4MTabrcxl1YWFhfz9738nOTmZ8PBw4uLiGDhwIK+99prGhIiIyFEadhjxeaHYA95iS97+/PPPZ/fu3Wzbto1//vOfvPzyyzzyyCNltnn++ee5+OKLGThwICtWrODnn3/myiuv5Oabb+buu+8us+2DDz7IqFGjOP300/nf//7H2rVrmTp1Kj/99BP//e9/j1tLXl4ec+fO5d5772XmzJkV/kyFhYUMHTqUp59+mr/85S8sXbqUlStXMm7cOJ5//nl+/fXXCh9bRETqpzp/aW+lHNwBnkyIToKIuBp/e7fbTUJCAgBJSUkMGTKEhQsX8re//Q2AtLQ07rrrLiZMmMBTTz0V2O+uu+7C5XJxxx13MHLkSPr168fKlSt56qmnmDZtGuPHjw9s26ZNG84777wT3hDu3XffpWvXrtx///0kJiaSlpZGUlJS0J9p2rRpfPvtt6xatYpevXoF1rdr146RI0dSWFgY9DFFRKR+q3ctI4ZhkFdYfHKT105ekY+8As/J73OcyTCMCte9du1ali5disvlCqx77733KCoqOqoFBMwulcjISN566y0AZs+eTWRkJLfeemu5x4+JiTnu+8+YMYNrrrmG6Ohohg0bdsxuoBOZPXs2Q4YMKRNESoSEhBAREVGh44qISP1V71pG8ou8dJ38eZB7pVfJe697fCjhrpM/pZ988gmRkZEUFxfj8Xiw2+288MILgdc3bdpEdHR0uXcldblctGvXjk2bNgGwefNm2rVrR0hISNB1b968meXLlzNv3jwArrnmGiZOnMhDDz0U9CW3mzdvZvDgwUHXICIiDVe9axmpS8455xxSUlJYsWIFY8eO5brrruOyyy6r0LEq0yozc+ZMhg4dSlyc2VV1wQUXkJmZyVdffVWjdYiISMNU71pGwkIcrHt86MltnHcQMlMhJBLi2lfJewcjIiKCDh06AGYgSE5OZsaMGdxwww0AdOrUiczMTHbt2kViYmKZfQsLC9m6dSvnnHNOYNslS5ZQVFQUVOuI1+vl9ddfJz09HafTWWb9zJkzOffccwGIiopix44dR+1/6NAhHA5HoPulU6dObNiwIYizICIiDV29axmx2WyEu5wnN4W6CQ+xE+70nfw+x5kqcxdRu93OAw88wEMPPUR+fj4Al112GSEhIUydOvWo7V966SVyc3O56qqrABg9ejQ5OTm8+OKL5R7/WANYP/30U7Kzs1mzZg0pKSmB6a233mLevHmB/U455RR+/fVXPB5Pmf1//PFH2rZtGwhAo0eP5ssvv2TNmjVHvVdRURG5ubkndT5ERKThqHdhJCgOf0uAz5pLe480cuRIHA4H06dPB6BVq1b8/e9/Z9q0aTz44INs2LCBrVu38uyzz3Lvvfdy11130a9fPwD69esXWHfvvfeybNkyduzYwaJFixg5ciSvv/56ue85Y8YMLrzwQpKTk+nevXtguuKKK4iJiWH27NkAXH311dhsNsaMGcPq1avZsmULM2fOZNq0adx1112B402YMIGBAwdy7rnnMn36dH766Se2bdvGO++8wxlnnMHmzZur+SyKiEidY9QBmZmZBmBkZmYe9Vp+fr6xbt06Iz8/P/gDFxcaxs4fzcnnq4JKT97YsWONiy+++Kj1U6ZMMZo2bWrk5OQE1n344YfGmWeeaURERBihoaFG7969jZkzZ5Z73Lfffts466yzjEaNGhkRERHGqaeeajz++OPGwYMHj9o2PT3dcDqdxjvvvFPusW655RajV69egb83btxoXHLJJUZiYqIRERFhJCcnG6+++qrhO+LcFRQUGFOmTDF69OhhhIaGGrGxscbAgQONWbNmGUVFReW+V6X+HUVEpFY63vd3aTbDqP0jDrOysoiOjiYzM5OoqKgyrxUUFLB9+3batm1LaGhocAc2fLD7J3M5vjs4gr8SRapGpf4dRUSkVjre93dpDbubxmYHm3/QaS3pqhEREWloGnYYgVo3bkRERKShURixK4yIiIhYSWGkJIxY9LA8ERGRhk5hxO4ftKqWEREREUsojAS6aYqsrUNERKSBUhjRAFYRERFLKYxoAKuIiIilFEY0gFVERMRSCiMWDWAdPHgwEyZMqNH3FBERqY0URkpaRgyveXt4ERERqVEKI3bH4WWNGxEREalxCiM2m+XjRg4ePMiYMWNo3Lgx4eHhDBs2jM2bNwde37FjB8OHD6dx48ZERETQrVs3Pv3008C+V199NU2bNiUsLIyOHTvy2muvWfI5REREKsJpdQFVzjCgKC+4fbxFUFwABVlAJR5iHBJuhpsgXXvttWzevJmPPvqIqKgo7rvvPi644ALWrVtHSEgI48aNo7CwkG+//ZaIiAjWrVtHZGQkAA8//DDr1q3jf//7H3FxcWzZsoX8/PyKfwYREZEaVv/CSFEePJVozXs/sAtcEUHtUhJCvv/+ewYMGADA7NmzSUpKYv78+YwcOZLU1FQuu+wyevToAUC7du0C+6emptKrVy/69OkDQJs2barms4iIiNSQoLtpvv32W4YPH05iYiI2m4358+cfd/t58+Zx3nnn0bRpU6Kioujfvz+ff/55Reutd9avX4/T6aRfv36BdU2aNOGUU05h/fr1ANxxxx088cQTDBw4kEceeYSff/45sO0tt9zC3Llz6dmzJ/feey9Lly6t8c8gIiJSGUG3jOTm5pKcnMz111/PpZdeesLtv/32W8477zyeeuopYmJieO211xg+fDgrVqygV69eFSr6uELCzRaKYGTthNx9ENkMGjWv3HtXgxtvvJGhQ4eyYMECvvjiC6ZMmcLUqVO5/fbbGTZsGDt27ODTTz9l4cKFnHvuuYwbN45//OMf1VKLiIhIVbMZhlHhQRI2m40PPviAESNGBLVft27dGDVqFJMnTz6p7bOysoiOjiYzM5OoqKgyrxUUFLB9+3batm1LaGhoUHUEZKdD9m4Ij4WY1hU7RpAGDx5Mz549GTduHJ06dSrTTbN//36SkpJ44403uPzyy4/ad9KkSSxYsKBMC0mJl19+mXvuuYesrKxq/wxVqUr+HUVEpFY53vd3aTU+ZsTn85GdnU1sbGxNv/WxWXg1TceOHbn44ou56aabePnll2nUqBH3338/LVq04OKLLwZgwoQJDBs2jE6dOnHw4EG+/vprunTpAsDkyZPp3bs33bp1w+Px8MknnwReExERqQtqPIz84x//ICcnhyuuuOKY23g8HjweT+Dvav+Vb/HzaV577TXGjx/PRRddRGFhIWeddRaffvopISHm3WG9Xi/jxo3j999/JyoqivPPP59//vOfALhcLiZNmsRvv/1GWFgYZ555JnPnzrXkc4iIiFREjXbTzJkzh5tuuokPP/yQIUOGHHO7Rx99lMcee+yo9dXWTePJgf2bweGC+G4VO4ZUirppRETqn5Ptpqmxm57NnTuXG2+8kXfeeee4QQTMMRGZmZmBKS0trXqLc+jJvSIiIlapkW6at956i+uvv565c+dy4YUXnnB7t9uN2+2ugcr8Sh6WZ/jA5y17i3gRERGpVkGHkZycHLZs2RL4e/v27aSkpBAbG0urVq2YNGkSO3fu5I033gDMrpmxY8fy3HPP0a9fP9LT0wEICwsjOjq6ij5GJdnsgA0wzNYRhREREZEaE3Q3zapVq+jVq1fgHiETJ06kV69egct0d+/eTWpqamD7V155heLiYsaNG0fz5s0D0/jx46voI1SB0s+nUVeNiIhIjQq6ZWTw4MEcb8zrrFmzyvy9ePHiYN+iQioxDtfkcIKvSGHEIpX+9xMRkTqrzj+1t+Ty17y8IB+OdyS1jFiq5N+v5N9TREQajjr/oDyHw0FMTAwZGRkAhIeHY6vAk3MptkGxAfn5YC+o4irlWAzDIC8vj4yMDGJiYnA4NF5HRKShqfNhBCAhIQEgEEgqJP8QeLLA7YGw7KopTE5aTExM4N9RREQalnoRRmw2G82bN6dZs2YUFRVV7CCrX4dlz0OnC+CPj1dtgXJcISEhahEREWnA6kUYKeFwOCr+pRYeCTlpkLkFdAdQERGRGlPnB7BWmYim5jx3r7V1iIiINDAKIyUimpjz3H3W1iEiItLAKIyUKGkZydsHuueFiIhIjVEYKREeZ869heZVNSIiIlIjFEZKuMLBFWkuq6tGRESkxiiMlBZeMm5Eg1hFRERqisJIabqiRkREpMYpjJQWCCPqphEREakpCiOlRfgHsSqMiIiI1BiFkdLUTSMiIlLjFEZKC7SMKIyIiIjUFIWR0krf+ExERERqhMJIaRozIiIiUuMURkrTmBEREZEapzBSWkQzc563H4oLra1FRESkgVAYKS2yGYSEg+GDQzusrkZERKRBUBgpzWaD2Pbm8v6t1tYiIiLSQCiMHKlJO3O+f4u1dYiIiDQQCiNHatLBnB9Qy4iIiEhNUBg5UkkYUcuIiIhIjVAYOVJgzMg2a+sQERFpIBRGjlTSMpL1OxTmWVuLiIhIA6AwcqTwWAiNNpcPbre2FhERkQZAYeRINpvGjYiIiNQghZHy6F4jIiIiNUZhpDyBlhGFERERkeqmMFKeJv6WEd1rREREpNopjJSnJIxozIiIiEi1UxgpT8mYkdy9UJBpbS0iIiL1nMJIeUKjIKKZuaxxIyIiItVKYeRYAs+o0Z1YRUREqpPCyLHo6b0iIiI1QmHkWHR5r4iISI0IOox8++23DB8+nMTERGw2G/Pnzz/u9rt372b06NF06tQJu93OhAkTKlhqDYvVFTUiIiI1IegwkpubS3JyMtOnTz+p7T0eD02bNuWhhx4iOTk56AItExgzshUMw9paRERE6jFnsDsMGzaMYcOGnfT2bdq04bnnngNg5syZwb6ddWLbAjbz0t68/RARZ3VFIiIi9VLQYaQmeDwePB5P4O+srKyaLyIkDKJbQmaaOW5EYURERKRa1MoBrFOmTCE6OjowJSUlWVOI7sQqIiJS7WplGJk0aRKZmZmBKS0tzZpCYvWMGhERkepWK7tp3G43brfb6jJKXd6rlhEREZHqUitbRmqNQDeN7sIqIiJSXYJuGcnJyWHLlsMtBdu3byclJYXY2FhatWrFpEmT2LlzJ2+88UZgm5SUlMC+e/fuJSUlBZfLRdeuXSv/CarTkZf32mzW1iMiIlIPBR1GVq1axTnnnBP4e+LEiQCMHTuWWbNmsXv3blJTU8vs06tXr8Dy6tWrmTNnDq1bt+a3336rYNk1JKYV2J1QlAfZuyEq0eqKRERE6p2gw8jgwYMxjnMTsFmzZh217njb12qOEIhpbbaM7N+iMCIiIlINNGbkRPSMGhERkWqlMHIiJWFk3yZr6xAREamnFEZOJKG7Od/9s7V1iIiI1FMKIyfS3P9wv/SfweezthYREZF6SGHkROJOAWcoeLLg4HarqxEREal3FEZOxOGE+G7m8u6frK1FRESkHlIYORnNe5rz3SlWViEiIlIvKYycjJJxI2oZERERqXIKIyejdBipqzdwExERqaUURk5Gsy5gD4H8g5CZZnU1IiIi9YrCyMlwuiHe/1C/XSmWliIiIlLfKIycLI0bERERqRYKIydLYURERKRaKIycrNKX92oQq4iISJVRGDlZ8d3A5oDcvZC92+pqRERE6g2FkZMVEgZNO5vL6qoRERGpMgojwdC4ERERkSqnMBIMhREREZEqpzASDIURERGRKqcwEoyEHoANsnZCzl6rqxEREakXFEaC4Y6EuI7mslpHREREqoTCSLACXTUplpYhIiJSXyiMBEvjRkRERKqUwkiw1DIiIiJSpRRGgpVwqjk/lAp5B6ytRUREpB5QGAlWWAzEdTKX01ZYWoqIiEh9oDBSEa36m/MdS62tQ0REpB5QGKmIkjCSuszaOkREROoBhZGKaO0PI7tSoDDP0lJERETqOoWRiohpDY2ag68Idq62uhoREZE6TWGkImw2ddWIiIhUEYWRimo9wJwrjIiIiFSKwkhFtTrDnKetBG+xtbWIiIjUYQojFdWsK7ijoTAH9qy1uhoREZE6S2GkouwOSOprLqurRkREpMIURiqjtW5+JiIiUlkKI5XRqmQQ63IwDGtrERERqaMURiojsRc4XJCbAQe2WV2NiIhInRR0GPn2228ZPnw4iYmJ2Gw25s+ff8J9Fi9ezGmnnYbb7aZDhw7MmjWrAqXWQiGh0KK3uayuGhERkQoJOozk5uaSnJzM9OnTT2r77du3c+GFF3LOOeeQkpLChAkTuPHGG/n888+DLrZWCtz8bLm1dYiIiNRRzmB3GDZsGMOGDTvp7V966SXatm3L1KlTAejSpQtLlizhn//8J0OHDg327WufQBhRy4iIiEhFVPuYkWXLljFkyJAy64YOHcqyZce+HNbj8ZCVlVVmqrWS+gI2c8xI9h6rqxEREalzqj2MpKenEx8fX2ZdfHw8WVlZ5Ofnl7vPlClTiI6ODkxJSUnVXWbFhcVAfDdzWfcbERERCVqtvJpm0qRJZGZmBqa0tDSrSzq+VrrfiIiISEVVexhJSEhgz56y3Rd79uwhKiqKsLCwcvdxu91ERUWVmWq1NoPM+fZvrK1DRESkDqr2MNK/f38WLVpUZt3ChQvp379/db91zWl7FtjssHcDZP5udTUiIiJ1StBhJCcnh5SUFFJSUgDz0t2UlBRSU1MBs4tlzJgxge1vvvlmtm3bxr333suGDRt48cUXeeedd7jzzjur5hPUBuGxkHiaubz1a2trERERqWOCDiOrVq2iV69e9OrVC4CJEyfSq1cvJk+eDMDu3bsDwQSgbdu2LFiwgIULF5KcnMzUqVP5z3/+Uz8u6y2tw7nmfOui428nIiIiZdgMo/Y/VCUrK4vo6GgyMzNr7/iR1OUwcyiENYZ7tppP9RUREWnATvb7u1ZeTVMntegD7ijIPwi7UqyuRkREpM5QGKkqDqc5kBVg61fW1iIiIlKHKIxUJY0bERERCZrCSFVq/wdznrYSCmrxLexFRERqEYWRqtS4DcS2B8ML27+1uhoREZE6QWGkqpW0jmjciIiIyElRGKlqGjciIiISFIWRqtZmENidcPA3OLDN6mpERERqPYWRquZuBEn9zOUtah0RERE5EYWR6hAYN6Ln1IiIiJyIwkh1KAkj278Fb5G1tYiIiNRyCiPVoXlPCG8ChdnmM2tERETkmBRGqoPdDh3/aC5v/J+1tYiIiNRyCiPV5ZRh5nzjp1D7H4wsIiJiGYWR6tL+XHC44OB22LvB6mpERERqLYWR6uKOhLZnm8sbP7W2FhERkVpMYaQ6db7AnG9QGBERETkWhZHq1Mk/bmTnKsjeY20tIiIitZTCSHWKag6Jp5nLm3RVjYiISHkURqrbKf6uGl3iKyIiUi6FkepWMm5k22IozLW0FBERkdpIYaS6NesKMa2guEDPqhERESmHwkh1s9nglAvNZXXViIiIHEVhpCaU3I1102fg81pbi4iISC2jMFITWg+A0GjI2we//2B1NSIiIrWKwkhNcIQcfnDehgXW1iIiIlLLKIzUlJJLfNd/rAfniYiIlKIwUlM6/hGcoeaD89J/troaERGRWkNhpKa4Iw931fz6gbW1iIiI1CIKIzWp2whz/ut8ddWIiIj4KYzUpI5DwRlmdtXs/snqakRERGoFhZGa5I6ETuqqERERKU1hpKZ1HWHO181XV42IiAgKIzWvU0lXzW+wO8XqakRERCynMFLTXBFmIAF11YiIiKAwYo1ul5hzXVUjIiKiMGKJjn+EkHA4tAN2rbG6GhEREUtVKIxMnz6dNm3aEBoaSr9+/Vi5cuUxty0qKuLxxx+nffv2hIaGkpyczGeffVbhgusFV7i6akRERPyCDiNvv/02EydO5JFHHuHHH38kOTmZoUOHkpGRUe72Dz30EC+//DLPP/8869at4+abb+aSSy5hzZoG3iKgrhoREREAbIYR3Ddhv379OP3003nhhRcA8Pl8JCUlcfvtt3P//fcftX1iYiIPPvgg48aNC6y77LLLCAsL48033zyp98zKyiI6OprMzEyioqKCKbf2KsyDZ9pDUR7c+BW07G11RSIiIlXqZL+/g2oZKSwsZPXq1QwZMuTwAex2hgwZwrJly8rdx+PxEBoaWmZdWFgYS5YsCeat6x9XOJwyzFxe+761tYiIiFgoqDCyb98+vF4v8fHxZdbHx8eTnp5e7j5Dhw7l2WefZfPmzfh8PhYuXMi8efPYvXv3Md/H4/GQlZVVZqqXul9mzn+dBz6vtbWIiIhYpNqvpnnuuefo2LEjnTt3xuVycdttt3Hddddhtx/7radMmUJ0dHRgSkpKqu4yrdFhCIRGQ/ZuSC2/ZUlERKS+CyqMxMXF4XA42LNnT5n1e/bsISEhodx9mjZtyvz588nNzWXHjh1s2LCByMhI2rVrd8z3mTRpEpmZmYEpLS0tmDLrDqcbugw3l395z9paRERELBJUGHG5XPTu3ZtFixYF1vl8PhYtWkT//v2Pu29oaCgtWrSguLiY999/n4svvviY27rdbqKiospM9Vb3y835ug/BW2RtLSIiIhYIuptm4sSJvPrqq7z++uusX7+eW265hdzcXK677joAxowZw6RJkwLbr1ixgnnz5rFt2za+++47zj//fHw+H/fee2/VfYq6rO1ZENEM8g/A1q+trkZERKTGOYPdYdSoUezdu5fJkyeTnp5Oz549+eyzzwKDWlNTU8uMBykoKOChhx5i27ZtREZGcsEFF/Df//6XmJiYKvsQdZrdYd5zZOXLsPY96PRHqysSERGpUUHfZ8QK9fI+I6WlrYQZ54ErEu7ebF72KyIiUsdVy31GpJq0PB2iW0FhDmz+wupqREREapTCSG1gs0H3S83ltbqqRkREGhaFkdqih/+qmk1fQEGmtbWIiIjUIIWR2iK+O8SdAl4PbFhgdTUiIiI1RmGktrDZDreO6AZoIiLSgCiM1CYlz6rZ9jVkHfvZPSIiIvWJwkht0qQ9tOoPhg9+ftvqakRERGqEwkht03O0OU+ZA7X/FjAiIiKVpjBS23QdAc4w2LcRdv5odTUiIiLVTmGktgmNgq5/MpdTZltbi4iISA1QGKmNSrpq1r4HRQXW1iIiIlLNFEZqozZnQVRL8+ZnGz+1uhoREZFqpTBSG9nt0PMqczlljrW1iIiIVDOFkdoq2R9Gti6CrF3W1iIiIlKNFEZqK91zREREGgiFkdpM9xwREZEGQGGkNut2CYSEw75N8Psqq6sRERGpFgojtZm7EXTx33Nk9WvW1iIiIlJNFEZqu9NvNOe/vAe5+62tRUREpBoojNR2LftA857g9cCaN6yuRkREpMopjNR2Nhv0/Yu5/MMM8HmtrUdERKSKKYzUBd0vhbBYyEyDTZ9ZXY2IiEiVUhipC0LC4LQx5vLKV6ytRUREpIopjNQVfa4Hmx22LYa9G62uRkREpMoojNQVjVtDp2Hm8g//sbYWERGRKqQwUpf0vcmcp8yBgixraxEREakiCiN1SbvB0KQjFOboeTUiIlJvKIzUJaUv8135Cvh81tYjIiJSBRRG6prkK8EdZT6vZvPnVlcjIiJSaQojdU1oFPS5zlxeMs3SUkRERKqCwkhddMat4HBB2nJIXW51NSIiIpWiMFIXNUowu2tArSMiIlLnOa0uQCpowHj48b+w6X+QsR6adbG6IhERKYfXZ2C3gc1mC6wr9vrILigmu6CYrIIisguKKSjyUlDkJd8/+Qxw2m047TZCHHacDnPZbrPhdJhzA/AU+fAUe/EU+/AU+zAMA8M4/P5FXh85nmJyCorJ8RST7SnGU2RuX1jso9BrzicN68KgjnE1f4JQGKm74jpAl4tg/cfw/b/gkn9bXZGIyFG8PoNinw+fD3yG4Z+gsNhHXmExuR4vuYXF5BV6MQwDu82GzYY5B7CVOpgBPgPzeIZBsdc8FpgXG5Zsnl/kJaugmKz8IrIKisj1FGPDhsP/Re6wQ5HXoKDIS16hORUUeSn0+sx6vT6KvAYGZhiw+wOBw2bDaxgU+7cx398odVwbdhsUFJlf/rmFxeR6iinyHk4Gdv9nK/aVSgu1xP5cj2XvrTBSlw280wwjv7wDf3gQoltaXZGIVAHDMPxf4kbgi9mcyv66Lr19kdegoNhLgf/LNcdj/urO8ZhfiMU+84vT/EI38BoGBSW/qIsO/6K2BcKA+cWf6zl8jFyPlyJv2VsK+PzHySssDsw9xeYXdZHPV+YXupjn1FfqpIS7HDQKdRLpdhLuchIW4iDU5SDUacdht1HkNcNcsdegyOsPYT4DX6n/fYQ6HbhD7LidDlwOcz8gEOScdhuRbieRoU4auZ1EuJ2EhpjbukPsuBx2XE47XZtHWXBG/DVa9s5SeS17Q5sz4bfvYNmLcP5TVlckUi8Y/v/gF3l9eIp85pd8kY+CIvPL2Ov/Yvf6zF/+Xp/5xVvsNX8xF/r3K2luzy/0ml/mJXP/r+Z8f3Ao2cbjbzIv8h7/S9zh/5VeElQ8xV5q4Q/tEwp3OYhwO4lwOQhzOQMBqKSbwWybKKukBaKkxcJeKpwZhrlHWIiDqNAQosKcRIWGEOF2YgA+nxnCfD4Du91GeIiDMJfDDAEuu9kVYrcT4jDfw2azmfv4v/h9/pabktdDHHZsNvOWTyXH9foM3CF2ItxmwIhwmwHD8LcIlczdTjuNQp04HRq6CQojdd/ACWYYWT0LzrobwmOtrkjkhLw+g8z8IgzDwGm343Ac/nL1+VsFSv4Dn5VfxMG8Qg7lmfOs/CLy/F/eJU3sXp8Pr8/fouAPEp6isl/0hgF2u9lE77DZwGYL9JvnF3op8LcQFPt8ZZrVayOvz8Bbzhc1mN0VYSGHf21HhoYQ6XbgtNsDLSslXQWhIQ7cTrv5K9lpvm74u0IMDGzYiHA7Al+skW4nIUd8eZa8X5jLQViIg3CXeSynw06I3YbT/0v9yABVEiZEQGGk7utwLsT3gD2/wMpXYfB9Vlck9YRhGHiKzVaAkl+iDrsNr8/gQF4h+7IL2Z/rYX9OIYfyCs3BeJ5isguKyPV48fq7BAzMX7m5hV72ZnvYm+3hQK6nTv2SD3HYcDsdhIaYv55Lfp2bv54hxO4fXOj/Ag5x2Al3lTS3m/uVNMNHuB3msttJuP/LO8w/hTodhDjNX+ZuhwOHw1bmF7XZInN47IXXZ55bt9OOO8R8H5fDXm5XjkhtVqEwMn36dJ555hnS09NJTk7m+eefp2/fvsfcftq0afz73/8mNTWVuLg4Lr/8cqZMmUJoaGiFCxc/mw0GTYD3b4Dl06Hf/0FYjNVVSS3h9RlkFxSRmW8GBPNXv/nLv8jrY1+Ohz1ZHvZkFZCRZQaFQ/lmK8Sh/CIKi61/5ECEy0FMuIuY8BAah7uIDgvxN637m9hDnIQ4/QMI/b+8nXab+eUecngqGXxY0pRuYH6Jl/yiN7/IHYQ4zTBREjDc/l/5IlJ9gg4jb7/9NhMnTuSll16iX79+TJs2jaFDh7Jx40aaNWt21PZz5szh/vvvZ+bMmQwYMIBNmzZx7bXXYrPZePbZZ6vkQzR43S6Bb/4O+zbCipfVOlKPFBR5Sc8sID2rIDDfm+2hyOuj2Gfg9ZpdEgXF5liEwKV7/isJsj3F1VKXzQZNIlw0iXDTJNJF43AXjUKd/snso3f4uwRsNnMcXWiIg6aN3IEpNtwVaGkpLhUQSgJFSbO+mvJF6j+bYQQ31rlfv36cfvrpvPDCCwD4fD6SkpK4/fbbuf/++4/a/rbbbmP9+vUsWrQosO6uu+5ixYoVLFmy5KTeMysri+joaDIzM4mKsm60b6229n1473pwR8OEn9U6Ugt5fQapB/LYtCebTenZbNmbg6fIh9Phv4eA3YbPgIzsAvZkFbAny0NmflGVvHe4f5Ceq6Qrwf+esREuEqJCaRYVSnyUGRJKWh9iwkOIDgvBabdT7PMFBmoCxPiDhIjI8Zzs93dQLSOFhYWsXr2aSZMmBdbZ7XaGDBnCsmXLyt1nwIABvPnmm6xcuZK+ffuybds2Pv30U/785z8f8308Hg8ez+HrnbOysoIps2HqOgKa/h32boAVL8Hgo4OhBM9T7OVArr/bIq+IQ3mFZOYXUeQz8PpbJ3yGQX6hj8z8osCUVVBEQZE3cCWGp8jHwbxCPBXo9ggNsdM8Ooz4KDfNo8No2shtdh34uxEcdrMrIdLt9A9aDCHC7SA6LISosBCiQkNwOSvbzeCo5P4iIscWVBjZt28fXq+X+Pj4Muvj4+PZsGFDufuMHj2affv2MWjQIPNyueJibr75Zh544IFjvs+UKVN47LHHgilN7A44+z547zrzMt9+N6t1pByGYbA/t5C0A3mkHcznUF4hOZ5i8jyH78uwN8dDRpbZOnEwr2paJkq4nXY6xkfSqVkjOsY3IjLUGbh5UqHXh80GzRqZrRTxUaHER4USFerUgEQRqdeq/WqaxYsX89RTT/Hiiy/Sr18/tmzZwvjx4/nrX//Kww8/XO4+kyZNYuLEiYG/s7KySEpKqu5S675A68h6WP5vOGfSCXepjwzDvGx0695ctu3NYds+c759Xy6/H8wnr9Ab1PGcdhsx4SHmIEp/a4PbaT98V0Z/y0RUmNmtEe1vjYhwOwJXYLid5n0PWjQOU/eGiMgRggojcXFxOBwO9uzZU2b9nj17SEhIKHefhx9+mD//+c/ceOONAPTo0YPc3Fz+8pe/8OCDD2K3H9187Ha7cbvdwZQmAHa7OXj13Wth+Ytwxs0Q1tjqqqpNYbGPTXuyWbcri80Z2aQeyCPtQD5pB/KOO3DTZoOEqFCSGocT18hFhMu8MVG4y0FkqJOmkYdbJeKj3ESHhahlQkSkGgUVRlwuF71792bRokWMGDECMAewLlq0iNtuu63cffLy8o4KHA6H2f8c5NhZORldLoZmXSFjnb915NjdYXXJvhwPG9OzWb87i43p2fzqDyDHuzlVQlQo7ZtF0C4uknZNI2jXNJJWseEkxoTidmoMhIhIbRF0N83EiRMZO3Ysffr0oW/fvkybNo3c3Fyuu+46AMaMGUOLFi2YMmUKAMOHD+fZZ5+lV69egW6ahx9+mOHDhwdCiVQhu90cO/LuWDOM9P0/iGhidVVBS88s4OuNGXy9IYMfUw+xL6f8BzhFhTrplhhN5+aNaB0bTqsm4SQ1Dqdl43DCXPrfl4hIXRB0GBk1ahR79+5l8uTJpKen07NnTz777LPAoNbU1NQyLSEPPfQQNpuNhx56iJ07d9K0aVOGDx/Ok08+WXWfQsrq8idI6AHpv8DiKXDhP6yu6JgMw+BgXhG/7c9lx/5cNqbn8M2mvazfXfYKKpsNWseG0zkhilMSGtE1MYquzaNo2ThMXSgiInVc0PcZsYLuM1IB27+F14eDzQG3LoOmp1hdEYZh8PvBfNakHSIl9RApaQfZvCen3PEdNhskt4zhnFOaMahjHF2aNyLcpacXiIjUJdVynxGpQ9qeBadcCBsXwBcPwdXv1ngJmflF/JR2iJ/SDpGSdoiffj/EvpzCcrdNjA6lVZNw2jSJoG/bWM7u1JQmkRrELCLSECiM1GfnPQ6bP4fNX8CWReZD9arR3mwPK7bvZ/m2/SzfdoAtGTlHbRPisNG1eRQ9k2Lo2SqGbonRtIoNJzRE4ztERBoqhZH6LK4D9P2LeZnvFw9B27PBUbX/5Jv2ZDN/zU6+WLen3PDRKjacnkkxJCfF0DMphm6JUQoeIiJShsJIfXfWPZAyx7zUd80b0Of6Sh9yT1YBH6bsZP6aXaw7YqBpl+ZRnNEuljPaNaFP68bqahERkRNSGKnvwmNh8CT47D746knofjmEVmwQ8K5D+Tz/1RbeXZVGsf+BaSEOG2d3asbFPRMZ1CGOxhGuqqxeREQaAIWRhuD0G+CHV2H/Fvj27/DHJ4LaPSO7gBe/3sqcFakUes0HvfVu3ZhLT2vBBd2bK4CIiEilKIw0BI4QGPoUzLnCfIjeqaPM+5Ach2EYrEk7xPurf+f9H3+noMgMIf3axnL30FM4vU1sTVQuIiINgMJIQ9FpqHkztPUfwUd3wI1fmk/6PULagTzmr9nJvDU72b4vN7C+V6sY7v7jKQxo30Q3GRMRkSqlMNKQDPs7bFsMu36EH/4D/f4v8NKvuzJ58eutfLp2NyW3wQt3OTi/ewKXn9aS/gohIiJSTRRGGpKo5jDkEVhwFyx6HDpfxOpDYbzw1Ra+3rg3sNnADk247LSWDO2WQIRb/xMREZHqpW+ahqb39fDT2/D7Sla/dBOXHRwHgN0GF52ayK3ntKdzgm65LyIiNUdhpKGx21l8yoMM/P1Seud/zwXOfkT1uoSbz25Pm7gIq6sTEZEGyH7iTaS+OJRXyB1vreHaBbm8XHwRAP+Kns3TF7ZWEBEREcsojDQQy7ftZ+i0b/nop1047DZ8g+7GiG2HM3cP/O8+q8sTEZEGTGGknvP5DKZ/vYXRry5nT5aHdnERvH/LAO44/1RsI14Cmx1+egvWfWh1qSIi0kApjNRjh/IKufGNVTzz+UZ8Blx6Wgs+uWMQPZNizA1a9YNBd5rLH0+A7HSrShURkQZMYaSe+intEBf+awlfbcjA5bTz9KU9mDoymXDXEWOWz74fEk6F/APw0e0EbjIiIiJSQxRG6qF3V6Ux8qVl7DyUT+sm4Xxw6wCu7Nuq/JuWOV1w6SvgcMPmL2D1azVfsIiINGgKI/VIsdfHYx//yj3v/Uyh18d5XeP5+PZBdEuMPv6OzbqYN0MD+PxB2L+1+osVERHxUxipJw7mFjL2tZW89v1vAIw/tyMvX9ObqNCQkztAv1ugzZlQlAfv3wjFnuorVkREpBSFkXpg9Y6DXDz9e77fsp9wl4OXrjmNO8/rhN0exLNk7HYY8W8IjTGfXfP5g9VWr4iISGkKI3XYrkP53PHWGi7791JSD+SRFBvGvFsHcH735hU7YEwSXPqqufzDq/DLe1VXrIiIyDHodvB1UF5hMS99s41Xvt1KQZEPmw2u6J3E/cM60zjCVbmDd/ojnHk3fPcP+OgOSOgBTU+pmsJFRETKoTBShxiGwYJfdvPkgvXsziwAoG+bWCYP70r3FicYpBqMcx6A31fC9m/h7T/DTV+BO7Lqji8iIlKKwkgdsSUjh0c+Wsv3W/YD0LJxGA9c0IVh3RPKv2S3MuwOuGwmvHwm7NsIn9xpXv5b1e8jIiKCwkitl+sp5l9fbWbmku0UeQ1cTju3Dm7PzWe3JzTEUX1vHNkULn8NZl0Iv7wDzZNhwG3V934iItJgKYzUUj6fwfyUnTz9vw1kZJuX2Q7p0ozJF3WjVZPwmimidX8Y+iR8dj988RDEtoPOF9TMe4uISIOhMFIL/ZR2iEc//pU1qYcAaBUbziPDu3Jul/iaL6bfzbB3o3ln1vdvhOs/g+an1nwdIiJSbymM1CJZBUU88ck63ln1OwDhLge3/aEDNwxqi9tZjV0yx2OzwQXPwMHfYNvXMGeUOaA1qoKXD4uIiBxB9xmpJVbvOMgFz30XCCKX9mrB13cP5tbBHawLIiUcITByFsSdAtm74K0roTDX2ppERKTeUBixmNdn8PyizVzx8jJ+P5hPUmwY793cn2dH9SQ+KtTq8g4Li4HRb0N4E9idAu/fBN5iq6sSEZF6QGHEQumZBYx+dTlTF27C6zO4uGciC+44kz5tYq0urXyxbeHKOeYTfjcugA9vBZ/P6qpERKSOUxixSK6nmKv/s5wV2w8Q4XIwdWQy00b1PPkH21ml1Rlwxetgd8LPb8Ond4FhWF2ViIjUYQojFpn84a9s3ZtLfJSbT+44k8t6t6z6m5dVl1OGwSUvAzZYNRMWPqxAIiIiFaYwYoH3V//O+z/+jt0Gz13Zi7ZxEVaXFLwel8Of/mUuL30evvm7tfWIiEidpTBSw7Zk5PDwh2sBmDCkE2e0a2JxRZVw2hg4/2lzefFT8M0zaiEREZGgKYzUoIIiL7fN+ZG8Qi8D2jdh3DkdrC6p8s64Bf7wsLn89RPqshERkaApjNSgJxasY0N6Nk0iXEwb1ROHvY6METmRs+6GoU+Zy0ufh08mgM9raUkiIlJ3VCiMTJ8+nTZt2hAaGkq/fv1YuXLlMbcdPHgwNpvtqOnCCy+scNF10Ypt+3lzeSoA/xzVk2a16R4iVaH/OPjT84ANVs+CeX8Bb5HVVYmISB0QdBh5++23mThxIo888gg//vgjycnJDB06lIyMjHK3nzdvHrt37w5Ma9euxeFwMHLkyEoXX5e8t9q8s+rI3i05q1NTi6upJqeNgctnmJf9rn0P5l4NnhyrqxIRkVou6DDy7LPPctNNN3HdddfRtWtXXnrpJcLDw5k5c2a528fGxpKQkBCYFi5cSHh4eIMKIwVFXj77NR2Ay3u3tLiaatb9MrjyLXCGwubP4bVhkLXL6qpERKQWCyqMFBYWsnr1aoYMGXL4AHY7Q4YMYdmyZSd1jBkzZnDllVcSEXHsy1k9Hg9ZWVllprps8ca9ZBcU0zw6lNNr691Vq1KnP8LYjyE8DtJ/hlfPhd0/W12ViIjUUkGFkX379uH1eomPL/so+/j4eNLT00+4/8qVK1m7di033njjcbebMmUK0dHRgSkpKSmYMmudj37aCcDw5ETs9WXQ6okk9YUbv4S4TubD9WaeD5s+t7oqERGphWr0apoZM2bQo0cP+vbte9ztJk2aRGZmZmBKS0uroQqrXnZBEYvWm+Np/pScaHE1NSy2LdywENqeBUW55tN+v39Ol/6KiEgZQYWRuLg4HA4He/bsKbN+z549JCQkHHff3Nxc5s6dyw033HDC93G73URFRZWZ6qovft2Dp9hH+6YRdEusu5+jwsJi4Jp50OvPYPhg4WR4589QkGl1ZSIiUksEFUZcLhe9e/dm0aJFgXU+n49FixbRv3//4+777rvv4vF4uOaaaypWaR314U/m4M0/JbeoO8+eqWqOEPOy3wungj0E1n8MrwyG9LVWVyYiIrVA0N00EydO5NVXX+X1119n/fr13HLLLeTm5nLdddcBMGbMGCZNmnTUfjNmzGDEiBE0aVKHb38epH05Hr7fsg+AP/VsYF00R7LZ4PQb4frPIToJDmyD/wyBlLesrkxERCzmDHaHUaNGsXfvXiZPnkx6ejo9e/bks88+CwxqTU1NxW4vm3E2btzIkiVL+OKLL6qm6jri01924/UZJLeMrpsPw6sOLXvDX76BeTfC1q9g/s2wdRFc8A+zS0dERBocm2HU/tGEWVlZREdHk5mZWafGj1z276Ws3nGQhy7swo1ntrO6nNrF54XvpsLip8Hwmq0ll7wMbQZaXZmIiFSRk/3+1rNpqknagTxW7ziIzWZe0itHsDvg7HvNbpvGbSAzDWZdCF8+BsWFVlcnIiI1SGGkmnz8szlwtX+7JsTXt+fQVKWk0+HmJdDzasCAJc/Cf/4A6b9YXZmIiNQQhZFq8lFKyVU0ahU5IXcjGPEijHwdwhqbQeSVwbD4b3rYnohIA6AwUg3SDuSxIT0bh93G0G7Hv/+KlNJtBNy6AjpfBL5iWPwUvPoHXQIsIlLPKYxUgy/XmzeF69O6MY0jXBZXU8c0iodRb8Kl//G3kvwMr5wNXz4KhXlWVyciItVAYaQalISR87rGn2BLKZfNBqeOLNtKsuSf8OIZsHmh1dWJiEgVUxipYpn5RazYdgBQGKm0RvFw5Wy4cg5EtYRDO2D25fDOWMjaZXV1IiJSRRRGqtg3m/ZS7DPo2CyS1k10o7Mq0flCGLcC+t8GNgesmw/P9zYHuKrrRkSkzlMYqWJfrjO7aIaoVaRquSNh6JPwl8WQ1A+K8swBri/0gZ/eBp/P6gpFRKSCFEaqUJHXx9cbMwAY0kVhpFo0P9W8UdrlMyG6FWTthA/+Av85F7Z+DbX/hsIiInIEhZEq9MP2A2QXFBMX6aJnUozV5dRfNht0vwxuWwnnTgZXJOz6Ef47Al67AH5bYnWFIiISBIWRKrTQfxXNHzo3w2G3WVxNAxASBmfeBbf/CP1uBocbUpeat5V/fTjsWGp1hSIichIURqqIYRiBS3rVRVPDGsXDsL/BHWvg9BvBHgLbv4XXhsHM82HTF+q+ERGpxRRGqsjGPdmkHcjH7bQzqGOc1eU0TNEt4MKpcMeP0Ps6cLggdRnMGQkvnQm/vAfeYqurFBGRIyiMVJGSq2gGdYgj3OW0uJoGLqYVDJ8G43+GAbdDSATs+QXevwH+1RO+/xfkH7K4SBERKaEwUkUWrvdfRaNLemuPqObwxyfgzrUw+AEIbwKZabDwYXi2Kyy4G/ZttrpKEZEGT2GkCmRkFfBT2iEAzu3czNpi5GjhsTD4PrhzHfzpBWjWDYpy4YdXzfuUzDwfUuZAYa7VlYqINEgKI1Vg0QazVSQ5KYZmUaEWVyPHFBIKp/0ZbvkexnwInYaBzW6OK5l/C/zjFPh4PKSt1IBXEZEapMENVeArfxhRq0gdYbNBu8HmlLXLbBVZ8yYc3A6rZ5lTkw6QfCWcOsocgyIiItXGZhi1/ydgVlYW0dHRZGZmEhUVZXU5ZXiKvfR6fCF5hV4+uX0Q3VtEW12SVITPBzuWwJrZsP4j83bzJVoPgq5/gi7DISrRuhpFROqYk/3+VstIJa3cfoC8Qi/NGrnplli7gpIEwW6HtmeZk+cfsO4j+Okt+O07M6TsWAL/uxdang5d/gRdLoLYdlZXLSJSLyiMVFJJF83gU5pis+muq/WCuxH0utqcDqWawWT9R5C2An7/wZwWPgzNuppPFO58ITTvaXb/iIhI0BRGKulrfxj5g8aL1E8xrWDAbeaUtRs2fALrPjRvNZ+xzpy+fQaiWkCHIdDxPHMsiruR1ZWLiNQZCiOVsH1fLr/tzyPEYWNgB911td6Lag59bzKnvAOw+QvYsAC2fGk+PfjH183JHgKtzoAO50K7cyDhVLMbSEREyqUwUgklXTSnt4mlUWiIxdVIjQqPNa+2Sb4SivLht+9hy0IzoBzYZo41+e074FHzZmttz4b250CbM6FxG3XpiIiUojBSCeqiEcB8enDHIeY07G+wfytsXgjbvobflkDefvh1njkBRLWENoPMqfUAcyCswomINGAKIxWU6ylmxfb9AJyjMCKlNWlvTmfcDN4i+H2VGUy2f2suZ/0OP881J4CIZpDU1+zaSToDmieD02XtZxARqUEKIxW0ZMs+irwGrZuE0y4uwupypLZyhEDr/uZ0zgPmLefTVpotJr8tgV0/Qm6GOTB2wyfmPs5QSDzNDChJ/czLiSObWvs5RESqkcJIBZV00ZxzSjNd0isnzxVhjh1pf475d1EB7E6B1OXmlLYC8g9A6lJzKhHVEhJ7QmIvc968F0Q0seADiIhUPYWRCjAMg683+sOIumikMkJCze6ZVmeYfxsG7N9ihpK0FZC6AvZtMrt2sn4/3HoCEJ1kduk07+mfnwqNEiz5GCIilaEwUgHrdmexJ8tDWIiDfm1jrS5H6hObDeI6mlOva8x1nmzY/TPsWnN4OrAVMtPMqXRAiYw3LyVunnx4immlAbIiUqspjFRASRfNwA5NCA1xWFyN1HvuRtBmoDmVKMiC9J9hV4rZzbP7Z7MFJWePeYnxloWHtw1rbIaShB7QtAs06wxxp4A7sqY/iYhIuRRGKqDk/iLqohHLhEYdvjy4RGEu7PkVdv90OKBkrIf8g7BtsTmVFt0Kmp5SauoMcZ0gLKbmPoeICAojQcvMLyIl7RBgDl4VqTVcEf4rcPoeXlfsMW9ZvyvFf/v69bB3o3kFT2aqOZVuRQEIizXvfVIyNWl/eDlc3ZIiUvUURoK0fNt+fAa0axpBYkyY1eWIHJ/T7b8Cp1fZ9XkHYO8GM5js3Wgu79tk3tY+/wDsPAA7Vx19vLDGZiiJToKYJLN1JSbJHJcS01pdPyJSIQojQVq6ZR8AA9rrskqpw8Jjzbu/th5Qdr0nBw5uN29pf2CbeTfZA9vNAbPZu80un52rzanc4zYxQ0lMK4huaT5AMLqFOY9qYQ6w1XN6ROQICiNBWrrVvOvqwPZ6MJ7UQ+5Ic6BrQo+jXyvMNYPJwe1wyH8lz6FUOLTD/LvgkHnr+7z95s3cymMPgahEM6hEtzQvRY5MgEbx/rl/culGgiINSYXCyPTp03nmmWdIT08nOTmZ559/nr59+x5z+0OHDvHggw8yb948Dhw4QOvWrZk2bRoXXHBBhQu3QkZWAZszcrDZ4Ix2ahmRBsYVAQndzak8+YdKhZNUyNpldvtk7jTn2bvBV+R/fcfx38sd5Q8q8RDZDMLjIKIpRMSZU2S8+XdkPLjCq/yjikjNCjqMvP3220ycOJGXXnqJfv36MW3aNIYOHcrGjRtp1uzoAZ2FhYWcd955NGvWjPfee48WLVqwY8cOYmJiqqL+GrVsm9kq0rV5FI0j9OwQkTLCYsyp+anlv+4thpx0yPz98JSzB7LTD8+z06EoFzxZ5rRv04nf1xVpBpTwuMPz8FhzCjty3ticnO6q/OQiUklBh5Fnn32Wm266ieuuuw6Al156iQULFjBz5kzuv//+o7afOXMmBw4cYOnSpYSEhADQpk2bylVtke/940UGdlAXjUjQHM7D3TPH48n2B5Pd5jx3L+TuKzXPgJy95ry4AApzzOngbydfS0j44WAS1vhwYAlrDKHRZqgKjfZP/uWwxmaLjUO92yJVLaj/VxUWFrJ69WomTZoUWGe32xkyZAjLli0rd5+PPvqI/v37M27cOD788EOaNm3K6NGjue+++3A46s4NwwzD4PstZstIfw1eFak+7kbmFNfx+NsZhtl6krMX8vaZQSVvnzlmJXe/eVVQ3oFS84PmuBbDB0V55pS1M/j6XJFmKAmN8s+j/cuNSq2P9v8deXh7d6TZ1eXyr1OoEQkI6v8N+/btw+v1Eh8fX2Z9fHw8GzZsKHefbdu28dVXX3H11Vfz6aefsmXLFm699VaKiop45JFHyt3H4/Hg8XgCf2dlZQVTZrVIO5DPzkP5OO02+rbRvRZELGezHW69oMPJ7ePzmQEm/6AZUvIPQt7Bw4Gl4BAUZJrjXwoyy/5dlGseo6QlJntX5ep3hh0OXiVhxtXo6NBy5N+ucPPvkAj/ev+kriepw6o9mvt8Ppo1a8Yrr7yCw+Ggd+/e7Ny5k2eeeeaYYWTKlCk89thj1V1aUL7fanbR9EyKIcKtXzQidZLdfnhsC22D29db5A8o/smTZd6W/6h5ptnV5Mkx54U55nKhf52vyDxecb455WZU0WcLOdwSUxJQQsKPXg4JNwNN6TDjbuR/Lcx8PTD5/9bl2FLNgvpWjYuLw+FwsGfPnjLr9+zZQ0JC+U8Lbd68OSEhIWW6ZLp06UJ6ejqFhYW4XEcPBJ00aRITJ04M/J2VlUVSUlIwpVa5kkt6B2i8iEjD5Ag5fDVPZRR7/EElyx9Uss2pIOtwq4sn5/ByYe4Rf+eZ64pyzWWvvxXZV+Rv8TlY+c96pJJwUhJiAqEl7PCy68gQ45+cYebTqcudl94uVA90bMCCCiMul4vevXuzaNEiRowYAZgtH4sWLeK2224rd5+BAwcyZ84cfD4fdn+63rRpE82bNy83iAC43W7c7trT5GgYBsv8LSMDNV5ERCrD6TaniCr6b4m3yAwnRwaXIn9oKZlKwkvJ+qI8f7DJObx/Ub5/PI1/XqJkjE3escuoEs5Q//nxzx0lyy5z7vDPQ0JLbRtmzksCTbnzkmO5/HP34X1LgpFafywVdH/DxIkTGTt2LH369KFv375MmzaN3NzcwNU1Y8aMoUWLFkyZMgWAW265hRdeeIHx48dz++23s3nzZp566inuuOOOqv0k1Wjjnmz25RQSGmKnZ6sYq8sRETnMEVKq66kK+XxmN1Jhnj/IlAozRf4upqJ8f7DJPxxYCo94vWQqzjdbhYryzaugStaXdFuBub64AMis2s9yMhyuIwKLq/zA43Adnpwlc39oCgSdI0KV013OfqVCUen3dbgaZDAKOoyMGjWKvXv3MnnyZNLT0+nZsyefffZZYFBrampqoAUEICkpic8//5w777yTU089lRYtWjB+/Hjuu+++qvsU1Wyp/yqa09vE4nbWnSuAREQqzG4/PKaEptX3Pt7iw8GluACKC/1zz+EA4y29zlP2tdLhpvS8uACKCvzHLjC7s4oLD8+LC8oGIW+hORVW30c9aXZnqUAUVqolKNQMnw6XfxuX+XfJa2VakEoFHYfLvHrL4TLHFpUsH7lt4zbmJewWsBmGYVjyzkHIysoiOjqazMxMoqKiavz9b3z9B75cn8F953fmlsHta/z9RUSkGvi8ZUNLIPgcEYCK8g8HIG+hP9QUml1kxSVBp2QqFZpK1pe0AAX2O+I9vLUhAQGXvgqnXlGlhzzZ729dFnICxV4fK7YdAGBgB40XERGpN+yOUq0/FvL5DoeU0mElEG5KtfT4ig4HoUAYOjJAFR4dknxe/75F4CsuG5ZKJnfN/9gvoTByAr/szCTbU0xUqJNuidFWlyMiIvWN3Q52/8DcBqrhjZIJ0hfrzMuYz2jXBIddl52JiIhUtQYfRnI9xcd8bfOebGZ8tx2AEb1a1FRJIiIiDUqDDiMf/bSLs5/5mnW7jr7dvNdncN/7P1Po9fGHzs0Y1r38m7qJiIhI5TTYMOLzGbyx9Df25RRyzYwVbNqTXeb1N5b9xo+ph4h0O3liRHdsujOgiIhItWiwYcRutzHj2tPp0SKaA7mFjH51BVsycgBIO5DH3z/bCMD9wzqTGBNmZakiIiL1WoMNIwDRYSH894a+dG0exb4cD6NfXc72fbk88MEv5Bd56ds2ltF9W1ldpoiISL3WoMMIQEy4izdv7Mcp8Y3IyPYw/PklfLd5H26nnacv7YFdV9CIiIhUqwYfRgBiI1zMvqkfHZpFkuO/uubO8zrRrmmkxZWJiIjUfwojfnGRbubc2I8z2sVyQY8EbhzU1uqSREREGgTdgbWUZlGhzP1Lf6vLEBERaVDUMiIiIiKWUhgRERERSymMiIiIiKUURkRERMRSCiMiIiJiKYURERERsZTCiIiIiFhKYUREREQspTAiIiIillIYEREREUspjIiIiIilFEZERETEUgojIiIiYimFEREREbGU0+oCToZhGABkZWVZXImIiIicrJLv7ZLv8WOpE2EkOzsbgKSkJIsrERERkWBlZ2cTHR19zNdtxoniSi3g8/nYtWsXjRo1wmazVdlxs7KySEpKIi0tjaioqCo7rhxN57pm6XzXHJ3rmqNzXXOq6lwbhkF2djaJiYnY7cceGVInWkbsdjstW7astuNHRUXpf9g1ROe6Zul81xyd65qjc11zquJcH69FpIQGsIqIiIilFEZERETEUg06jLjdbh555BHcbrfVpdR7Otc1S+e75uhc1xyd65pT0+e6TgxgFRERkfqrQbeMiIiIiPUURkRERMRSCiMiIiJiKYURERERsVSDDiPTp0+nTZs2hIaG0q9fP1auXGl1SXXelClTOP3002nUqBHNmjVjxIgRbNy4scw2BQUFjBs3jiZNmhAZGclll13Gnj17LKq4/nj66aex2WxMmDAhsE7nuurs3LmTa665hiZNmhAWFkaPHj1YtWpV4HXDMJg8eTLNmzcnLCyMIUOGsHnzZgsrrpu8Xi8PP/wwbdu2JSwsjPbt2/PXv/61zLNNdK4r5ttvv2X48OEkJiZis9mYP39+mddP5rweOHCAq6++mqioKGJiYrjhhhvIycmpfHFGAzV37lzD5XIZM2fONH799VfjpptuMmJiYow9e/ZYXVqdNnToUOO1114z1q5da6SkpBgXXHCB0apVKyMnJyewzc0332wkJSUZixYtMlatWmWcccYZxoABAyysuu5buXKl0aZNG+PUU081xo8fH1ivc101Dhw4YLRu3dq49tprjRUrVhjbtm0zPv/8c2PLli2BbZ5++mkjOjramD9/vvHTTz8Zf/rTn4y2bdsa+fn5FlZe9zz55JNGkyZNjE8++cTYvn278e677xqRkZHGc889F9hG57piPv30U+PBBx805s2bZwDGBx98UOb1kzmv559/vpGcnGwsX77c+O6774wOHToYV111VaVra7BhpG/fvsa4ceMCf3u9XiMxMdGYMmWKhVXVPxkZGQZgfPPNN4ZhGMahQ4eMkJAQ49133w1ss379egMwli1bZlWZdVp2drbRsWNHY+HChcbZZ58dCCM611XnvvvuMwYNGnTM130+n5GQkGA888wzgXWHDh0y3G638dZbb9VEifXGhRdeaFx//fVl1l166aXG1VdfbRiGznVVOTKMnMx5XbdunQEYP/zwQ2Cb//3vf4bNZjN27txZqXoaZDdNYWEhq1evZsiQIYF1drudIUOGsGzZMgsrq38yMzMBiI2NBWD16tUUFRWVOfedO3emVatWOvcVNG7cOC688MIy5xR0rqvSRx99RJ8+fRg5ciTNmjWjV69evPrqq4HXt2/fTnp6eplzHR0dTb9+/XSugzRgwAAWLVrEpk2bAPjpp59YsmQJw4YNA3Suq8vJnNdly5YRExNDnz59AtsMGTIEu93OihUrKvX+deJBeVVt3759eL1e4uPjy6yPj49nw4YNFlVV//h8PiZMmMDAgQPp3r07AOnp6bhcLmJiYspsGx8fT3p6ugVV1m1z587lxx9/5IcffjjqNZ3rqrNt2zb+/e9/M3HiRB544AF++OEH7rjjDlwuF2PHjg2cz/L+m6JzHZz777+frKwsOnfujMPhwOv18uSTT3L11VcD6FxXk5M5r+np6TRr1qzM606nk9jY2Eqf+wYZRqRmjBs3jrVr17JkyRKrS6mX0tLSGD9+PAsXLiQ0NNTqcuo1n89Hnz59eOqppwDo1asXa9eu5aWXXmLs2LEWV1e/vPPOO8yePZs5c+bQrVs3UlJSmDBhAomJiTrX9ViD7KaJi4vD4XAcdVXBnj17SEhIsKiq+uW2227jk08+4euvv6Zly5aB9QkJCRQWFnLo0KEy2+vcB2/16tVkZGRw2mmn4XQ6cTqdfPPNN/zrX//C6XQSHx+vc11FmjdvTteuXcus69KlC6mpqQCB86n/plTePffcw/3338+VV15Jjx49+POf/8ydd97JlClTAJ3r6nIy5zUhIYGMjIwyrxcXF3PgwIFKn/sGGUZcLhe9e/dm0aJFgXU+n49FixbRv39/Cyur+wzD4LbbbuODDz7gq6++om3btmVe7927NyEhIWXO/caNG0lNTdW5D9K5557LL7/8QkpKSmDq06cPV199dWBZ57pqDBw48KhL1Ddt2kTr1q0BaNu2LQkJCWXOdVZWFitWrNC5DlJeXh52e9mvJofDgc/nA3Suq8vJnNf+/ftz6NAhVq9eHdjmq6++wufz0a9fv8oVUKnhr3XY3LlzDbfbbcyaNctYt26d8Ze//MWIiYkx0tPTrS6tTrvllluM6OhoY/Hixcbu3bsDU15eXmCbm2++2WjVqpXx1VdfGatWrTL69+9v9O/f38Kq64/SV9MYhs51VVm5cqXhdDqNJ5980ti8ebMxe/ZsIzw83HjzzTcD2zz99NNGTEyM8eGHHxo///yzcfHFF+ty0woYO3as0aJFi8ClvfPmzTPi4uKMe++9N7CNznXFZGdnG2vWrDHWrFljAMazzz5rrFmzxtixY4dhGCd3Xs8//3yjV69exooVK4wlS5YYHTt21KW9lfX8888brVq1Mlwul9G3b19j+fLlVpdU5wHlTq+99lpgm/z8fOPWW281GjdubISHhxuXXHKJsXv3buuKrkeODCM611Xn448/Nrp372643W6jc+fOxiuvvFLmdZ/PZzz88MNGfHy84Xa7jXPPPdfYuHGjRdXWXVlZWcb48eONVq1aGaGhoUa7du2MBx980PB4PIFtdK4r5uuvvy73v89jx441DOPkzuv+/fuNq666yoiMjDSioqKM6667zsjOzq50bTbDKHVbOxEREZEa1iDHjIiIiEjtoTAiIiIillIYEREREUspjIiIiIilFEZERETEUgojIiIiYimFEREREbGUwoiI1DmLFy/GZrMd9dwdEambFEZERETEUgojIiIiYimFEREJms/nY8qUKbRt25awsDCSk5N57733gMNdKAsWLODUU08lNDSUM844g7Vr15Y5xvvvv0+3bt1wu920adOGqVOnlnnd4/Fw3333kZSUhNvtpkOHDsyYMaPMNqtXr6ZPnz6Eh4czYMCAo56sKyJ1g8KIiARtypQpvPHGG7z00kv8+uuv3HnnnVxzzTV88803gW3uuecepk6dyg8//EDTpk0ZPnw4RUVFgBkirrjiCq688kp++eUXHn30UR5++GFmzZoV2H/MmDG89dZb/Otf/2L9+vW8/PLLREZGlqnjwQcfZOrUqaxatQqn08n1119fI59fRKpYpR+1JyINSkFBgREeHm4sXbq0zPobbrjBuOqqqwJPBp07d27gtf379xthYWHG22+/bRiGYYwePdo477zzyux/zz33GF27djUMwzA2btxoAMbChQvLraHkPb788svAugULFhiAHiMvUgepZUREgrJlyxby8vI477zziIyMDExvvPEGW7duDWzXv3//wHJsbCynnHIK69evB2D9+vUMHDiwzHEHDhzI5s2b8Xq9pKSk4HA4OPvss49by6mnnhpYbt68OQAZGRmV/owiUrOcVhcgInVLTk4OAAsWLKBFixZlXnO73WUCSUWFhYWd1HYhISGBZZvNBpjjWUSkblHLiIgEpWvXrrjdblJTU+nQoUOZKSkpKbDd8uXLA8sHDx5k06ZNdOnSBYAuXbrw/ffflznu999/T6dOnXA4HPTo0QOfz1dmDIqI1F9qGRGRoDRq1Ii7776bO++8E5/Px6BBg8jMzOT7778nKiqK1q1bA/D444/TpEkT4uPjefDBB4mLi2PEiBEA3HXXXZx++un89a9/ZdSoUSxbtowXXniBF198EYA2bdowduxYrr/+ev71r3+RnJzMjh07yMjI4IorrrDqo4tINVEYEZGg/fWvf6Vp06ZMmTKFbdu2ERMTw2mnncYDDzwQ6CZ5+umnGT9+PJs3b6Znz558/PHHuFwuAE477TTeeecdJk+ezF//+leaN2/O448/zrXXXht4j3//+9888MAD3Hrrrezfv59WrVrxwAMPWPFxRaSa2QzDMKwuQkTqj8WLF3POOedw8OBBYmJirC5HROoAjRkRERERSymMiIiIiKXUTSMiIiKWUsuIiIiIWEphRERERCylMCIiIiKWUhgRERERSymMiIiIiKUURkRERMRSCiMiIiJiKYURERERsZTCiIiIiFjq/wEgYn9xlGhyiQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(training.history['auc'])\n",
        "plt.plot(training.history['loss'])\n",
        "plt.title('ROC AUC')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['ROC AUC', 'loss'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmRziSOO4Jlm"
      },
      "source": [
        "##Evaluate on train set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqhDsbwKIvmB"
      },
      "source": [
        "###`predict` gives list of lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCoX4hcp4Jlm",
        "outputId": "7aa7936f-b4a5-4429-93cf-17ecefc25fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47342908, 0.31570902, 0.7469393 , 0.76173514, 0.21468766],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "yraw = ann_model.predict(x_train)[:,0]  #pull out prob of 1\n",
        "yraw[:5]  #array([0.47342908, 0.31570902, 0.7469393 , 0.76173514, 0.21468766], dtype=float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHs7ZYcQ4Jlm",
        "outputId": "70104580-4d51-47c3-abca-c188d6a0e6b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.7438095238095238)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "binary = [1 if y>.5 else 0 for y in yraw]  #use normal threshold of .5\n",
        "sum([x==y for x,y in zip(binary,y_train)])/len(binary)  #0.7438095238095238 accuracy on training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icr1yxgRNjZU"
      },
      "source": [
        "##Evaluate on test set\n",
        "\n",
        "There is no `score` method. And `predict_proba` has been replaced with just `predict`. And `predict` just gives you probabilities of 1 (positive case)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPQpadYUKgLR",
        "outputId": "3038bd98-69eb-476c-86fc-9053e9303a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5388105 , 0.7720659 , 0.8347173 , 0.22516692, 0.3030476 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "yraw = ann_model.predict(x_test)[:,0]  #replaces predict_proba\n",
        "yraw[:5]  #[0.5388105 , 0.7720659 , 0.8347173 , 0.22516692, 0.3030476 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "AZveEpdV5o-j",
        "outputId": "8a114edd-fac1-489c-fc3f-b16134fdc032"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7927902f0810>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_de9f5 th:not(.index_name) {\n",
              "  background-color: #800000;\n",
              "  color: white;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_de9f5_row0_col0, #T_de9f5_row0_col1, #T_de9f5_row0_col3, #T_de9f5_row0_col5, #T_de9f5_row1_col0, #T_de9f5_row1_col1, #T_de9f5_row1_col3, #T_de9f5_row1_col5, #T_de9f5_row2_col0, #T_de9f5_row2_col1, #T_de9f5_row2_col3, #T_de9f5_row2_col5, #T_de9f5_row3_col0, #T_de9f5_row3_col1, #T_de9f5_row3_col2, #T_de9f5_row3_col3, #T_de9f5_row3_col5, #T_de9f5_row4_col0, #T_de9f5_row4_col1, #T_de9f5_row4_col2, #T_de9f5_row4_col3, #T_de9f5_row4_col5, #T_de9f5_row5_col0, #T_de9f5_row5_col1, #T_de9f5_row5_col2, #T_de9f5_row5_col3, #T_de9f5_row5_col5, #T_de9f5_row6_col0, #T_de9f5_row6_col1, #T_de9f5_row6_col2, #T_de9f5_row6_col5, #T_de9f5_row7_col0, #T_de9f5_row7_col1, #T_de9f5_row7_col2, #T_de9f5_row7_col3, #T_de9f5_row7_col5, #T_de9f5_row8_col0, #T_de9f5_row8_col1, #T_de9f5_row8_col2, #T_de9f5_row8_col3, #T_de9f5_row8_col5, #T_de9f5_row9_col0, #T_de9f5_row9_col1, #T_de9f5_row9_col2, #T_de9f5_row9_col3, #T_de9f5_row9_col5, #T_de9f5_row10_col0, #T_de9f5_row10_col1, #T_de9f5_row10_col2, #T_de9f5_row10_col3, #T_de9f5_row10_col5, #T_de9f5_row11_col0, #T_de9f5_row11_col1, #T_de9f5_row11_col2, #T_de9f5_row11_col3, #T_de9f5_row11_col5, #T_de9f5_row12_col0, #T_de9f5_row12_col1, #T_de9f5_row12_col2, #T_de9f5_row12_col3, #T_de9f5_row13_col0, #T_de9f5_row13_col1, #T_de9f5_row13_col2, #T_de9f5_row13_col3, #T_de9f5_row13_col5, #T_de9f5_row14_col0, #T_de9f5_row14_col1, #T_de9f5_row14_col2, #T_de9f5_row14_col3, #T_de9f5_row14_col5, #T_de9f5_row15_col0, #T_de9f5_row15_col1, #T_de9f5_row15_col2, #T_de9f5_row15_col3, #T_de9f5_row15_col5, #T_de9f5_row16_col0, #T_de9f5_row16_col2, #T_de9f5_row16_col3, #T_de9f5_row16_col5, #T_de9f5_row17_col0, #T_de9f5_row17_col1, #T_de9f5_row17_col2, #T_de9f5_row17_col3, #T_de9f5_row17_col5, #T_de9f5_row18_col0, #T_de9f5_row18_col1, #T_de9f5_row18_col2, #T_de9f5_row18_col3, #T_de9f5_row18_col5, #T_de9f5_row19_col0, #T_de9f5_row19_col1, #T_de9f5_row19_col2, #T_de9f5_row19_col3, #T_de9f5_row19_col5, #T_de9f5_row20_col1, #T_de9f5_row20_col2, #T_de9f5_row20_col3, #T_de9f5_row20_col5 {\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_de9f5_row0_col2, #T_de9f5_row0_col4, #T_de9f5_row1_col2, #T_de9f5_row1_col4, #T_de9f5_row2_col2, #T_de9f5_row2_col4, #T_de9f5_row3_col4, #T_de9f5_row4_col4, #T_de9f5_row5_col4, #T_de9f5_row6_col3, #T_de9f5_row6_col4, #T_de9f5_row7_col4, #T_de9f5_row8_col4, #T_de9f5_row9_col4, #T_de9f5_row10_col4, #T_de9f5_row11_col4, #T_de9f5_row12_col4, #T_de9f5_row12_col5, #T_de9f5_row13_col4, #T_de9f5_row14_col4, #T_de9f5_row15_col4, #T_de9f5_row16_col1, #T_de9f5_row16_col4, #T_de9f5_row17_col4, #T_de9f5_row18_col4, #T_de9f5_row19_col4, #T_de9f5_row20_col0, #T_de9f5_row20_col4 {\n",
              "  background-color: pink;\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_de9f5\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_de9f5_level0_col0\" class=\"col_heading level0 col0\" >threshold</th>\n",
              "      <th id=\"T_de9f5_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
              "      <th id=\"T_de9f5_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
              "      <th id=\"T_de9f5_level0_col3\" class=\"col_heading level0 col3\" >f1</th>\n",
              "      <th id=\"T_de9f5_level0_col4\" class=\"col_heading level0 col4\" >auc</th>\n",
              "      <th id=\"T_de9f5_level0_col5\" class=\"col_heading level0 col5\" >accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_de9f5_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
              "      <td id=\"T_de9f5_row0_col1\" class=\"data row0 col1\" >0.43</td>\n",
              "      <td id=\"T_de9f5_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
              "      <td id=\"T_de9f5_row0_col3\" class=\"data row0 col3\" >0.60</td>\n",
              "      <td id=\"T_de9f5_row0_col4\" class=\"data row0 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row0_col5\" class=\"data row0 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_de9f5_row1_col0\" class=\"data row1 col0\" >0.05</td>\n",
              "      <td id=\"T_de9f5_row1_col1\" class=\"data row1 col1\" >0.43</td>\n",
              "      <td id=\"T_de9f5_row1_col2\" class=\"data row1 col2\" >1.00</td>\n",
              "      <td id=\"T_de9f5_row1_col3\" class=\"data row1 col3\" >0.60</td>\n",
              "      <td id=\"T_de9f5_row1_col4\" class=\"data row1 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row1_col5\" class=\"data row1 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_de9f5_row2_col0\" class=\"data row2 col0\" >0.10</td>\n",
              "      <td id=\"T_de9f5_row2_col1\" class=\"data row2 col1\" >0.43</td>\n",
              "      <td id=\"T_de9f5_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
              "      <td id=\"T_de9f5_row2_col3\" class=\"data row2 col3\" >0.60</td>\n",
              "      <td id=\"T_de9f5_row2_col4\" class=\"data row2 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row2_col5\" class=\"data row2 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_de9f5_row3_col0\" class=\"data row3 col0\" >0.15</td>\n",
              "      <td id=\"T_de9f5_row3_col1\" class=\"data row3 col1\" >0.45</td>\n",
              "      <td id=\"T_de9f5_row3_col2\" class=\"data row3 col2\" >0.99</td>\n",
              "      <td id=\"T_de9f5_row3_col3\" class=\"data row3 col3\" >0.62</td>\n",
              "      <td id=\"T_de9f5_row3_col4\" class=\"data row3 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row3_col5\" class=\"data row3 col5\" >0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_de9f5_row4_col0\" class=\"data row4 col0\" >0.20</td>\n",
              "      <td id=\"T_de9f5_row4_col1\" class=\"data row4 col1\" >0.47</td>\n",
              "      <td id=\"T_de9f5_row4_col2\" class=\"data row4 col2\" >0.94</td>\n",
              "      <td id=\"T_de9f5_row4_col3\" class=\"data row4 col3\" >0.62</td>\n",
              "      <td id=\"T_de9f5_row4_col4\" class=\"data row4 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row4_col5\" class=\"data row4 col5\" >0.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_de9f5_row5_col0\" class=\"data row5 col0\" >0.25</td>\n",
              "      <td id=\"T_de9f5_row5_col1\" class=\"data row5 col1\" >0.51</td>\n",
              "      <td id=\"T_de9f5_row5_col2\" class=\"data row5 col2\" >0.91</td>\n",
              "      <td id=\"T_de9f5_row5_col3\" class=\"data row5 col3\" >0.66</td>\n",
              "      <td id=\"T_de9f5_row5_col4\" class=\"data row5 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row5_col5\" class=\"data row5 col5\" >0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_de9f5_row6_col0\" class=\"data row6 col0\" >0.30</td>\n",
              "      <td id=\"T_de9f5_row6_col1\" class=\"data row6 col1\" >0.59</td>\n",
              "      <td id=\"T_de9f5_row6_col2\" class=\"data row6 col2\" >0.87</td>\n",
              "      <td id=\"T_de9f5_row6_col3\" class=\"data row6 col3\" >0.70</td>\n",
              "      <td id=\"T_de9f5_row6_col4\" class=\"data row6 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row6_col5\" class=\"data row6 col5\" >0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_de9f5_row7_col0\" class=\"data row7 col0\" >0.35</td>\n",
              "      <td id=\"T_de9f5_row7_col1\" class=\"data row7 col1\" >0.62</td>\n",
              "      <td id=\"T_de9f5_row7_col2\" class=\"data row7 col2\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row7_col3\" class=\"data row7 col3\" >0.69</td>\n",
              "      <td id=\"T_de9f5_row7_col4\" class=\"data row7 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row7_col5\" class=\"data row7 col5\" >0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_de9f5_row8_col0\" class=\"data row8 col0\" >0.40</td>\n",
              "      <td id=\"T_de9f5_row8_col1\" class=\"data row8 col1\" >0.66</td>\n",
              "      <td id=\"T_de9f5_row8_col2\" class=\"data row8 col2\" >0.71</td>\n",
              "      <td id=\"T_de9f5_row8_col3\" class=\"data row8 col3\" >0.68</td>\n",
              "      <td id=\"T_de9f5_row8_col4\" class=\"data row8 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row8_col5\" class=\"data row8 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_de9f5_row9_col0\" class=\"data row9 col0\" >0.45</td>\n",
              "      <td id=\"T_de9f5_row9_col1\" class=\"data row9 col1\" >0.70</td>\n",
              "      <td id=\"T_de9f5_row9_col2\" class=\"data row9 col2\" >0.61</td>\n",
              "      <td id=\"T_de9f5_row9_col3\" class=\"data row9 col3\" >0.65</td>\n",
              "      <td id=\"T_de9f5_row9_col4\" class=\"data row9 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row9_col5\" class=\"data row9 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_de9f5_row10_col0\" class=\"data row10 col0\" >0.50</td>\n",
              "      <td id=\"T_de9f5_row10_col1\" class=\"data row10 col1\" >0.72</td>\n",
              "      <td id=\"T_de9f5_row10_col2\" class=\"data row10 col2\" >0.55</td>\n",
              "      <td id=\"T_de9f5_row10_col3\" class=\"data row10 col3\" >0.62</td>\n",
              "      <td id=\"T_de9f5_row10_col4\" class=\"data row10 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row10_col5\" class=\"data row10 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_de9f5_row11_col0\" class=\"data row11 col0\" >0.55</td>\n",
              "      <td id=\"T_de9f5_row11_col1\" class=\"data row11 col1\" >0.76</td>\n",
              "      <td id=\"T_de9f5_row11_col2\" class=\"data row11 col2\" >0.52</td>\n",
              "      <td id=\"T_de9f5_row11_col3\" class=\"data row11 col3\" >0.61</td>\n",
              "      <td id=\"T_de9f5_row11_col4\" class=\"data row11 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row11_col5\" class=\"data row11 col5\" >0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_de9f5_row12_col0\" class=\"data row12 col0\" >0.60</td>\n",
              "      <td id=\"T_de9f5_row12_col1\" class=\"data row12 col1\" >0.91</td>\n",
              "      <td id=\"T_de9f5_row12_col2\" class=\"data row12 col2\" >0.44</td>\n",
              "      <td id=\"T_de9f5_row12_col3\" class=\"data row12 col3\" >0.59</td>\n",
              "      <td id=\"T_de9f5_row12_col4\" class=\"data row12 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row12_col5\" class=\"data row12 col5\" >0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_de9f5_row13_col0\" class=\"data row13 col0\" >0.65</td>\n",
              "      <td id=\"T_de9f5_row13_col1\" class=\"data row13 col1\" >0.92</td>\n",
              "      <td id=\"T_de9f5_row13_col2\" class=\"data row13 col2\" >0.39</td>\n",
              "      <td id=\"T_de9f5_row13_col3\" class=\"data row13 col3\" >0.54</td>\n",
              "      <td id=\"T_de9f5_row13_col4\" class=\"data row13 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row13_col5\" class=\"data row13 col5\" >0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_de9f5_row14_col0\" class=\"data row14 col0\" >0.70</td>\n",
              "      <td id=\"T_de9f5_row14_col1\" class=\"data row14 col1\" >0.91</td>\n",
              "      <td id=\"T_de9f5_row14_col2\" class=\"data row14 col2\" >0.37</td>\n",
              "      <td id=\"T_de9f5_row14_col3\" class=\"data row14 col3\" >0.52</td>\n",
              "      <td id=\"T_de9f5_row14_col4\" class=\"data row14 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row14_col5\" class=\"data row14 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_de9f5_row15_col0\" class=\"data row15 col0\" >0.75</td>\n",
              "      <td id=\"T_de9f5_row15_col1\" class=\"data row15 col1\" >0.92</td>\n",
              "      <td id=\"T_de9f5_row15_col2\" class=\"data row15 col2\" >0.32</td>\n",
              "      <td id=\"T_de9f5_row15_col3\" class=\"data row15 col3\" >0.47</td>\n",
              "      <td id=\"T_de9f5_row15_col4\" class=\"data row15 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row15_col5\" class=\"data row15 col5\" >0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_de9f5_row16_col0\" class=\"data row16 col0\" >0.80</td>\n",
              "      <td id=\"T_de9f5_row16_col1\" class=\"data row16 col1\" >0.96</td>\n",
              "      <td id=\"T_de9f5_row16_col2\" class=\"data row16 col2\" >0.21</td>\n",
              "      <td id=\"T_de9f5_row16_col3\" class=\"data row16 col3\" >0.35</td>\n",
              "      <td id=\"T_de9f5_row16_col4\" class=\"data row16 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row16_col5\" class=\"data row16 col5\" >0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_de9f5_row17_col0\" class=\"data row17 col0\" >0.85</td>\n",
              "      <td id=\"T_de9f5_row17_col1\" class=\"data row17 col1\" >0.93</td>\n",
              "      <td id=\"T_de9f5_row17_col2\" class=\"data row17 col2\" >0.11</td>\n",
              "      <td id=\"T_de9f5_row17_col3\" class=\"data row17 col3\" >0.20</td>\n",
              "      <td id=\"T_de9f5_row17_col4\" class=\"data row17 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row17_col5\" class=\"data row17 col5\" >0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_de9f5_row18_col0\" class=\"data row18 col0\" >0.90</td>\n",
              "      <td id=\"T_de9f5_row18_col1\" class=\"data row18 col1\" >0.50</td>\n",
              "      <td id=\"T_de9f5_row18_col2\" class=\"data row18 col2\" >0.01</td>\n",
              "      <td id=\"T_de9f5_row18_col3\" class=\"data row18 col3\" >0.02</td>\n",
              "      <td id=\"T_de9f5_row18_col4\" class=\"data row18 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row18_col5\" class=\"data row18 col5\" >0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_de9f5_row19_col0\" class=\"data row19 col0\" >0.95</td>\n",
              "      <td id=\"T_de9f5_row19_col1\" class=\"data row19 col1\" >0.00</td>\n",
              "      <td id=\"T_de9f5_row19_col2\" class=\"data row19 col2\" >0.00</td>\n",
              "      <td id=\"T_de9f5_row19_col3\" class=\"data row19 col3\" >0.00</td>\n",
              "      <td id=\"T_de9f5_row19_col4\" class=\"data row19 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row19_col5\" class=\"data row19 col5\" >0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_de9f5_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_de9f5_row20_col0\" class=\"data row20 col0\" >1.00</td>\n",
              "      <td id=\"T_de9f5_row20_col1\" class=\"data row20 col1\" >0.00</td>\n",
              "      <td id=\"T_de9f5_row20_col2\" class=\"data row20 col2\" >0.00</td>\n",
              "      <td id=\"T_de9f5_row20_col3\" class=\"data row20 col3\" >0.00</td>\n",
              "      <td id=\"T_de9f5_row20_col4\" class=\"data row20 col4\" >0.79</td>\n",
              "      <td id=\"T_de9f5_row20_col5\" class=\"data row20 col5\" >0.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "result_df, fancy_df = threshold_results(np.round(np.arange(0.0,1.01,.05), 2), y_test, yraw)\n",
        "fancy_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agVPpWkS4nlt"
      },
      "source": [
        "#II. Getting ready for tuning\n",
        "\n",
        "We cannot use sklearn HalvingSearchCV here, at least not directly.\n",
        "\n",
        "It is more complicated, sigh.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOSl-q_r_JKL"
      },
      "source": [
        "##We need to package up ANN building\n",
        "\n",
        "There are two approaches to tuning an ANN. One involves sklearn. The good news is that we should be able to use the same tuning method, halving search. The bad news is that tensorflow and sklearn are two different libraries. So we would have to employ yet a 3rd library to get them to talk together:\n",
        "\n",
        "<pre>\n",
        "try:\n",
        "    import scikeras\n",
        "except ImportError:\n",
        "    !python -m pip install scikeras\n",
        "</pre>\n",
        "\n",
        "I find this library confusing. Too many moving parts to glue things together. As an alternative, tensorflow has a tuner built just for it. The good news is we do not have to glue libraries together. The bad news it is still complicated to use. But I still find it slighly easier to use than `scikeras`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgWauy1Ne50o",
        "outputId": "02a76461-2dd6-4bb5-a687-da22256cc109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m102.4/129.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#tuner library we will use\n",
        "!pip install keras-tuner -q\n",
        "import keras_tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ya2Vlo75WH"
      },
      "source": [
        "###If we are going to tune we need choices\n",
        "\n",
        "The obvious choices are how many layers and for each layer, how many nodes.\n",
        "The one new choice I will add is for the activation function. I will do tuning on both relu (seen in last chapter) and leaky-relu. You can see below that the \"leak\" is for negative values - it does not map them automatically to 0 but gives them a small, scaled, negative contribution. This addresses a problem with relu, which has a tendency to eventually map all weights to 0, AKA the vanishing gradient. You cannot do learning with weights of 0.\n",
        "\n",
        "<pre>\n",
        "def leakyrelu(A,x):\n",
        "  return A*x if x<0 else x\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLLRL3w42y2a"
      },
      "source": [
        "###Add a new choice for activation function\n",
        "\n",
        "<img src='https://www.dropbox.com/scl/fi/zbosbh712w3zd9daqbzj2/Screenshot-2023-09-26-at-4.38.30-PM.png?rlkey=cqjzxengplxm10ctog7jp82zw&raw=1'>\n",
        "\n",
        "\n",
        "[More discussion on these choices among others](https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/#case-3-leaky-relu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq7vNxim9VH6"
      },
      "source": [
        "##Ok, here is where you need to buckle up\n",
        "\n",
        "We need to define a function that will construct, compile and return an ANN model. The trick is, we will parameterize model building within the function body (as opposed to passing in a large parameter list).\n",
        "\n",
        "The class `hp` comes with `keras_tuner` and stands for hyperparameters. What it gives us is a set of methods for laying out alternative choices. In essence, it replaces the `param_grid` we have been using up until now.\n",
        "\n",
        "I think it is more confusing than the `param_grid`, but it is what is built-in to `keras_tuner`.\n",
        "\n",
        "Let me show you a few things we will use in our new function:\n",
        "\n",
        "<pre>\n",
        "units=hp.Int(f\"hidden_units{i}\", min_value=min_units, max_value=max_units, step=step_units)\n",
        "</pre>\n",
        "This is the `Int` method. It allows you to set up choices. I suppose it would be a bit like using `range` in `param_grid` to set up choices. Notice I have to give it a name, i.e., \"hidden_units{i}\". The name has to be unique, hence I added the `{i}`. Here is the confusing part, at least to me: you cannot read it as literal code. You read it as when we are tuning, we will try various combinations of values. `Int` will give a different random value each time we take a tuning step (called a trial). So it is like `build` will be called over and over again, once for each tuning step. And we will get a random value each time it is called from this line of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX4jb1v0OvgA"
      },
      "source": [
        "##Need to build a class\n",
        "\n",
        "The main workhorse is the `build` method. The constructor is used to set up bounds on our choices. Note that differs from video. Here, I am passing in bounds, whereas in the video, I had them hard-coded.\n",
        "\n",
        "Notice that each layer is basically the same format with slight changes so I can use a loop to build them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EY1AbKB7JeV_"
      },
      "outputs": [],
      "source": [
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "  def __init__(self, n=6, metrics='auc',\n",
        "                      layers=(1,5,1),   #1 to 5 by 1\n",
        "                      units=(2,16,1),   #2 to 16 by 1\n",
        "                      afn_list=('relu', 'leaky_relu')):\n",
        "    self.n = n #number of features\n",
        "    self.metrics = metrics\n",
        "    self.units = units\n",
        "    self.layers = layers\n",
        "    self.afn_list = afn_list\n",
        "\n",
        "  def build(self, hp):\n",
        "\n",
        "    n = self.n\n",
        "    metrics = self.metrics\n",
        "    min_units = self.units[0]\n",
        "    max_units = self.units[1]\n",
        "    step_units = self.units[2]\n",
        "\n",
        "    min_layers = self.layers[0]\n",
        "    max_layers = self.layers[1]\n",
        "    step_layers = self.layers[2]\n",
        "\n",
        "    n_afns = len(self.afn_list)\n",
        "\n",
        "    ann_model = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    ann_model.add(Input(shape=(n,), name=\"input_layer\"))\n",
        "\n",
        "    #add one or more new hidden layers\n",
        "    layers = hp.Int(\"layers\", min_value=min_layers, max_value=max_layers, step=step_layers)\n",
        "    for i in range(layers):\n",
        "      layer_name = f\"hidden_layer_{i}\"\n",
        "      ann_model.add(Dense(\n",
        "                  name=layer_name+'_dense',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(0.01),  #fixed but could be tuned\n",
        "                  kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense')),\n",
        "\n",
        "                  # Tune number of units.\n",
        "                  units=hp.Int(f\"hidden_units{i}\", min_value=min_units, max_value=max_units, step=step_units),\n",
        "\n",
        "                  # Tune the activation function to use.\n",
        "                  activation= self.afn_list[hp.Int(f'afn{i}', min_value=0, max_value=n_afns-1, step=1)],\n",
        "      ))\n",
        "\n",
        "    #now output layer\n",
        "    ann_model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    ann_model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=.1),  #fixed but could be tuned\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001),           #fixed but could be tuned\n",
        "                  metrics=['auc', 'accuracy']\n",
        ")\n",
        "    return ann_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOttFoZPAsg"
      },
      "source": [
        "##Discussion\n",
        "\n",
        "In essence, the build method is called for each new trial, i.e., each new choice from the configurations. The hp choice methods randomly choose values.\n",
        "\n",
        "I hope you can see where I am making choices by looking for the hp methods. Could I have made more choices? Sure. I could have chosen the  (reverse) lambda value. So up to you to decide how much you want to tune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRO1gVqFTkBe"
      },
      "source": [
        "###Search space\n",
        "\n",
        "I was trying roughly calculate how many unique configurations are possible with the build method above. My notes:\n",
        "\n",
        "* Each layer has `15x2=30` configurations.\n",
        "\n",
        "* There are 5 layers possible.\n",
        "\n",
        "* I came up with `30**5=24,300,000`. Caveat: it is really more given I should be summing `30**1 + 30**2 + 30**3 + ...30**5` given the `layers` choice.\n",
        "\n",
        "Yikes! That's a big space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UZNJfBf7Ka0"
      },
      "source": [
        "#Choice of search algorithm\n",
        "\n",
        "Ok, we now have our model generator set up with choice points. So this is similar to having `param_grid` set up in prior chapters. The next question is how we want to search this space for best combos.\n",
        "`keras_tuner` offers us 3 alternatives and one of them is similar to halving search: Hyperband. But I thought I would change things up a bit, and try a new search algorithm, random search. It's fairly simple. It randomly samples from all possible configurations. You tell it how many times to sample. It records the configuration that gives best results. If you say sample them all, then you have, in essence, grid search (24 million combinations).\n",
        "\n",
        "The tradeoff is between how many to sample and how long you want to wait: the more you sample, the longer you wait.\n",
        "\n",
        "I am choosing 40, which ends up about 10 minutes. Given 10 minutes is really not that long, I probably could have increased to a higher number. And if you were doing this for real, with this large a search space, you would tell your boss it's going to take days and she better give you extra computing power!\n",
        "\n",
        "For a discussion that includes another available search algorithm provided by keras_tuner (described in the video), [see here](https://mikulskibartosz.name/using-hyperband-for-tensorflow-hyperparameter-tuning-with-keras-tuner)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1mwoyTcAJ9Jh"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(1234)  #need this for replication\n",
        "\n",
        "max_trials = 40 #a tough choice - larger is better but takes more time\n",
        "\n",
        "hyper_tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=MyHyperModel(),\n",
        "    objective=keras_tuner.Objective('auc', 'max'),\n",
        "    max_trials=max_trials,  #how many models to build, i.e., how many different configs to try\n",
        "    executions_per_trial=1,  #given we have eliminated nondeterminism, can keep this at 1\n",
        "    overwrite=True,\n",
        "    #directory=\"ann/tb\",  #for use by TensorBoard - discussed below\n",
        "    seed=1234,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvrMiV8Ap9aw"
      },
      "source": [
        "###An alternative to cross-validation\n",
        "\n",
        "We cannot use cross-validation as with sklearn. We have to define our own folds and it can only be one fold! It is called the validation set. I am semi-arbitrarily carving off 250 rows from training to act as this validation set. The validation set is evaluated after every epoch. View it as a mini-test set but used during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "O3OtnACwL4xL"
      },
      "outputs": [],
      "source": [
        "x_train_tune = x_train[:-250]  #250/1050 roughly 20% - notice neither random nor stratified, kind of bad\n",
        "x_train_val = x_train[-250:]\n",
        "y_train_tune = y_train[:-250]\n",
        "y_train_val = y_train[-250:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9q5rVEqTfPk"
      },
      "source": [
        "If I was being more diligent about this, I would use `train_test_split` twice, once to carve out test set and then again to carve out validation set. Why is this better than what I have above? It will randomly sample and will stratify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "235C1vLmCFFI"
      },
      "outputs": [],
      "source": [
        "# Then add callbacks when calling search\n",
        "callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_auc',              #auc during validation\n",
        "            mode='max',\n",
        "            patience=5,\n",
        "            restore_best_weights=True),\n",
        "        #keras.callbacks.TensorBoard(\"mlops/tb_logs\"),  #for use by TensorBoard but slow!\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c08Lq3iHT9w-"
      },
      "source": [
        "Notice I changed metrics to monitor validation auc. This is standard practice. The validation set gives you a good picture of how you are doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRV8dq1MwkR_"
      },
      "source": [
        "##Under 10 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7U5nCuB6K-ji"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "hyper_tuner.search(x_train_tune, y_train_tune,\n",
        "                   epochs=100, batch_size=100,\n",
        "                   validation_data=(x_train_val, y_train_val),\n",
        "                   callbacks=callbacks,\n",
        "                   )\n",
        "tf.keras.backend.clear_session()  #get rid of unused models created during search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ61nl65LT1m",
        "outputId": "750e5649-b0ec-40a1-84bb-86d005d0d14d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': 3,\n",
              " 'hidden_units0': 13,\n",
              " 'afn0': 1,\n",
              " 'hidden_units1': 15,\n",
              " 'afn1': 1,\n",
              " 'hidden_units2': 13,\n",
              " 'afn2': 0,\n",
              " 'hidden_units3': 13,\n",
              " 'afn3': 1,\n",
              " 'hidden_units4': 16,\n",
              " 'afn4': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "best_hp = hyper_tuner.get_best_hyperparameters()[0]\n",
        "best_hp.values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzbpO6ejvXmo"
      },
      "source": [
        "###My results\n",
        "\n",
        "<pre>\n",
        "{'layers': 3,\n",
        " 'hidden_units0': 13,\n",
        " 'afn0': 1,\n",
        " 'hidden_units1': 15,\n",
        " 'afn1': 1,\n",
        " 'hidden_units2': 13,\n",
        " 'afn2': 0,\n",
        " 'hidden_units3': 13,\n",
        " 'afn3': 1,\n",
        " 'hidden_units4': 16,\n",
        " 'afn4': 1}\n",
        " </pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh-nEm6EvcX2"
      },
      "source": [
        "###Head scratcher\n",
        "\n",
        "I read the above as finding 3 layers as the best. Yet we show unit results for 5 layers. It is one of the quirks of the keras tuner. It will actually generate a random selection for each `Int` generator before the loop even starts! I have read this decision is based on performance. It is faster to generate all random numbers possibly needed up front than do it incrementally. So we can ignore everything at `hidden_units3` and beyond."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu1FHwjBZGu4"
      },
      "source": [
        "###Video gives more details\n",
        "\n",
        "Around minute 52 of the video I go into more detail on how keras tuner works behind the scenes, if you want a bit more on the rationale for this odd behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbrONuL-ZfqL"
      },
      "source": [
        "##Train best model\n",
        "\n",
        "We now have the best configuration out of the 40 we tried. It's relatively easy to now train a model using this configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dRJNQT6mMTns",
        "outputId": "f4ed0150-0173-48fc-8b27-be069740499f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5575 - auc: 0.4671 - loss: 1.7010 - val_accuracy: 0.5480 - val_auc: 0.5265 - val_loss: 1.5061\n",
            "Epoch 2/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5651 - auc: 0.5121 - loss: 1.4924 - val_accuracy: 0.5480 - val_auc: 0.5428 - val_loss: 1.4047\n",
            "Epoch 3/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5560 - auc: 0.5254 - loss: 1.3977 - val_accuracy: 0.5760 - val_auc: 0.5726 - val_loss: 1.3317\n",
            "Epoch 4/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5760 - auc: 0.5559 - loss: 1.3251 - val_accuracy: 0.6200 - val_auc: 0.6030 - val_loss: 1.2697\n",
            "Epoch 5/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6043 - auc: 0.5930 - loss: 1.2621 - val_accuracy: 0.6360 - val_auc: 0.6315 - val_loss: 1.2148\n",
            "Epoch 6/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6463 - auc: 0.6301 - loss: 1.2056 - val_accuracy: 0.6320 - val_auc: 0.6646 - val_loss: 1.1645\n",
            "Epoch 7/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6508 - auc: 0.6725 - loss: 1.1533 - val_accuracy: 0.6360 - val_auc: 0.6908 - val_loss: 1.1200\n",
            "Epoch 8/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6719 - auc: 0.7044 - loss: 1.1067 - val_accuracy: 0.6480 - val_auc: 0.7095 - val_loss: 1.0806\n",
            "Epoch 9/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6633 - auc: 0.7222 - loss: 1.0659 - val_accuracy: 0.6320 - val_auc: 0.7197 - val_loss: 1.0460\n",
            "Epoch 10/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6739 - auc: 0.7328 - loss: 1.0298 - val_accuracy: 0.6280 - val_auc: 0.7252 - val_loss: 1.0150\n",
            "Epoch 11/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6746 - auc: 0.7419 - loss: 0.9972 - val_accuracy: 0.6280 - val_auc: 0.7279 - val_loss: 0.9862\n",
            "Epoch 12/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6818 - auc: 0.7502 - loss: 0.9669 - val_accuracy: 0.6560 - val_auc: 0.7360 - val_loss: 0.9597\n",
            "Epoch 13/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6817 - auc: 0.7585 - loss: 0.9403 - val_accuracy: 0.6680 - val_auc: 0.7396 - val_loss: 0.9357\n",
            "Epoch 14/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6893 - auc: 0.7624 - loss: 0.9160 - val_accuracy: 0.6800 - val_auc: 0.7427 - val_loss: 0.9146\n",
            "Epoch 15/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6997 - auc: 0.7680 - loss: 0.8940 - val_accuracy: 0.6800 - val_auc: 0.7457 - val_loss: 0.8957\n",
            "Epoch 16/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7029 - auc: 0.7723 - loss: 0.8738 - val_accuracy: 0.6880 - val_auc: 0.7462 - val_loss: 0.8776\n",
            "Epoch 17/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7030 - auc: 0.7756 - loss: 0.8555 - val_accuracy: 0.6800 - val_auc: 0.7469 - val_loss: 0.8615\n",
            "Epoch 18/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7032 - auc: 0.7783 - loss: 0.8389 - val_accuracy: 0.6800 - val_auc: 0.7490 - val_loss: 0.8468\n",
            "Epoch 19/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7031 - auc: 0.7804 - loss: 0.8235 - val_accuracy: 0.6800 - val_auc: 0.7504 - val_loss: 0.8329\n",
            "Epoch 20/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7037 - auc: 0.7824 - loss: 0.8092 - val_accuracy: 0.6840 - val_auc: 0.7509 - val_loss: 0.8198\n",
            "Epoch 21/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7125 - auc: 0.7851 - loss: 0.7959 - val_accuracy: 0.6960 - val_auc: 0.7538 - val_loss: 0.8078\n",
            "Epoch 22/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7175 - auc: 0.7882 - loss: 0.7836 - val_accuracy: 0.6920 - val_auc: 0.7572 - val_loss: 0.7965\n",
            "Epoch 23/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - auc: 0.7901 - loss: 0.7723 - val_accuracy: 0.6840 - val_auc: 0.7576 - val_loss: 0.7863\n",
            "Epoch 24/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7182 - auc: 0.7918 - loss: 0.7621 - val_accuracy: 0.6880 - val_auc: 0.7602 - val_loss: 0.7769\n",
            "Epoch 25/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7161 - auc: 0.7926 - loss: 0.7528 - val_accuracy: 0.6920 - val_auc: 0.7605 - val_loss: 0.7680\n",
            "Epoch 26/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7182 - auc: 0.7927 - loss: 0.7441 - val_accuracy: 0.6920 - val_auc: 0.7619 - val_loss: 0.7599\n",
            "Epoch 27/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7195 - auc: 0.7936 - loss: 0.7361 - val_accuracy: 0.6920 - val_auc: 0.7625 - val_loss: 0.7523\n",
            "Epoch 28/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7195 - auc: 0.7946 - loss: 0.7288 - val_accuracy: 0.6920 - val_auc: 0.7635 - val_loss: 0.7454\n",
            "Epoch 29/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7195 - auc: 0.7958 - loss: 0.7221 - val_accuracy: 0.6920 - val_auc: 0.7661 - val_loss: 0.7388\n",
            "Epoch 30/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - auc: 0.7966 - loss: 0.7158 - val_accuracy: 0.6920 - val_auc: 0.7667 - val_loss: 0.7326\n",
            "Epoch 31/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - auc: 0.7972 - loss: 0.7100 - val_accuracy: 0.6920 - val_auc: 0.7684 - val_loss: 0.7269\n",
            "Epoch 32/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - auc: 0.7975 - loss: 0.7046 - val_accuracy: 0.6920 - val_auc: 0.7688 - val_loss: 0.7217\n",
            "Epoch 33/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - auc: 0.7974 - loss: 0.6997 - val_accuracy: 0.6920 - val_auc: 0.7697 - val_loss: 0.7169\n",
            "Epoch 34/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - auc: 0.7976 - loss: 0.6950 - val_accuracy: 0.6920 - val_auc: 0.7708 - val_loss: 0.7125\n",
            "Epoch 35/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - auc: 0.7974 - loss: 0.6907 - val_accuracy: 0.6920 - val_auc: 0.7713 - val_loss: 0.7083\n",
            "Epoch 36/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - auc: 0.7977 - loss: 0.6866 - val_accuracy: 0.6920 - val_auc: 0.7714 - val_loss: 0.7046\n",
            "Epoch 37/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - auc: 0.7986 - loss: 0.6828 - val_accuracy: 0.6920 - val_auc: 0.7719 - val_loss: 0.7010\n",
            "Epoch 38/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - auc: 0.7987 - loss: 0.6793 - val_accuracy: 0.6920 - val_auc: 0.7721 - val_loss: 0.6977\n",
            "Epoch 39/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - auc: 0.7983 - loss: 0.6760 - val_accuracy: 0.6920 - val_auc: 0.7732 - val_loss: 0.6945\n",
            "Epoch 40/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - auc: 0.7981 - loss: 0.6729 - val_accuracy: 0.6920 - val_auc: 0.7739 - val_loss: 0.6916\n",
            "Epoch 41/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - auc: 0.7985 - loss: 0.6700 - val_accuracy: 0.6920 - val_auc: 0.7747 - val_loss: 0.6890\n",
            "Epoch 42/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7193 - auc: 0.7986 - loss: 0.6673 - val_accuracy: 0.6920 - val_auc: 0.7748 - val_loss: 0.6863\n",
            "Epoch 43/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7192 - auc: 0.7988 - loss: 0.6648 - val_accuracy: 0.6920 - val_auc: 0.7743 - val_loss: 0.6839\n",
            "Epoch 44/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7196 - auc: 0.7988 - loss: 0.6624 - val_accuracy: 0.6920 - val_auc: 0.7756 - val_loss: 0.6815\n",
            "Epoch 45/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7196 - auc: 0.7986 - loss: 0.6601 - val_accuracy: 0.6920 - val_auc: 0.7746 - val_loss: 0.6792\n",
            "Epoch 46/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7192 - auc: 0.7984 - loss: 0.6579 - val_accuracy: 0.6920 - val_auc: 0.7750 - val_loss: 0.6770\n",
            "Epoch 47/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7187 - auc: 0.7987 - loss: 0.6559 - val_accuracy: 0.6920 - val_auc: 0.7746 - val_loss: 0.6749\n",
            "Epoch 48/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7190 - auc: 0.7993 - loss: 0.6539 - val_accuracy: 0.6920 - val_auc: 0.7744 - val_loss: 0.6731\n",
            "Epoch 49/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7187 - auc: 0.7987 - loss: 0.6521 - val_accuracy: 0.6920 - val_auc: 0.7748 - val_loss: 0.6713\n",
            "Epoch 50/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7187 - auc: 0.7987 - loss: 0.6504 - val_accuracy: 0.6920 - val_auc: 0.7747 - val_loss: 0.6696\n",
            "Epoch 51/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7187 - auc: 0.7980 - loss: 0.6487 - val_accuracy: 0.6920 - val_auc: 0.7752 - val_loss: 0.6679\n",
            "Epoch 52/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7187 - auc: 0.7991 - loss: 0.6470 - val_accuracy: 0.6920 - val_auc: 0.7757 - val_loss: 0.6663\n",
            "Epoch 53/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7187 - auc: 0.7999 - loss: 0.6455 - val_accuracy: 0.6920 - val_auc: 0.7749 - val_loss: 0.6647\n",
            "Epoch 54/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - auc: 0.7995 - loss: 0.6440 - val_accuracy: 0.6920 - val_auc: 0.7756 - val_loss: 0.6632\n",
            "Epoch 55/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - auc: 0.7990 - loss: 0.6426 - val_accuracy: 0.6920 - val_auc: 0.7757 - val_loss: 0.6618\n",
            "Epoch 56/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7187 - auc: 0.7997 - loss: 0.6413 - val_accuracy: 0.6920 - val_auc: 0.7754 - val_loss: 0.6606\n",
            "Epoch 57/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - auc: 0.7999 - loss: 0.6401 - val_accuracy: 0.6920 - val_auc: 0.7756 - val_loss: 0.6593\n",
            "Epoch 58/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - auc: 0.7999 - loss: 0.6390 - val_accuracy: 0.6920 - val_auc: 0.7755 - val_loss: 0.6581\n",
            "Epoch 59/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - auc: 0.8002 - loss: 0.6379 - val_accuracy: 0.6920 - val_auc: 0.7761 - val_loss: 0.6570\n",
            "Epoch 60/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - auc: 0.7999 - loss: 0.6368 - val_accuracy: 0.6920 - val_auc: 0.7766 - val_loss: 0.6559\n",
            "Epoch 61/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7225 - auc: 0.8004 - loss: 0.6358 - val_accuracy: 0.6920 - val_auc: 0.7759 - val_loss: 0.6550\n",
            "Epoch 62/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7225 - auc: 0.8002 - loss: 0.6349 - val_accuracy: 0.6920 - val_auc: 0.7755 - val_loss: 0.6540\n",
            "Epoch 63/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7242 - auc: 0.8007 - loss: 0.6340 - val_accuracy: 0.6920 - val_auc: 0.7764 - val_loss: 0.6530\n",
            "Epoch 64/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7242 - auc: 0.8007 - loss: 0.6331 - val_accuracy: 0.6920 - val_auc: 0.7761 - val_loss: 0.6521\n",
            "Epoch 65/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7242 - auc: 0.8005 - loss: 0.6323 - val_accuracy: 0.6920 - val_auc: 0.7759 - val_loss: 0.6512\n",
            "Epoch 66/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7242 - auc: 0.8009 - loss: 0.6315 - val_accuracy: 0.6920 - val_auc: 0.7755 - val_loss: 0.6504\n",
            "Epoch 67/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7248 - auc: 0.8012 - loss: 0.6307 - val_accuracy: 0.6920 - val_auc: 0.7760 - val_loss: 0.6496\n",
            "Epoch 68/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - auc: 0.8013 - loss: 0.6300 - val_accuracy: 0.6920 - val_auc: 0.7762 - val_loss: 0.6488\n",
            "Epoch 69/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - auc: 0.8011 - loss: 0.6294 - val_accuracy: 0.6920 - val_auc: 0.7765 - val_loss: 0.6480\n",
            "Epoch 70/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - auc: 0.8008 - loss: 0.6286 - val_accuracy: 0.6920 - val_auc: 0.7766 - val_loss: 0.6472\n",
            "Epoch 71/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7248 - auc: 0.8009 - loss: 0.6280 - val_accuracy: 0.6920 - val_auc: 0.7774 - val_loss: 0.6465\n",
            "Epoch 72/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - auc: 0.8012 - loss: 0.6273 - val_accuracy: 0.6920 - val_auc: 0.7775 - val_loss: 0.6458\n",
            "Epoch 73/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7248 - auc: 0.8024 - loss: 0.6267 - val_accuracy: 0.6920 - val_auc: 0.7774 - val_loss: 0.6452\n",
            "Epoch 74/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - auc: 0.8020 - loss: 0.6261 - val_accuracy: 0.6920 - val_auc: 0.7768 - val_loss: 0.6445\n",
            "Epoch 75/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7248 - auc: 0.8016 - loss: 0.6255 - val_accuracy: 0.6920 - val_auc: 0.7773 - val_loss: 0.6439\n",
            "Epoch 76/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - auc: 0.8019 - loss: 0.6249 - val_accuracy: 0.6920 - val_auc: 0.7771 - val_loss: 0.6433\n",
            "Epoch 77/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7248 - auc: 0.8025 - loss: 0.6244 - val_accuracy: 0.6920 - val_auc: 0.7773 - val_loss: 0.6428\n",
            "Epoch 78/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7248 - auc: 0.8020 - loss: 0.6239 - val_accuracy: 0.6920 - val_auc: 0.7777 - val_loss: 0.6422\n",
            "Epoch 79/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7248 - auc: 0.8028 - loss: 0.6234 - val_accuracy: 0.6920 - val_auc: 0.7778 - val_loss: 0.6417\n",
            "Epoch 80/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7248 - auc: 0.8029 - loss: 0.6229 - val_accuracy: 0.6920 - val_auc: 0.7776 - val_loss: 0.6412\n",
            "Epoch 81/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7241 - auc: 0.8025 - loss: 0.6224 - val_accuracy: 0.6920 - val_auc: 0.7779 - val_loss: 0.6407\n",
            "Epoch 82/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7241 - auc: 0.8029 - loss: 0.6219 - val_accuracy: 0.6920 - val_auc: 0.7781 - val_loss: 0.6402\n",
            "Epoch 83/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7226 - auc: 0.8030 - loss: 0.6215 - val_accuracy: 0.6920 - val_auc: 0.7784 - val_loss: 0.6397\n",
            "Epoch 84/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7244 - auc: 0.8033 - loss: 0.6211 - val_accuracy: 0.6920 - val_auc: 0.7784 - val_loss: 0.6393\n",
            "Epoch 85/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7246 - auc: 0.8030 - loss: 0.6207 - val_accuracy: 0.6920 - val_auc: 0.7785 - val_loss: 0.6389\n",
            "Epoch 86/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7232 - auc: 0.8030 - loss: 0.6203 - val_accuracy: 0.6920 - val_auc: 0.7790 - val_loss: 0.6384\n",
            "Epoch 87/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7232 - auc: 0.8028 - loss: 0.6199 - val_accuracy: 0.6880 - val_auc: 0.7791 - val_loss: 0.6380\n",
            "Epoch 88/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7232 - auc: 0.8028 - loss: 0.6195 - val_accuracy: 0.6880 - val_auc: 0.7784 - val_loss: 0.6376\n",
            "Epoch 89/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7250 - auc: 0.8030 - loss: 0.6191 - val_accuracy: 0.6880 - val_auc: 0.7787 - val_loss: 0.6372\n",
            "Epoch 90/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7250 - auc: 0.8029 - loss: 0.6187 - val_accuracy: 0.6880 - val_auc: 0.7785 - val_loss: 0.6368\n",
            "Epoch 91/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7237 - auc: 0.8024 - loss: 0.6184 - val_accuracy: 0.6880 - val_auc: 0.7789 - val_loss: 0.6364\n",
            "Epoch 92/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7263 - auc: 0.8030 - loss: 0.6180 - val_accuracy: 0.6920 - val_auc: 0.7794 - val_loss: 0.6361\n",
            "Epoch 93/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7270 - auc: 0.8030 - loss: 0.6177 - val_accuracy: 0.6920 - val_auc: 0.7794 - val_loss: 0.6357\n",
            "Epoch 94/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7279 - auc: 0.8032 - loss: 0.6173 - val_accuracy: 0.6920 - val_auc: 0.7798 - val_loss: 0.6353\n",
            "Epoch 95/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7279 - auc: 0.8034 - loss: 0.6170 - val_accuracy: 0.6960 - val_auc: 0.7802 - val_loss: 0.6350\n",
            "Epoch 96/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7265 - auc: 0.8040 - loss: 0.6167 - val_accuracy: 0.6960 - val_auc: 0.7802 - val_loss: 0.6346\n",
            "Epoch 97/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7282 - auc: 0.8040 - loss: 0.6164 - val_accuracy: 0.6960 - val_auc: 0.7801 - val_loss: 0.6343\n",
            "Epoch 98/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7282 - auc: 0.8037 - loss: 0.6160 - val_accuracy: 0.6960 - val_auc: 0.7807 - val_loss: 0.6340\n",
            "Epoch 99/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7282 - auc: 0.8038 - loss: 0.6157 - val_accuracy: 0.6960 - val_auc: 0.7810 - val_loss: 0.6336\n",
            "Epoch 100/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7282 - auc: 0.8038 - loss: 0.6154 - val_accuracy: 0.7000 - val_auc: 0.7810 - val_loss: 0.6333\n"
          ]
        }
      ],
      "source": [
        "hypermodel = MyHyperModel()\n",
        "model = hypermodel.build(best_hp)\n",
        "training = model.fit(x_train, y_train, epochs=100, validation_data=(x_train_val, y_train_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
        "                                      monitor='val_auc',\n",
        "                                      mode='max',\n",
        "                                      patience=15,\n",
        "                                      restore_best_weights=True)\n",
        "                   ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXwRdkwixocf"
      },
      "source": [
        "###I did not turn off verbose on purpose\n",
        "\n",
        "I wanted to show you there is some value in watching epochs unfold. In particular, you should track training metrics (accuracy, auc, loss) with validation metrics (val_accuracy, val_auc, val_loss). The more they diverge, the more likely you are overfitting. For this run, I am quite pleased. Here is the last epoch:\n",
        "\n",
        "<pre>\n",
        "Epoch 100/100\n",
        "accuracy: 0.7282 - auc: 0.8038 - loss: 0.6154 - val_accuracy: 0.7000 - val_auc: 0.7810 - val_loss: 0.6333\n",
        "</pre>\n",
        "It is almost always the case that validation metrics are worse than training. However, they are quite close here. I would be worried if validation was twice as bad or even worse. In that case, you would have to think about modifying your model to combat overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF-_ZEnZ5B5N"
      },
      "source": [
        "###We can check to make sure\n",
        "\n",
        "From below, it does match up with what we expect at least in terms of `layers=3` and units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "A9Qrq6Sc4DHf",
        "outputId": "36005d28-b148-4141-9c29-3a361029667d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_0_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │            \u001b[38;5;34m91\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │           \u001b[38;5;34m208\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m14\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_0_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,571\u001b[0m (6.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,571</span> (6.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m523\u001b[0m (2.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">523</span> (2.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,048\u001b[0m (4.10 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,048</span> (4.10 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf3al6PJmMYo",
        "outputId": "3a268120-6cf9-4aad-e7f2-7fcb72d83761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "len(training.history['auc'])  #100 - no early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74X4PYDOmMYp",
        "outputId": "90c85076-5a23-4623-e846-34833f9d779d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8026094436645508"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "training.history['auc'][-1]  #0.8026094436645508"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Mj-pFez2mNvn",
        "outputId": "9f186dda-ccf1-4848-99c8-e28db9a0b891"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(training.history['auc'])\n",
        "plt.plot(training.history['loss'])\n",
        "plt.title('ROC AUC')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['ROC AUC', 'loss'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4usNP5lOUcl"
      },
      "source": [
        "###Check on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCwy0buFNfTN",
        "outputId": "0ad3b5c3-f83a-44f9-fb1b-6a0df85522a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6162435 , 0.7569884 , 0.8081401 , 0.21723291, 0.26127705],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "yraw = model.predict(x_test)[:,0]\n",
        "\n",
        "yraw[:5]  #[0.6162435 , 0.7569884 , 0.8081401 , 0.21723291, 0.26127705]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "wf5DyFcvtY8R",
        "outputId": "fb7e84b2-623c-44dd-8f96-3aec23f8b102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7927855258d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_dc5a5 th:not(.index_name) {\n",
              "  background-color: #800000;\n",
              "  color: white;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_dc5a5_row0_col0, #T_dc5a5_row0_col1, #T_dc5a5_row0_col3, #T_dc5a5_row0_col5, #T_dc5a5_row1_col0, #T_dc5a5_row1_col1, #T_dc5a5_row1_col3, #T_dc5a5_row1_col5, #T_dc5a5_row2_col0, #T_dc5a5_row2_col1, #T_dc5a5_row2_col2, #T_dc5a5_row2_col3, #T_dc5a5_row2_col5, #T_dc5a5_row3_col0, #T_dc5a5_row3_col1, #T_dc5a5_row3_col2, #T_dc5a5_row3_col3, #T_dc5a5_row3_col5, #T_dc5a5_row4_col0, #T_dc5a5_row4_col1, #T_dc5a5_row4_col2, #T_dc5a5_row4_col3, #T_dc5a5_row4_col5, #T_dc5a5_row5_col0, #T_dc5a5_row5_col1, #T_dc5a5_row5_col2, #T_dc5a5_row5_col3, #T_dc5a5_row5_col5, #T_dc5a5_row6_col0, #T_dc5a5_row6_col1, #T_dc5a5_row6_col2, #T_dc5a5_row6_col5, #T_dc5a5_row7_col0, #T_dc5a5_row7_col1, #T_dc5a5_row7_col2, #T_dc5a5_row7_col3, #T_dc5a5_row7_col5, #T_dc5a5_row8_col0, #T_dc5a5_row8_col1, #T_dc5a5_row8_col2, #T_dc5a5_row8_col3, #T_dc5a5_row8_col5, #T_dc5a5_row9_col0, #T_dc5a5_row9_col1, #T_dc5a5_row9_col2, #T_dc5a5_row9_col3, #T_dc5a5_row10_col0, #T_dc5a5_row10_col1, #T_dc5a5_row10_col2, #T_dc5a5_row10_col3, #T_dc5a5_row10_col5, #T_dc5a5_row11_col0, #T_dc5a5_row11_col1, #T_dc5a5_row11_col2, #T_dc5a5_row11_col3, #T_dc5a5_row11_col5, #T_dc5a5_row12_col0, #T_dc5a5_row12_col1, #T_dc5a5_row12_col2, #T_dc5a5_row12_col3, #T_dc5a5_row12_col5, #T_dc5a5_row13_col0, #T_dc5a5_row13_col1, #T_dc5a5_row13_col2, #T_dc5a5_row13_col3, #T_dc5a5_row13_col5, #T_dc5a5_row14_col0, #T_dc5a5_row14_col1, #T_dc5a5_row14_col2, #T_dc5a5_row14_col3, #T_dc5a5_row14_col5, #T_dc5a5_row15_col0, #T_dc5a5_row15_col2, #T_dc5a5_row15_col3, #T_dc5a5_row15_col5, #T_dc5a5_row16_col0, #T_dc5a5_row16_col1, #T_dc5a5_row16_col2, #T_dc5a5_row16_col3, #T_dc5a5_row16_col5, #T_dc5a5_row17_col0, #T_dc5a5_row17_col1, #T_dc5a5_row17_col2, #T_dc5a5_row17_col3, #T_dc5a5_row17_col5, #T_dc5a5_row18_col0, #T_dc5a5_row18_col1, #T_dc5a5_row18_col2, #T_dc5a5_row18_col3, #T_dc5a5_row18_col5, #T_dc5a5_row19_col0, #T_dc5a5_row19_col1, #T_dc5a5_row19_col2, #T_dc5a5_row19_col3, #T_dc5a5_row19_col5, #T_dc5a5_row20_col1, #T_dc5a5_row20_col2, #T_dc5a5_row20_col3, #T_dc5a5_row20_col5 {\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_dc5a5_row0_col2, #T_dc5a5_row0_col4, #T_dc5a5_row1_col2, #T_dc5a5_row1_col4, #T_dc5a5_row2_col4, #T_dc5a5_row3_col4, #T_dc5a5_row4_col4, #T_dc5a5_row5_col4, #T_dc5a5_row6_col3, #T_dc5a5_row6_col4, #T_dc5a5_row7_col4, #T_dc5a5_row8_col4, #T_dc5a5_row9_col4, #T_dc5a5_row9_col5, #T_dc5a5_row10_col4, #T_dc5a5_row11_col4, #T_dc5a5_row12_col4, #T_dc5a5_row13_col4, #T_dc5a5_row14_col4, #T_dc5a5_row15_col1, #T_dc5a5_row15_col4, #T_dc5a5_row16_col4, #T_dc5a5_row17_col4, #T_dc5a5_row18_col4, #T_dc5a5_row19_col4, #T_dc5a5_row20_col0, #T_dc5a5_row20_col4 {\n",
              "  background-color: pink;\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_dc5a5\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_dc5a5_level0_col0\" class=\"col_heading level0 col0\" >threshold</th>\n",
              "      <th id=\"T_dc5a5_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
              "      <th id=\"T_dc5a5_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
              "      <th id=\"T_dc5a5_level0_col3\" class=\"col_heading level0 col3\" >f1</th>\n",
              "      <th id=\"T_dc5a5_level0_col4\" class=\"col_heading level0 col4\" >auc</th>\n",
              "      <th id=\"T_dc5a5_level0_col5\" class=\"col_heading level0 col5\" >accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_dc5a5_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row0_col1\" class=\"data row0 col1\" >0.43</td>\n",
              "      <td id=\"T_dc5a5_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
              "      <td id=\"T_dc5a5_row0_col3\" class=\"data row0 col3\" >0.60</td>\n",
              "      <td id=\"T_dc5a5_row0_col4\" class=\"data row0 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row0_col5\" class=\"data row0 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_dc5a5_row1_col0\" class=\"data row1 col0\" >0.05</td>\n",
              "      <td id=\"T_dc5a5_row1_col1\" class=\"data row1 col1\" >0.43</td>\n",
              "      <td id=\"T_dc5a5_row1_col2\" class=\"data row1 col2\" >1.00</td>\n",
              "      <td id=\"T_dc5a5_row1_col3\" class=\"data row1 col3\" >0.60</td>\n",
              "      <td id=\"T_dc5a5_row1_col4\" class=\"data row1 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row1_col5\" class=\"data row1 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_dc5a5_row2_col0\" class=\"data row2 col0\" >0.10</td>\n",
              "      <td id=\"T_dc5a5_row2_col1\" class=\"data row2 col1\" >0.43</td>\n",
              "      <td id=\"T_dc5a5_row2_col2\" class=\"data row2 col2\" >0.99</td>\n",
              "      <td id=\"T_dc5a5_row2_col3\" class=\"data row2 col3\" >0.60</td>\n",
              "      <td id=\"T_dc5a5_row2_col4\" class=\"data row2 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row2_col5\" class=\"data row2 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_dc5a5_row3_col0\" class=\"data row3 col0\" >0.15</td>\n",
              "      <td id=\"T_dc5a5_row3_col1\" class=\"data row3 col1\" >0.44</td>\n",
              "      <td id=\"T_dc5a5_row3_col2\" class=\"data row3 col2\" >0.99</td>\n",
              "      <td id=\"T_dc5a5_row3_col3\" class=\"data row3 col3\" >0.61</td>\n",
              "      <td id=\"T_dc5a5_row3_col4\" class=\"data row3 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row3_col5\" class=\"data row3 col5\" >0.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_dc5a5_row4_col0\" class=\"data row4 col0\" >0.20</td>\n",
              "      <td id=\"T_dc5a5_row4_col1\" class=\"data row4 col1\" >0.46</td>\n",
              "      <td id=\"T_dc5a5_row4_col2\" class=\"data row4 col2\" >0.96</td>\n",
              "      <td id=\"T_dc5a5_row4_col3\" class=\"data row4 col3\" >0.62</td>\n",
              "      <td id=\"T_dc5a5_row4_col4\" class=\"data row4 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row4_col5\" class=\"data row4 col5\" >0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_dc5a5_row5_col0\" class=\"data row5 col0\" >0.25</td>\n",
              "      <td id=\"T_dc5a5_row5_col1\" class=\"data row5 col1\" >0.51</td>\n",
              "      <td id=\"T_dc5a5_row5_col2\" class=\"data row5 col2\" >0.91</td>\n",
              "      <td id=\"T_dc5a5_row5_col3\" class=\"data row5 col3\" >0.65</td>\n",
              "      <td id=\"T_dc5a5_row5_col4\" class=\"data row5 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row5_col5\" class=\"data row5 col5\" >0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_dc5a5_row6_col0\" class=\"data row6 col0\" >0.30</td>\n",
              "      <td id=\"T_dc5a5_row6_col1\" class=\"data row6 col1\" >0.59</td>\n",
              "      <td id=\"T_dc5a5_row6_col2\" class=\"data row6 col2\" >0.82</td>\n",
              "      <td id=\"T_dc5a5_row6_col3\" class=\"data row6 col3\" >0.69</td>\n",
              "      <td id=\"T_dc5a5_row6_col4\" class=\"data row6 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row6_col5\" class=\"data row6 col5\" >0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_dc5a5_row7_col0\" class=\"data row7 col0\" >0.35</td>\n",
              "      <td id=\"T_dc5a5_row7_col1\" class=\"data row7 col1\" >0.62</td>\n",
              "      <td id=\"T_dc5a5_row7_col2\" class=\"data row7 col2\" >0.70</td>\n",
              "      <td id=\"T_dc5a5_row7_col3\" class=\"data row7 col3\" >0.66</td>\n",
              "      <td id=\"T_dc5a5_row7_col4\" class=\"data row7 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row7_col5\" class=\"data row7 col5\" >0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_dc5a5_row8_col0\" class=\"data row8 col0\" >0.40</td>\n",
              "      <td id=\"T_dc5a5_row8_col1\" class=\"data row8 col1\" >0.70</td>\n",
              "      <td id=\"T_dc5a5_row8_col2\" class=\"data row8 col2\" >0.61</td>\n",
              "      <td id=\"T_dc5a5_row8_col3\" class=\"data row8 col3\" >0.65</td>\n",
              "      <td id=\"T_dc5a5_row8_col4\" class=\"data row8 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row8_col5\" class=\"data row8 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_dc5a5_row9_col0\" class=\"data row9 col0\" >0.45</td>\n",
              "      <td id=\"T_dc5a5_row9_col1\" class=\"data row9 col1\" >0.72</td>\n",
              "      <td id=\"T_dc5a5_row9_col2\" class=\"data row9 col2\" >0.58</td>\n",
              "      <td id=\"T_dc5a5_row9_col3\" class=\"data row9 col3\" >0.64</td>\n",
              "      <td id=\"T_dc5a5_row9_col4\" class=\"data row9 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row9_col5\" class=\"data row9 col5\" >0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_dc5a5_row10_col0\" class=\"data row10 col0\" >0.50</td>\n",
              "      <td id=\"T_dc5a5_row10_col1\" class=\"data row10 col1\" >0.73</td>\n",
              "      <td id=\"T_dc5a5_row10_col2\" class=\"data row10 col2\" >0.54</td>\n",
              "      <td id=\"T_dc5a5_row10_col3\" class=\"data row10 col3\" >0.62</td>\n",
              "      <td id=\"T_dc5a5_row10_col4\" class=\"data row10 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row10_col5\" class=\"data row10 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_dc5a5_row11_col0\" class=\"data row11 col0\" >0.55</td>\n",
              "      <td id=\"T_dc5a5_row11_col1\" class=\"data row11 col1\" >0.75</td>\n",
              "      <td id=\"T_dc5a5_row11_col2\" class=\"data row11 col2\" >0.49</td>\n",
              "      <td id=\"T_dc5a5_row11_col3\" class=\"data row11 col3\" >0.59</td>\n",
              "      <td id=\"T_dc5a5_row11_col4\" class=\"data row11 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row11_col5\" class=\"data row11 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_dc5a5_row12_col0\" class=\"data row12 col0\" >0.60</td>\n",
              "      <td id=\"T_dc5a5_row12_col1\" class=\"data row12 col1\" >0.80</td>\n",
              "      <td id=\"T_dc5a5_row12_col2\" class=\"data row12 col2\" >0.43</td>\n",
              "      <td id=\"T_dc5a5_row12_col3\" class=\"data row12 col3\" >0.56</td>\n",
              "      <td id=\"T_dc5a5_row12_col4\" class=\"data row12 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row12_col5\" class=\"data row12 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_dc5a5_row13_col0\" class=\"data row13 col0\" >0.65</td>\n",
              "      <td id=\"T_dc5a5_row13_col1\" class=\"data row13 col1\" >0.87</td>\n",
              "      <td id=\"T_dc5a5_row13_col2\" class=\"data row13 col2\" >0.34</td>\n",
              "      <td id=\"T_dc5a5_row13_col3\" class=\"data row13 col3\" >0.49</td>\n",
              "      <td id=\"T_dc5a5_row13_col4\" class=\"data row13 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row13_col5\" class=\"data row13 col5\" >0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_dc5a5_row14_col0\" class=\"data row14 col0\" >0.70</td>\n",
              "      <td id=\"T_dc5a5_row14_col1\" class=\"data row14 col1\" >0.89</td>\n",
              "      <td id=\"T_dc5a5_row14_col2\" class=\"data row14 col2\" >0.30</td>\n",
              "      <td id=\"T_dc5a5_row14_col3\" class=\"data row14 col3\" >0.45</td>\n",
              "      <td id=\"T_dc5a5_row14_col4\" class=\"data row14 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row14_col5\" class=\"data row14 col5\" >0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_dc5a5_row15_col0\" class=\"data row15 col0\" >0.75</td>\n",
              "      <td id=\"T_dc5a5_row15_col1\" class=\"data row15 col1\" >0.96</td>\n",
              "      <td id=\"T_dc5a5_row15_col2\" class=\"data row15 col2\" >0.23</td>\n",
              "      <td id=\"T_dc5a5_row15_col3\" class=\"data row15 col3\" >0.37</td>\n",
              "      <td id=\"T_dc5a5_row15_col4\" class=\"data row15 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row15_col5\" class=\"data row15 col5\" >0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_dc5a5_row16_col0\" class=\"data row16 col0\" >0.80</td>\n",
              "      <td id=\"T_dc5a5_row16_col1\" class=\"data row16 col1\" >0.95</td>\n",
              "      <td id=\"T_dc5a5_row16_col2\" class=\"data row16 col2\" >0.16</td>\n",
              "      <td id=\"T_dc5a5_row16_col3\" class=\"data row16 col3\" >0.27</td>\n",
              "      <td id=\"T_dc5a5_row16_col4\" class=\"data row16 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row16_col5\" class=\"data row16 col5\" >0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_dc5a5_row17_col0\" class=\"data row17 col0\" >0.85</td>\n",
              "      <td id=\"T_dc5a5_row17_col1\" class=\"data row17 col1\" >0.88</td>\n",
              "      <td id=\"T_dc5a5_row17_col2\" class=\"data row17 col2\" >0.06</td>\n",
              "      <td id=\"T_dc5a5_row17_col3\" class=\"data row17 col3\" >0.11</td>\n",
              "      <td id=\"T_dc5a5_row17_col4\" class=\"data row17 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row17_col5\" class=\"data row17 col5\" >0.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_dc5a5_row18_col0\" class=\"data row18 col0\" >0.90</td>\n",
              "      <td id=\"T_dc5a5_row18_col1\" class=\"data row18 col1\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row18_col2\" class=\"data row18 col2\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row18_col3\" class=\"data row18 col3\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row18_col4\" class=\"data row18 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row18_col5\" class=\"data row18 col5\" >0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_dc5a5_row19_col0\" class=\"data row19 col0\" >0.95</td>\n",
              "      <td id=\"T_dc5a5_row19_col1\" class=\"data row19 col1\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row19_col2\" class=\"data row19 col2\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row19_col3\" class=\"data row19 col3\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row19_col4\" class=\"data row19 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row19_col5\" class=\"data row19 col5\" >0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dc5a5_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_dc5a5_row20_col0\" class=\"data row20 col0\" >1.00</td>\n",
              "      <td id=\"T_dc5a5_row20_col1\" class=\"data row20 col1\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row20_col2\" class=\"data row20 col2\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row20_col3\" class=\"data row20 col3\" >0.00</td>\n",
              "      <td id=\"T_dc5a5_row20_col4\" class=\"data row20 col4\" >0.78</td>\n",
              "      <td id=\"T_dc5a5_row20_col5\" class=\"data row20 col5\" >0.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "result_df, fancy_df = threshold_results(np.round(np.arange(0.0,1.01,.05), 2), y_test, yraw)\n",
        "fancy_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAYmv0UqF7CN"
      },
      "source": [
        "#TensorBoard\n",
        "\n",
        "TensorBoard is a fancy way to visualize training and tuning. I have in essence shut it off by commenting out this line in tuning:\n",
        "\n",
        "<pre>\n",
        "#callbacks=[keras.callbacks.TensorBoard(\"mlops/tb_logs\")]  #for use by TensorBoard\n",
        "</pre>\n",
        "\n",
        "Why? Because it seems to double the time tuning takes and we won't be using TensorBoard.\n",
        "\n",
        "Why? I felt this chapter is already jam-packed with new libraries and did not want to stop and go over yet another.\n",
        "\n",
        "That said, you can uncomment the line and then run the commands below to bring TensorBoard up if you want to play with it yourself.\n",
        "\n",
        "Note you will get a \"can't find folder\" error for `%tensorboard` unless you uncomment my line.\n",
        "\n",
        "More on use of [keras_tuner and TensorBoard](https://keras.io/guides/keras_tuner/visualize_tuning/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HBOQ08kFF9Od"
      },
      "outputs": [],
      "source": [
        "#%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6o4uSaSaGGF0"
      },
      "outputs": [],
      "source": [
        "#%tensorboard --logdir ann/tb_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-EgecPIj9PD"
      },
      "source": [
        "#Challenge 1\n",
        "\n",
        "Tune an ANN for customer dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdnjf2WN-Jva"
      },
      "source": [
        "##Step 1.1 Bring in cable data\n",
        "\n",
        "Divide out into features and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_aiYvxcbIBEe"
      },
      "outputs": [],
      "source": [
        "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQPM6PqZXgmAHfRYTcDZseyALRyVwkBtKEo_rtaKq_C7T0jycWxH6QVEzTzJCRA0m8Vz0k68eM9tDm-/pub?output=csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-aLzw63jIBEr",
        "outputId": "f2ccb455-d5ce-4399-c5cd-99984b4993a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender Experience Level  Time Spent       OS      ISP   Age  Rating\n",
              "0  Female           medium         NaN      iOS  Xfinity   NaN       0\n",
              "1    Male           medium       71.97  Android      Cox  50.0       0\n",
              "2  Female           medium      101.81      NaN      Cox  49.0       1\n",
              "3  Female           medium       86.37  Android  Xfinity  53.0       0\n",
              "4  Female           medium      103.97      iOS  Xfinity  58.0       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c785668b-57b6-4636-acfb-3965f8152b70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Experience Level</th>\n",
              "      <th>Time Spent</th>\n",
              "      <th>OS</th>\n",
              "      <th>ISP</th>\n",
              "      <th>Age</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>medium</td>\n",
              "      <td>NaN</td>\n",
              "      <td>iOS</td>\n",
              "      <td>Xfinity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>medium</td>\n",
              "      <td>71.97</td>\n",
              "      <td>Android</td>\n",
              "      <td>Cox</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Female</td>\n",
              "      <td>medium</td>\n",
              "      <td>101.81</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cox</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>medium</td>\n",
              "      <td>86.37</td>\n",
              "      <td>Android</td>\n",
              "      <td>Xfinity</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>medium</td>\n",
              "      <td>103.97</td>\n",
              "      <td>iOS</td>\n",
              "      <td>Xfinity</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c785668b-57b6-4636-acfb-3965f8152b70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c785668b-57b6-4636-acfb-3965f8152b70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c785668b-57b6-4636-acfb-3965f8152b70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a5474008-0bae-4711-b8e4-ae71d87ef389\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5474008-0bae-4711-b8e4-ae71d87ef389')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a5474008-0bae-4711-b8e4-ae71d87ef389 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "customers_trimmed",
              "summary": "{\n  \"name\": \"customers_trimmed\",\n  \"rows\": 977,\n  \"fields\": [\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Experience Level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"medium\",\n          \"low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time Spent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.236693297839539,\n        \"min\": 62.43,\n        \"max\": 144.95,\n        \"num_unique_values\": 738,\n        \"samples\": [\n          107.36,\n          71.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Android\",\n          \"iOS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ISP\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Cox\",\n          \"AT&T\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.652659220442612,\n        \"min\": 18.0,\n        \"max\": 75.0,\n        \"num_unique_values\": 56,\n        \"samples\": [\n          50.0,\n          64.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "customers_df = pd.read_csv(url)\n",
        "customers_trimmed = customers_df.drop(columns='ID')  #this is a useless column which we will drop early\n",
        "customers_trimmed = customers_trimmed.drop_duplicates(ignore_index=True)  #get rid of any duplicates\n",
        "customers_trimmed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fO3Dc8CSHtfV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "x_train_cust, x_test_cust, y_train_cust,  y_test_cust = customer_setup(customers_trimmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQazuv2oW9qC",
        "outputId": "cd75eb8c-f688-4ce0-a084-03c558516341"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.45875063, 0.43511254, 0.75411243, 0.45929552, 0.04987596,\n",
              "       0.62993528])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "x_train_cust.std(axis=0)  #[0.45875063, 0.43511254, 0.75411243, 0.45929552, 0.04987596, 0.62993528]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tbq-R2wKkWk"
      },
      "source": [
        "##Step 1.2 Set up model builder\n",
        "\n",
        "Parameterize `loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=.1)`. Include choices for `label_smoothing` `.1, .2, .3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7P2GQqvX5TX"
      },
      "source": [
        "###Here is original as a starting place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "COdi-PzYqxgc"
      },
      "outputs": [],
      "source": [
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "  def __init__(self, n=6, metrics='auc',\n",
        "                      layers=(1,5,1),\n",
        "                      units=(2,16,1),\n",
        "                      afn_list=('relu', 'leaky_relu')):\n",
        "    self.n = n #number of features\n",
        "    self.metrics = metrics\n",
        "    self.units = units\n",
        "    self.layers = layers\n",
        "    self.afn_list = afn_list\n",
        "\n",
        "  def build(self, hp):\n",
        "\n",
        "    n = self.n\n",
        "    metrics = self.metrics\n",
        "    min_units = self.units[0]\n",
        "    max_units = self.units[1]\n",
        "    step_units = self.units[2]\n",
        "\n",
        "    min_layers = self.layers[0]\n",
        "    max_layers = self.layers[1]\n",
        "    step_layers = self.layers[2]\n",
        "\n",
        "    n_afns = len(self.afn_list)\n",
        "\n",
        "    ann_model = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    ann_model.add(Input(shape=(n,), name=\"input_layer\"))\n",
        "\n",
        "    #add one or more new hidden layers\n",
        "    layers = hp.Int(\"layers\", min_value=min_layers, max_value=max_layers, step=step_layers)\n",
        "    for i in range(layers):\n",
        "      layer_name = f\"hidden_layer_{i}\"\n",
        "      ann_model.add(Dense(\n",
        "                  name=layer_name+'_dense',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(0.01),  #fixed but could be tuned\n",
        "                  kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense')),\n",
        "\n",
        "                  # Tune number of units.\n",
        "                  units=hp.Int(f\"hidden_units{i}\", min_value=min_units, max_value=max_units, step=step_units),\n",
        "\n",
        "                  # Tune the activation function to use.\n",
        "                  activation= self.afn_list[hp.Int(f'afn{i}', min_value=0, max_value=n_afns-1, step=1)],\n",
        "      ))\n",
        "\n",
        "    #now output layer\n",
        "    ann_model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    ann_model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=.1),  #fixed but could be tuned\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001),           #fixed but could be tuned\n",
        "                  metrics=['auc', 'accuracy']\n",
        ")\n",
        "    return ann_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkTvAUuyT_0g"
      },
      "source": [
        "###Now your new one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jvE4cWELs-B5"
      },
      "outputs": [],
      "source": [
        "class CustomerHyperModel(keras_tuner.HyperModel):\n",
        "  def __init__(self, n=6, metrics='auc',\n",
        "                      layers=(1,5,1),\n",
        "                      units=(2,16,1),\n",
        "                      afn_list=('relu', 'leaky_relu'),\n",
        "                      smoothing_list=(.1, .2, 0.3)\n",
        "               ):\n",
        "    self.n = n #number of features\n",
        "    self.metrics = metrics\n",
        "    self.units = units\n",
        "    self.layers = layers\n",
        "    self.afn_list = afn_list\n",
        "    self.smoothing_list = smoothing_list\n",
        "\n",
        "  def build(self, hp):\n",
        "\n",
        "    n = self.n\n",
        "    metrics = self.metrics\n",
        "    min_units = self.units[0]\n",
        "    max_units = self.units[1]\n",
        "    step_units = self.units[2]\n",
        "\n",
        "    min_layers = self.layers[0]\n",
        "    max_layers = self.layers[1]\n",
        "    step_layers = self.layers[2]\n",
        "\n",
        "    n_afns = len(self.afn_list)\n",
        "\n",
        "    ann_model = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    ann_model.add(Input(shape=(n,), name=\"input_layer\"))\n",
        "\n",
        "    #add one or more new hidden layers\n",
        "    layers = hp.Int(\"layers\", min_value=min_layers, max_value=max_layers, step=step_layers)\n",
        "    for i in range(layers):\n",
        "      layer_name = f\"hidden_layer_{i}\"\n",
        "      ann_model.add(Dense(\n",
        "                  name=layer_name+'_dense',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(0.01),  #fixed but could be tuned\n",
        "                  kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense')),\n",
        "\n",
        "                  # Tune number of units.\n",
        "                  units=hp.Int(f\"hidden_units{i}\", min_value=min_units, max_value=max_units, step=step_units),\n",
        "\n",
        "                  # Tune the activation function to use.\n",
        "                  activation= self.afn_list[hp.Int(f'afn{i}', min_value=0, max_value=n_afns-1, step=1)],\n",
        "      ))\n",
        "\n",
        "    #now output layer\n",
        "    ann_model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    # Parameterize label smoothing\n",
        "\n",
        "    smoothing = hp.Choice('smoothing', values=self.smoothing_list)\n",
        "\n",
        "    ann_model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=smoothing),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001),           #fixed but could be tuned\n",
        "                  metrics=['auc', 'accuracy']\n",
        ")\n",
        "    return ann_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bbpTb2xsbI7"
      },
      "source": [
        "##Step 2.2 Set up search\n",
        "\n",
        "But bump trials to 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ViKFu8jPsbI7"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(1234)  #need this for replication\n",
        "\n",
        "max_trials = 50\n",
        "\n",
        "hyper_tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=CustomerHyperModel(),\n",
        "    objective=keras_tuner.Objective('auc', 'max'),  #cannot use auc object as previously defined - have to use instance of keras_tuner.Objective class instead\n",
        "    max_trials=max_trials,  #how many models to build, i.e., how many different configs to try\n",
        "    executions_per_trial=1,  #given we have eliminated nondeterminism, can keep this at 1\n",
        "    overwrite=True,\n",
        "    #directory=\"ann/tb\",  #for use by TensorBoard - discussed below\n",
        "    seed=1234,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJt0li41sbI8"
      },
      "source": [
        "##Step 2.3 Create validation set\n",
        "\n",
        "See how we did this for Titanic earlier in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lt2JTBjvoQM",
        "outputId": "548a7dc8-3b0c-49c0-ee77-e550ac361b2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "781"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "len(x_train_cust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KND0qXNcuz-J"
      },
      "outputs": [],
      "source": [
        "x_train_tune_cust = x_train_cust[:-150]  #150/1050 roughly 20% - notice not stratified\n",
        "x_train_val_cust = x_train_cust[-150:]\n",
        "y_train_tune_cust = y_train_cust[:-150]\n",
        "y_train_val_cust = y_train_cust[-150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM_a6arksbI8",
        "outputId": "f0b34bfb-b66f-4969-fa25-8ee6d9baef88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(x_train_val_cust)  #150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd8zkkAlsbI8"
      },
      "source": [
        "##Step 2.4 Do the search\n",
        "\n",
        "Get some coffee. Took me 28 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "MiLWourmqUWJ"
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SgPA-CAasbI8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "hyper_tuner.search(x_train_tune_cust, y_train_tune_cust,\n",
        "                   epochs=100, batch_size=32,\n",
        "                   validation_data=(x_train_val_cust, y_train_val_cust),\n",
        "                   #callbacks=[keras.callbacks.TensorBoard(\"mlops/tb_logs\")]  #for use by TensorBoard\n",
        "                   )\n",
        "tf.keras.backend.clear_session()  #get rid of unused models created during search  #get rid of unused models created during search\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "time_difference = end - start\n",
        "difference_in_minutes = time_difference.total_seconds() / 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEMTDos9sbI9",
        "outputId": "8ed92ef6-0958-484c-fa38-52ae32c19970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The difference between the two datetimes is 25.96502931666667 minutes.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The difference between the two datetimes is {difference_in_minutes} minutes.\")  #28.3 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH6o6zOcsbI9",
        "outputId": "51d7daeb-400c-4faa-f164-0bbcf6880db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': 4,\n",
              " 'hidden_units0': 11,\n",
              " 'afn0': 0,\n",
              " 'smoothing': 0.1,\n",
              " 'hidden_units1': 2,\n",
              " 'afn1': 1,\n",
              " 'hidden_units2': 14,\n",
              " 'afn2': 1,\n",
              " 'hidden_units3': 7,\n",
              " 'afn3': 0,\n",
              " 'hidden_units4': 15,\n",
              " 'afn4': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "best_hp = hyper_tuner.get_best_hyperparameters()[0]\n",
        "best_hp.values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbr7m8h3sbI9"
      },
      "source": [
        "###My results\n",
        "\n",
        "<pre>\n",
        "{'layers': 4,\n",
        " 'hidden_units0': 11,\n",
        " 'afn0': 0,\n",
        " 'smoothing': 0,\n",
        " 'hidden_units1': 2,\n",
        " 'afn1': 1,\n",
        " 'hidden_units2': 14,\n",
        " 'afn2': 1,\n",
        " 'hidden_units3': 7,\n",
        " 'afn3': 0,\n",
        " 'hidden_units4': 15,\n",
        " 'afn4': 0}\n",
        " </pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T27NZG2rsbI9"
      },
      "source": [
        "Reminder:  `hidden_units4` will be ignored given that `layers=4`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P6WXHnDsbI9"
      },
      "source": [
        "##Step 2.5 Train best model\n",
        "\n",
        "We now have the best configuration out of the 40 we tried. It's relatively easy to now train a model using this configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5gDjKK3sbI9",
        "outputId": "21660c33-b78d-41fd-a340-5456c43b7853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.7224 - auc: 0.6641 - loss: 1.4575 - val_accuracy: 0.6600 - val_auc: 0.6382 - val_loss: 1.4291\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7212 - auc: 0.7085 - loss: 1.4104 - val_accuracy: 0.6800 - val_auc: 0.6615 - val_loss: 1.3859\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7347 - auc: 0.7246 - loss: 1.3638 - val_accuracy: 0.7000 - val_auc: 0.6760 - val_loss: 1.3442\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7429 - auc: 0.7350 - loss: 1.3178 - val_accuracy: 0.7200 - val_auc: 0.6877 - val_loss: 1.3048\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7620 - auc: 0.7476 - loss: 1.2736 - val_accuracy: 0.7133 - val_auc: 0.6996 - val_loss: 1.2679\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7664 - auc: 0.7605 - loss: 1.2314 - val_accuracy: 0.7267 - val_auc: 0.7199 - val_loss: 1.2312\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7746 - auc: 0.7737 - loss: 1.1915 - val_accuracy: 0.7200 - val_auc: 0.7303 - val_loss: 1.1989\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7732 - auc: 0.7859 - loss: 1.1555 - val_accuracy: 0.7200 - val_auc: 0.7448 - val_loss: 1.1674\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7761 - auc: 0.7948 - loss: 1.1231 - val_accuracy: 0.7467 - val_auc: 0.7583 - val_loss: 1.1366\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7820 - auc: 0.8035 - loss: 1.0922 - val_accuracy: 0.7867 - val_auc: 0.7740 - val_loss: 1.1044\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7963 - auc: 0.8156 - loss: 1.0593 - val_accuracy: 0.7667 - val_auc: 0.7863 - val_loss: 1.0741\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8311 - auc: 0.8268 - loss: 1.0257 - val_accuracy: 0.7667 - val_auc: 0.8013 - val_loss: 1.0423\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8379 - auc: 0.8380 - loss: 0.9962 - val_accuracy: 0.7667 - val_auc: 0.8135 - val_loss: 1.0170\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8370 - auc: 0.8498 - loss: 0.9708 - val_accuracy: 0.7867 - val_auc: 0.8255 - val_loss: 0.9927\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8363 - auc: 0.8590 - loss: 0.9482 - val_accuracy: 0.7867 - val_auc: 0.8359 - val_loss: 0.9717\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8350 - auc: 0.8670 - loss: 0.9278 - val_accuracy: 0.7867 - val_auc: 0.8384 - val_loss: 0.9515\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8344 - auc: 0.8714 - loss: 0.9092 - val_accuracy: 0.7867 - val_auc: 0.8442 - val_loss: 0.9338\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8348 - auc: 0.8751 - loss: 0.8917 - val_accuracy: 0.7867 - val_auc: 0.8510 - val_loss: 0.9175\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8350 - auc: 0.8809 - loss: 0.8753 - val_accuracy: 0.7867 - val_auc: 0.8534 - val_loss: 0.9020\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8350 - auc: 0.8849 - loss: 0.8603 - val_accuracy: 0.7933 - val_auc: 0.8551 - val_loss: 0.8877\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8361 - auc: 0.8893 - loss: 0.8461 - val_accuracy: 0.7933 - val_auc: 0.8575 - val_loss: 0.8740\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8393 - auc: 0.8915 - loss: 0.8327 - val_accuracy: 0.7933 - val_auc: 0.8579 - val_loss: 0.8618\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8420 - auc: 0.8940 - loss: 0.8199 - val_accuracy: 0.7933 - val_auc: 0.8587 - val_loss: 0.8497\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8434 - auc: 0.8961 - loss: 0.8075 - val_accuracy: 0.7933 - val_auc: 0.8618 - val_loss: 0.8386\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8434 - auc: 0.8984 - loss: 0.7958 - val_accuracy: 0.7933 - val_auc: 0.8642 - val_loss: 0.8276\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8434 - auc: 0.8996 - loss: 0.7847 - val_accuracy: 0.8000 - val_auc: 0.8670 - val_loss: 0.8170\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8438 - auc: 0.9015 - loss: 0.7742 - val_accuracy: 0.8000 - val_auc: 0.8670 - val_loss: 0.8071\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8429 - auc: 0.9029 - loss: 0.7643 - val_accuracy: 0.8000 - val_auc: 0.8679 - val_loss: 0.7976\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8429 - auc: 0.9037 - loss: 0.7548 - val_accuracy: 0.7933 - val_auc: 0.8691 - val_loss: 0.7885\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8483 - auc: 0.9050 - loss: 0.7458 - val_accuracy: 0.8000 - val_auc: 0.8685 - val_loss: 0.7796\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8483 - auc: 0.9058 - loss: 0.7371 - val_accuracy: 0.8000 - val_auc: 0.8696 - val_loss: 0.7712\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8491 - auc: 0.9065 - loss: 0.7288 - val_accuracy: 0.8000 - val_auc: 0.8699 - val_loss: 0.7630\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8509 - auc: 0.9075 - loss: 0.7208 - val_accuracy: 0.8000 - val_auc: 0.8704 - val_loss: 0.7555\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8515 - auc: 0.9091 - loss: 0.7132 - val_accuracy: 0.8000 - val_auc: 0.8706 - val_loss: 0.7480\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8569 - auc: 0.9091 - loss: 0.7059 - val_accuracy: 0.8067 - val_auc: 0.8711 - val_loss: 0.7411\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8587 - auc: 0.9107 - loss: 0.6989 - val_accuracy: 0.8067 - val_auc: 0.8712 - val_loss: 0.7344\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8607 - auc: 0.9109 - loss: 0.6922 - val_accuracy: 0.8133 - val_auc: 0.8694 - val_loss: 0.7280\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8607 - auc: 0.9123 - loss: 0.6858 - val_accuracy: 0.8133 - val_auc: 0.8699 - val_loss: 0.7221\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8607 - auc: 0.9129 - loss: 0.6795 - val_accuracy: 0.8133 - val_auc: 0.8699 - val_loss: 0.7162\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8602 - auc: 0.9135 - loss: 0.6735 - val_accuracy: 0.8133 - val_auc: 0.8706 - val_loss: 0.7106\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8650 - auc: 0.9136 - loss: 0.6677 - val_accuracy: 0.8200 - val_auc: 0.8690 - val_loss: 0.7053\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8670 - auc: 0.9144 - loss: 0.6621 - val_accuracy: 0.8200 - val_auc: 0.8698 - val_loss: 0.7002\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - auc: 0.9146 - loss: 0.6567 - val_accuracy: 0.8267 - val_auc: 0.8696 - val_loss: 0.6952\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - auc: 0.9152 - loss: 0.6515 - val_accuracy: 0.8267 - val_auc: 0.8691 - val_loss: 0.6905\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8710 - auc: 0.9154 - loss: 0.6465 - val_accuracy: 0.8267 - val_auc: 0.8693 - val_loss: 0.6860\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - auc: 0.9160 - loss: 0.6416 - val_accuracy: 0.8267 - val_auc: 0.8701 - val_loss: 0.6816\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - auc: 0.9164 - loss: 0.6369 - val_accuracy: 0.8267 - val_auc: 0.8701 - val_loss: 0.6773\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8710 - auc: 0.9164 - loss: 0.6323 - val_accuracy: 0.8267 - val_auc: 0.8693 - val_loss: 0.6732\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8692 - auc: 0.9160 - loss: 0.6280 - val_accuracy: 0.8267 - val_auc: 0.8678 - val_loss: 0.6691\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8693 - auc: 0.9166 - loss: 0.6238 - val_accuracy: 0.8267 - val_auc: 0.8684 - val_loss: 0.6651\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8693 - auc: 0.9170 - loss: 0.6197 - val_accuracy: 0.8333 - val_auc: 0.8691 - val_loss: 0.6612\n"
          ]
        }
      ],
      "source": [
        "hypermodel = CustomerHyperModel()\n",
        "customer_model = hypermodel.build(best_hp)\n",
        "training = customer_model.fit(x_train_tune_cust, y_train_tune_cust, epochs=100, validation_data=(x_train_val_cust, y_train_val_cust),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
        "                                      monitor='val_auc',\n",
        "                                      mode='max',\n",
        "                                      patience=15,\n",
        "                                      restore_best_weights=True)\n",
        "                   ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDAU4Oc9v1yz"
      },
      "source": [
        "Looks pretty good in terms of training and validation results matching up. You should stop at epoch 51 with these results.\n",
        "\n",
        "<pre>\n",
        "Epoch 51/100\n",
        "accuracy: 0.8693 - auc: 0.9170 - loss: 0.6197 - val_accuracy: 0.8333 - val_auc: 0.8691 - val_loss: 0.6612\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "GZhJZBq2sbI9",
        "outputId": "65047136-637f-4db4-eb5b-83a8754f9b62"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_0_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │            \u001b[38;5;34m77\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m24\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │            \u001b[38;5;34m42\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_3_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m105\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_0_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_3_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m770\u001b[0m (3.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">770</span> (3.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m514\u001b[0m (2.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> (2.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "customer_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18rGEeu_sbI-",
        "outputId": "88de1d63-4624-4d8f-f6e7-d7294534f4f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "len(training.history['auc'])  #51 - early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dPH7Bj-sbI-",
        "outputId": "50754fb9-a6ac-4eaf-f8b0-89790d0a2850"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8929543495178223"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "training.history['auc'][-1]  #0.8929543495178223"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "jUZBnQdisbI-",
        "outputId": "d3064b22-2346-4393-a8d3-3e6d7642ca60"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(training.history['auc'])\n",
        "plt.plot(training.history['loss'])\n",
        "plt.title('ROC AUC')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['ROC AUC', 'loss'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W72x19iTsbI-"
      },
      "source": [
        "##Step 2.6 Check on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMNVNy__sbI-",
        "outputId": "7828bcae-13ab-4983-a027-f4a042f480e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.14100425, 0.15412292, 0.06318091, 0.81507254, 0.42360467],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "yraw = customer_model.predict(x_test_cust)[:,0]\n",
        "\n",
        "yraw[:5]  #[0.14100425, 0.15412292, 0.06318091, 0.81507254, 0.42360467]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "HVU4kt6tsbI-",
        "outputId": "ce7083dd-4e40-4418-983e-0b937914b745"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79277f56e450>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_81654 th:not(.index_name) {\n",
              "  background-color: #800000;\n",
              "  color: white;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_81654_row0_col0, #T_81654_row0_col1, #T_81654_row0_col3, #T_81654_row0_col5, #T_81654_row1_col0, #T_81654_row1_col1, #T_81654_row1_col3, #T_81654_row1_col5, #T_81654_row2_col0, #T_81654_row2_col1, #T_81654_row2_col3, #T_81654_row2_col5, #T_81654_row3_col0, #T_81654_row3_col1, #T_81654_row3_col2, #T_81654_row3_col3, #T_81654_row3_col5, #T_81654_row4_col0, #T_81654_row4_col1, #T_81654_row4_col2, #T_81654_row4_col3, #T_81654_row4_col5, #T_81654_row5_col0, #T_81654_row5_col1, #T_81654_row5_col2, #T_81654_row5_col3, #T_81654_row5_col5, #T_81654_row6_col0, #T_81654_row6_col1, #T_81654_row6_col2, #T_81654_row7_col0, #T_81654_row7_col1, #T_81654_row7_col2, #T_81654_row7_col3, #T_81654_row8_col0, #T_81654_row8_col1, #T_81654_row8_col2, #T_81654_row8_col3, #T_81654_row9_col0, #T_81654_row9_col1, #T_81654_row9_col2, #T_81654_row9_col3, #T_81654_row9_col5, #T_81654_row10_col0, #T_81654_row10_col1, #T_81654_row10_col2, #T_81654_row10_col3, #T_81654_row10_col5, #T_81654_row11_col0, #T_81654_row11_col1, #T_81654_row11_col2, #T_81654_row11_col3, #T_81654_row11_col5, #T_81654_row12_col0, #T_81654_row12_col1, #T_81654_row12_col2, #T_81654_row12_col3, #T_81654_row12_col5, #T_81654_row13_col0, #T_81654_row13_col1, #T_81654_row13_col2, #T_81654_row13_col3, #T_81654_row13_col5, #T_81654_row14_col0, #T_81654_row14_col1, #T_81654_row14_col2, #T_81654_row14_col3, #T_81654_row14_col5, #T_81654_row15_col0, #T_81654_row15_col1, #T_81654_row15_col2, #T_81654_row15_col3, #T_81654_row15_col5, #T_81654_row16_col0, #T_81654_row16_col1, #T_81654_row16_col2, #T_81654_row16_col3, #T_81654_row16_col5, #T_81654_row17_col0, #T_81654_row17_col1, #T_81654_row17_col2, #T_81654_row17_col3, #T_81654_row17_col5, #T_81654_row18_col0, #T_81654_row18_col2, #T_81654_row18_col3, #T_81654_row18_col5, #T_81654_row19_col0, #T_81654_row19_col1, #T_81654_row19_col2, #T_81654_row19_col3, #T_81654_row19_col5, #T_81654_row20_col1, #T_81654_row20_col2, #T_81654_row20_col3, #T_81654_row20_col5 {\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_81654_row0_col2, #T_81654_row0_col4, #T_81654_row1_col2, #T_81654_row1_col4, #T_81654_row2_col2, #T_81654_row2_col4, #T_81654_row3_col4, #T_81654_row4_col4, #T_81654_row5_col4, #T_81654_row6_col3, #T_81654_row6_col4, #T_81654_row6_col5, #T_81654_row7_col4, #T_81654_row7_col5, #T_81654_row8_col4, #T_81654_row8_col5, #T_81654_row9_col4, #T_81654_row10_col4, #T_81654_row11_col4, #T_81654_row12_col4, #T_81654_row13_col4, #T_81654_row14_col4, #T_81654_row15_col4, #T_81654_row16_col4, #T_81654_row17_col4, #T_81654_row18_col1, #T_81654_row18_col4, #T_81654_row19_col4, #T_81654_row20_col0, #T_81654_row20_col4 {\n",
              "  background-color: pink;\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_81654\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_81654_level0_col0\" class=\"col_heading level0 col0\" >threshold</th>\n",
              "      <th id=\"T_81654_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
              "      <th id=\"T_81654_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
              "      <th id=\"T_81654_level0_col3\" class=\"col_heading level0 col3\" >f1</th>\n",
              "      <th id=\"T_81654_level0_col4\" class=\"col_heading level0 col4\" >auc</th>\n",
              "      <th id=\"T_81654_level0_col5\" class=\"col_heading level0 col5\" >accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_81654_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
              "      <td id=\"T_81654_row0_col1\" class=\"data row0 col1\" >0.32</td>\n",
              "      <td id=\"T_81654_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
              "      <td id=\"T_81654_row0_col3\" class=\"data row0 col3\" >0.49</td>\n",
              "      <td id=\"T_81654_row0_col4\" class=\"data row0 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row0_col5\" class=\"data row0 col5\" >0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_81654_row1_col0\" class=\"data row1 col0\" >0.05</td>\n",
              "      <td id=\"T_81654_row1_col1\" class=\"data row1 col1\" >0.33</td>\n",
              "      <td id=\"T_81654_row1_col2\" class=\"data row1 col2\" >1.00</td>\n",
              "      <td id=\"T_81654_row1_col3\" class=\"data row1 col3\" >0.49</td>\n",
              "      <td id=\"T_81654_row1_col4\" class=\"data row1 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row1_col5\" class=\"data row1 col5\" >0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_81654_row2_col0\" class=\"data row2 col0\" >0.10</td>\n",
              "      <td id=\"T_81654_row2_col1\" class=\"data row2 col1\" >0.34</td>\n",
              "      <td id=\"T_81654_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
              "      <td id=\"T_81654_row2_col3\" class=\"data row2 col3\" >0.50</td>\n",
              "      <td id=\"T_81654_row2_col4\" class=\"data row2 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row2_col5\" class=\"data row2 col5\" >0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_81654_row3_col0\" class=\"data row3 col0\" >0.15</td>\n",
              "      <td id=\"T_81654_row3_col1\" class=\"data row3 col1\" >0.44</td>\n",
              "      <td id=\"T_81654_row3_col2\" class=\"data row3 col2\" >0.95</td>\n",
              "      <td id=\"T_81654_row3_col3\" class=\"data row3 col3\" >0.60</td>\n",
              "      <td id=\"T_81654_row3_col4\" class=\"data row3 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row3_col5\" class=\"data row3 col5\" >0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_81654_row4_col0\" class=\"data row4 col0\" >0.20</td>\n",
              "      <td id=\"T_81654_row4_col1\" class=\"data row4 col1\" >0.56</td>\n",
              "      <td id=\"T_81654_row4_col2\" class=\"data row4 col2\" >0.90</td>\n",
              "      <td id=\"T_81654_row4_col3\" class=\"data row4 col3\" >0.69</td>\n",
              "      <td id=\"T_81654_row4_col4\" class=\"data row4 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row4_col5\" class=\"data row4 col5\" >0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_81654_row5_col0\" class=\"data row5 col0\" >0.25</td>\n",
              "      <td id=\"T_81654_row5_col1\" class=\"data row5 col1\" >0.65</td>\n",
              "      <td id=\"T_81654_row5_col2\" class=\"data row5 col2\" >0.83</td>\n",
              "      <td id=\"T_81654_row5_col3\" class=\"data row5 col3\" >0.73</td>\n",
              "      <td id=\"T_81654_row5_col4\" class=\"data row5 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row5_col5\" class=\"data row5 col5\" >0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_81654_row6_col0\" class=\"data row6 col0\" >0.30</td>\n",
              "      <td id=\"T_81654_row6_col1\" class=\"data row6 col1\" >0.77</td>\n",
              "      <td id=\"T_81654_row6_col2\" class=\"data row6 col2\" >0.73</td>\n",
              "      <td id=\"T_81654_row6_col3\" class=\"data row6 col3\" >0.75</td>\n",
              "      <td id=\"T_81654_row6_col4\" class=\"data row6 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row6_col5\" class=\"data row6 col5\" >0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_81654_row7_col0\" class=\"data row7 col0\" >0.35</td>\n",
              "      <td id=\"T_81654_row7_col1\" class=\"data row7 col1\" >0.80</td>\n",
              "      <td id=\"T_81654_row7_col2\" class=\"data row7 col2\" >0.68</td>\n",
              "      <td id=\"T_81654_row7_col3\" class=\"data row7 col3\" >0.74</td>\n",
              "      <td id=\"T_81654_row7_col4\" class=\"data row7 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row7_col5\" class=\"data row7 col5\" >0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_81654_row8_col0\" class=\"data row8 col0\" >0.40</td>\n",
              "      <td id=\"T_81654_row8_col1\" class=\"data row8 col1\" >0.81</td>\n",
              "      <td id=\"T_81654_row8_col2\" class=\"data row8 col2\" >0.67</td>\n",
              "      <td id=\"T_81654_row8_col3\" class=\"data row8 col3\" >0.73</td>\n",
              "      <td id=\"T_81654_row8_col4\" class=\"data row8 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row8_col5\" class=\"data row8 col5\" >0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_81654_row9_col0\" class=\"data row9 col0\" >0.45</td>\n",
              "      <td id=\"T_81654_row9_col1\" class=\"data row9 col1\" >0.82</td>\n",
              "      <td id=\"T_81654_row9_col2\" class=\"data row9 col2\" >0.59</td>\n",
              "      <td id=\"T_81654_row9_col3\" class=\"data row9 col3\" >0.69</td>\n",
              "      <td id=\"T_81654_row9_col4\" class=\"data row9 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row9_col5\" class=\"data row9 col5\" >0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_81654_row10_col0\" class=\"data row10 col0\" >0.50</td>\n",
              "      <td id=\"T_81654_row10_col1\" class=\"data row10 col1\" >0.85</td>\n",
              "      <td id=\"T_81654_row10_col2\" class=\"data row10 col2\" >0.54</td>\n",
              "      <td id=\"T_81654_row10_col3\" class=\"data row10 col3\" >0.66</td>\n",
              "      <td id=\"T_81654_row10_col4\" class=\"data row10 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row10_col5\" class=\"data row10 col5\" >0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_81654_row11_col0\" class=\"data row11 col0\" >0.55</td>\n",
              "      <td id=\"T_81654_row11_col1\" class=\"data row11 col1\" >0.84</td>\n",
              "      <td id=\"T_81654_row11_col2\" class=\"data row11 col2\" >0.51</td>\n",
              "      <td id=\"T_81654_row11_col3\" class=\"data row11 col3\" >0.63</td>\n",
              "      <td id=\"T_81654_row11_col4\" class=\"data row11 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row11_col5\" class=\"data row11 col5\" >0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_81654_row12_col0\" class=\"data row12 col0\" >0.60</td>\n",
              "      <td id=\"T_81654_row12_col1\" class=\"data row12 col1\" >0.91</td>\n",
              "      <td id=\"T_81654_row12_col2\" class=\"data row12 col2\" >0.48</td>\n",
              "      <td id=\"T_81654_row12_col3\" class=\"data row12 col3\" >0.62</td>\n",
              "      <td id=\"T_81654_row12_col4\" class=\"data row12 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row12_col5\" class=\"data row12 col5\" >0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_81654_row13_col0\" class=\"data row13 col0\" >0.65</td>\n",
              "      <td id=\"T_81654_row13_col1\" class=\"data row13 col1\" >0.93</td>\n",
              "      <td id=\"T_81654_row13_col2\" class=\"data row13 col2\" >0.43</td>\n",
              "      <td id=\"T_81654_row13_col3\" class=\"data row13 col3\" >0.59</td>\n",
              "      <td id=\"T_81654_row13_col4\" class=\"data row13 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row13_col5\" class=\"data row13 col5\" >0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_81654_row14_col0\" class=\"data row14 col0\" >0.70</td>\n",
              "      <td id=\"T_81654_row14_col1\" class=\"data row14 col1\" >0.93</td>\n",
              "      <td id=\"T_81654_row14_col2\" class=\"data row14 col2\" >0.40</td>\n",
              "      <td id=\"T_81654_row14_col3\" class=\"data row14 col3\" >0.56</td>\n",
              "      <td id=\"T_81654_row14_col4\" class=\"data row14 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row14_col5\" class=\"data row14 col5\" >0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_81654_row15_col0\" class=\"data row15 col0\" >0.75</td>\n",
              "      <td id=\"T_81654_row15_col1\" class=\"data row15 col1\" >0.95</td>\n",
              "      <td id=\"T_81654_row15_col2\" class=\"data row15 col2\" >0.32</td>\n",
              "      <td id=\"T_81654_row15_col3\" class=\"data row15 col3\" >0.48</td>\n",
              "      <td id=\"T_81654_row15_col4\" class=\"data row15 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row15_col5\" class=\"data row15 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_81654_row16_col0\" class=\"data row16 col0\" >0.80</td>\n",
              "      <td id=\"T_81654_row16_col1\" class=\"data row16 col1\" >0.95</td>\n",
              "      <td id=\"T_81654_row16_col2\" class=\"data row16 col2\" >0.30</td>\n",
              "      <td id=\"T_81654_row16_col3\" class=\"data row16 col3\" >0.46</td>\n",
              "      <td id=\"T_81654_row16_col4\" class=\"data row16 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row16_col5\" class=\"data row16 col5\" >0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_81654_row17_col0\" class=\"data row17 col0\" >0.85</td>\n",
              "      <td id=\"T_81654_row17_col1\" class=\"data row17 col1\" >0.92</td>\n",
              "      <td id=\"T_81654_row17_col2\" class=\"data row17 col2\" >0.19</td>\n",
              "      <td id=\"T_81654_row17_col3\" class=\"data row17 col3\" >0.32</td>\n",
              "      <td id=\"T_81654_row17_col4\" class=\"data row17 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row17_col5\" class=\"data row17 col5\" >0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_81654_row18_col0\" class=\"data row18 col0\" >0.90</td>\n",
              "      <td id=\"T_81654_row18_col1\" class=\"data row18 col1\" >1.00</td>\n",
              "      <td id=\"T_81654_row18_col2\" class=\"data row18 col2\" >0.02</td>\n",
              "      <td id=\"T_81654_row18_col3\" class=\"data row18 col3\" >0.03</td>\n",
              "      <td id=\"T_81654_row18_col4\" class=\"data row18 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row18_col5\" class=\"data row18 col5\" >0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_81654_row19_col0\" class=\"data row19 col0\" >0.95</td>\n",
              "      <td id=\"T_81654_row19_col1\" class=\"data row19 col1\" >0.00</td>\n",
              "      <td id=\"T_81654_row19_col2\" class=\"data row19 col2\" >0.00</td>\n",
              "      <td id=\"T_81654_row19_col3\" class=\"data row19 col3\" >0.00</td>\n",
              "      <td id=\"T_81654_row19_col4\" class=\"data row19 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row19_col5\" class=\"data row19 col5\" >0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_81654_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_81654_row20_col0\" class=\"data row20 col0\" >1.00</td>\n",
              "      <td id=\"T_81654_row20_col1\" class=\"data row20 col1\" >0.00</td>\n",
              "      <td id=\"T_81654_row20_col2\" class=\"data row20 col2\" >0.00</td>\n",
              "      <td id=\"T_81654_row20_col3\" class=\"data row20 col3\" >0.00</td>\n",
              "      <td id=\"T_81654_row20_col4\" class=\"data row20 col4\" >0.88</td>\n",
              "      <td id=\"T_81654_row20_col5\" class=\"data row20 col5\" >0.68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "result_df, fancy_df = threshold_results(np.round(np.arange(0.0,1.01,.05), 2), y_test_cust, yraw)\n",
        "fancy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "SZ4a5DvFhvyt",
        "outputId": "76e6f996-6318-4311-f747-8d6c4a5d53b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    threshold  precision  recall    f1   auc  accuracy\n",
              "0        0.00       0.32    1.00  0.49  0.88      0.32\n",
              "1        0.05       0.33    1.00  0.49  0.88      0.34\n",
              "2        0.10       0.34    1.00  0.50  0.88      0.36\n",
              "3        0.15       0.44    0.95  0.60  0.88      0.60\n",
              "4        0.20       0.56    0.90  0.69  0.88      0.74\n",
              "5        0.25       0.65    0.83  0.73  0.88      0.80\n",
              "6        0.30       0.77    0.73  0.75  0.88      0.84\n",
              "7        0.35       0.80    0.68  0.74  0.88      0.84\n",
              "8        0.40       0.81    0.67  0.73  0.88      0.84\n",
              "9        0.45       0.82    0.59  0.69  0.88      0.83\n",
              "10       0.50       0.85    0.54  0.66  0.88      0.82\n",
              "11       0.55       0.84    0.51  0.63  0.88      0.81\n",
              "12       0.60       0.91    0.48  0.62  0.88      0.82\n",
              "13       0.65       0.93    0.43  0.59  0.88      0.81\n",
              "14       0.70       0.93    0.40  0.56  0.88      0.80\n",
              "15       0.75       0.95    0.32  0.48  0.88      0.78\n",
              "16       0.80       0.95    0.30  0.46  0.88      0.77\n",
              "17       0.85       0.92    0.19  0.32  0.88      0.73\n",
              "18       0.90       1.00    0.02  0.03  0.88      0.68\n",
              "19       0.95       0.00    0.00  0.00  0.88      0.68\n",
              "20       1.00       0.00    0.00  0.00  0.88      0.68"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-400fbd16-fc33-43b9-aae3-c35cef276eb5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>auc</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.90</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-400fbd16-fc33-43b9-aae3-c35cef276eb5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-400fbd16-fc33-43b9-aae3-c35cef276eb5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-400fbd16-fc33-43b9-aae3-c35cef276eb5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1b1054c7-08ce-4cfa-a545-1be19af6465d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b1054c7-08ce-4cfa-a545-1be19af6465d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1b1054c7-08ce-4cfa-a545-1be19af6465d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c1ef9458-63a3-45c0-b6a3-3e27d5d62422\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c1ef9458-63a3-45c0-b6a3-3e27d5d62422 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3102418411497714,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.0,\n          0.85,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31315977969568126,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.32,\n          0.33,\n          0.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3322721202640419,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          1.0,\n          0.95,\n          0.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23759008316646468,\n        \"min\": 0.0,\n        \"max\": 0.75,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.49,\n          0.5,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.275280134513746e-16,\n        \"min\": 0.88,\n        \"max\": 0.88,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16756803877544071,\n        \"min\": 0.32,\n        \"max\": 0.84,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzeBbg2psbI_"
      },
      "source": [
        "###My results\n",
        "\n",
        "<img src='https://www.dropbox.com/scl/fi/gjiho9yw1nh7g4wf3y6z1/Screenshot-2025-05-16-at-9.39.03-AM.png?rlkey=szclvo6r0upif3tv1a4lli0da&raw=1' height = 500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCXIw2WpSWDT"
      },
      "source": [
        "#Challenge 2\n",
        "\n",
        "Explore a bit more tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_qd9R4WY639"
      },
      "source": [
        "##Step 2.1 Change the model builder class\n",
        "\n",
        "You can see the original at the start of Challenge 1, same one we used earlier in the notebook.\n",
        "\n",
        "1. Rework layers to between 2 and 5, i.e., remove 1.\n",
        "2. Rework units to between 4 and 16, i.e., remove 2 and 3.\n",
        "3. Parameterize `tf.keras.regularizers.l2(0.01)`. Use as choices .005, .01, .05.\n",
        "4. Skip tuning smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "FjxxRQYUY5ps"
      },
      "outputs": [],
      "source": [
        "class MyHyperModel_v2(keras_tuner.HyperModel):\n",
        "  def __init__(self, n=6, metrics='auc',\n",
        "                      layers=(3,5,1),\n",
        "                      units=(4,16,1),\n",
        "                      afn_list=('relu', 'leaky_relu'),\n",
        "                      l2_list=(0.005, 0.01, 0.05)\n",
        "                      ):\n",
        "    self.n = n #number of features\n",
        "    self.metrics = metrics\n",
        "    self.units = units\n",
        "    self.layers = layers\n",
        "    self.afn_list = afn_list\n",
        "    self.l2_list = l2_list\n",
        "\n",
        "  def build(self, hp):\n",
        "\n",
        "    n = self.n\n",
        "    metrics = self.metrics\n",
        "    min_units = self.units[0]\n",
        "    max_units = self.units[1]\n",
        "    step_units = self.units[2]\n",
        "\n",
        "    min_layers = self.layers[0]\n",
        "    max_layers = self.layers[1]\n",
        "    step_layers = self.layers[2]\n",
        "\n",
        "    n_afns = len(self.afn_list)\n",
        "    n_l2 = len(self.l2_list)\n",
        "\n",
        "    ann_model = Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    ann_model.add(Input(shape=(n,), name=\"input_layer\"))\n",
        "\n",
        "    #add one or more new hidden layers\n",
        "    layers = hp.Int(\"layers\", min_value=min_layers, max_value=max_layers, step=step_layers)\n",
        "    for i in range(layers):\n",
        "      layer_name = f\"hidden_layer_{i}\"\n",
        "      ann_model.add(Dense(\n",
        "                  name=layer_name+'_dense',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(hp.Choice(f'reg_lr{i}', values=self.l2_list)),\n",
        "                  kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense')),\n",
        "\n",
        "                  # Tune number of units.\n",
        "                  units=hp.Int(f\"hidden_units{i}\", min_value=min_units, max_value=max_units, step=step_units),\n",
        "\n",
        "                  # Tune the activation function to use.\n",
        "                  activation= self.afn_list[hp.Int(f'afn{i}', min_value=0, max_value=n_afns-1, step=1)],\n",
        "      ))\n",
        "\n",
        "    #now output layer\n",
        "    ann_model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    ann_model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=.1),  #fixed but could be tuned\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001),           #fixed but could be tuned\n",
        "                  metrics=['auc', 'accuracy']\n",
        ")\n",
        "    return ann_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYBPMEoSfH-B"
      },
      "source": [
        "##Step 2.2 Set up search\n",
        "\n",
        "But bump trials to 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "SrKlSlfTTKQh"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(1234)  #need this for replication\n",
        "\n",
        "max_trials = 100\n",
        "\n",
        "hyper_tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=MyHyperModel_v2(),\n",
        "    objective=keras_tuner.Objective('auc', 'max'),  #cannot use auc object as previously defined - have to use instance of keras_tuner.Objective class instead\n",
        "    max_trials=max_trials,  #how many models to build, i.e., how many different configs to try\n",
        "    executions_per_trial=1,  #given we have eliminated nondeterminism, can keep this at 1\n",
        "    overwrite=True,\n",
        "    #directory=\"ann/tb\",  #for use by TensorBoard\n",
        "    seed=1234,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFOVKemFfwKw"
      },
      "source": [
        "##Step 2.3 Check on validation set\n",
        "\n",
        "If it is not defined, you will have to execute the code again in previous portion of notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSWp8tkNf2S_",
        "outputId": "65502534-28ba-4a9d-d26f-664ad380f2ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "len(x_train_val)  #250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QpGsHFfggpX"
      },
      "source": [
        "##Step 2.4 Do the search\n",
        "\n",
        "Get some coffee. Took me 56 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "h2UAAU1KTKQk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "hyper_tuner.search(x_train_tune, y_train_tune,\n",
        "                   epochs=100, batch_size=32,\n",
        "                   validation_data=(x_train_val, y_train_val),\n",
        "                   #callbacks=[keras.callbacks.TensorBoard(\"mlops/tb_logs\")]  #for use by TensorBoard\n",
        "                   )\n",
        "tf.keras.backend.clear_session()  #get rid of unused models created during search  #get rid of unused models created during search\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "time_difference = end - start\n",
        "difference_in_minutes = time_difference.total_seconds() / 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjv5qDJt8xr3",
        "outputId": "e0e84df0-c718-4f2a-b402-08c0558faf37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The difference between the two datetimes is 57.71595335 minutes.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The difference between the two datetimes is {difference_in_minutes} minutes.\")  #56.17 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA65iu70TKQk",
        "outputId": "8c80585b-4f23-45ca-d6db-adc19faaa9b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': 5,\n",
              " 'reg_lr0': 0.005,\n",
              " 'hidden_units0': 16,\n",
              " 'afn0': 0,\n",
              " 'reg_lr1': 0.005,\n",
              " 'hidden_units1': 5,\n",
              " 'afn1': 0,\n",
              " 'reg_lr2': 0.005,\n",
              " 'hidden_units2': 11,\n",
              " 'afn2': 1,\n",
              " 'reg_lr3': 0.01,\n",
              " 'hidden_units3': 4,\n",
              " 'afn3': 1,\n",
              " 'reg_lr4': 0.005,\n",
              " 'hidden_units4': 5,\n",
              " 'afn4': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "best_hp = hyper_tuner.get_best_hyperparameters()[0]\n",
        "best_hp.values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jizZIQU4TKQk"
      },
      "source": [
        "###My results\n",
        "\n",
        "<pre>\n",
        "{'layers': 4,\n",
        " 'reg_lr0': 0,\n",
        " 'hidden_units0': 10,\n",
        " 'afn0': 0,\n",
        " 'reg_lr1': 0,\n",
        " 'hidden_units1': 4,\n",
        " 'afn1': 0,\n",
        " 'reg_lr2': 1,\n",
        " 'hidden_units2': 12,\n",
        " 'afn2': 0,\n",
        " 'reg_lr3': 1,\n",
        " 'hidden_units3': 15,\n",
        " 'afn3': 0,\n",
        " 'reg_lr4': 2,\n",
        " 'hidden_units4': 12,\n",
        " 'afn4': 0}\n",
        " </pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lQXc4TGkScq"
      },
      "source": [
        "##Step 2.5 Train best model\n",
        "\n",
        "We now have the best configuration out of the 100 we tried. It's relatively easy to now train a model using this configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDJ58VMMkScr",
        "outputId": "8489a37d-d15f-4596-e186-78c08061f64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4429 - auc: 0.6328 - loss: 1.1756 - val_accuracy: 0.4760 - val_auc: 0.6607 - val_loss: 1.1353\n",
            "Epoch 2/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4969 - auc: 0.6885 - loss: 1.1242 - val_accuracy: 0.5960 - val_auc: 0.6839 - val_loss: 1.0967\n",
            "Epoch 3/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6336 - auc: 0.7215 - loss: 1.0865 - val_accuracy: 0.6720 - val_auc: 0.6912 - val_loss: 1.0628\n",
            "Epoch 4/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6802 - auc: 0.7305 - loss: 1.0534 - val_accuracy: 0.6760 - val_auc: 0.7010 - val_loss: 1.0318\n",
            "Epoch 5/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7042 - auc: 0.7263 - loss: 1.0226 - val_accuracy: 0.6920 - val_auc: 0.7006 - val_loss: 1.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7060 - auc: 0.7338 - loss: 0.9906 - val_accuracy: 0.6960 - val_auc: 0.6995 - val_loss: 0.9709\n",
            "Epoch 7/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7111 - auc: 0.7325 - loss: 0.9599 - val_accuracy: 0.6960 - val_auc: 0.6993 - val_loss: 0.9437\n",
            "Epoch 8/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7031 - auc: 0.7333 - loss: 0.9315 - val_accuracy: 0.6640 - val_auc: 0.7074 - val_loss: 0.9182\n",
            "Epoch 9/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7038 - auc: 0.7417 - loss: 0.9044 - val_accuracy: 0.6760 - val_auc: 0.7130 - val_loss: 0.8949\n",
            "Epoch 10/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7013 - auc: 0.7460 - loss: 0.8785 - val_accuracy: 0.6760 - val_auc: 0.7266 - val_loss: 0.8719\n",
            "Epoch 11/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7015 - auc: 0.7572 - loss: 0.8533 - val_accuracy: 0.6680 - val_auc: 0.7453 - val_loss: 0.8521\n",
            "Epoch 12/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7035 - auc: 0.7680 - loss: 0.8324 - val_accuracy: 0.6600 - val_auc: 0.7492 - val_loss: 0.8352\n",
            "Epoch 13/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7061 - auc: 0.7748 - loss: 0.8142 - val_accuracy: 0.6680 - val_auc: 0.7559 - val_loss: 0.8170\n",
            "Epoch 14/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7106 - auc: 0.7829 - loss: 0.7965 - val_accuracy: 0.6800 - val_auc: 0.7613 - val_loss: 0.8035\n",
            "Epoch 15/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7245 - auc: 0.7846 - loss: 0.7827 - val_accuracy: 0.6800 - val_auc: 0.7653 - val_loss: 0.7919\n",
            "Epoch 16/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7221 - auc: 0.7879 - loss: 0.7708 - val_accuracy: 0.6800 - val_auc: 0.7690 - val_loss: 0.7812\n",
            "Epoch 17/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7222 - auc: 0.7919 - loss: 0.7603 - val_accuracy: 0.6840 - val_auc: 0.7693 - val_loss: 0.7712\n",
            "Epoch 18/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7222 - auc: 0.7937 - loss: 0.7505 - val_accuracy: 0.6840 - val_auc: 0.7723 - val_loss: 0.7623\n",
            "Epoch 19/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7216 - auc: 0.7994 - loss: 0.7417 - val_accuracy: 0.6840 - val_auc: 0.7706 - val_loss: 0.7539\n",
            "Epoch 20/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7209 - auc: 0.8003 - loss: 0.7332 - val_accuracy: 0.6840 - val_auc: 0.7764 - val_loss: 0.7467\n",
            "Epoch 21/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7247 - auc: 0.7996 - loss: 0.7257 - val_accuracy: 0.6840 - val_auc: 0.7781 - val_loss: 0.7395\n",
            "Epoch 22/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7247 - auc: 0.8022 - loss: 0.7188 - val_accuracy: 0.6840 - val_auc: 0.7806 - val_loss: 0.7332\n",
            "Epoch 23/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7247 - auc: 0.8021 - loss: 0.7125 - val_accuracy: 0.6840 - val_auc: 0.7801 - val_loss: 0.7272\n",
            "Epoch 24/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7253 - auc: 0.8046 - loss: 0.7067 - val_accuracy: 0.6840 - val_auc: 0.7828 - val_loss: 0.7219\n",
            "Epoch 25/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7260 - auc: 0.8053 - loss: 0.7016 - val_accuracy: 0.6840 - val_auc: 0.7828 - val_loss: 0.7167\n",
            "Epoch 26/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7260 - auc: 0.8053 - loss: 0.6966 - val_accuracy: 0.6840 - val_auc: 0.7824 - val_loss: 0.7120\n",
            "Epoch 27/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7277 - auc: 0.8074 - loss: 0.6921 - val_accuracy: 0.6880 - val_auc: 0.7820 - val_loss: 0.7075\n",
            "Epoch 28/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7277 - auc: 0.8073 - loss: 0.6876 - val_accuracy: 0.6880 - val_auc: 0.7841 - val_loss: 0.7031\n",
            "Epoch 29/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7277 - auc: 0.8078 - loss: 0.6833 - val_accuracy: 0.6880 - val_auc: 0.7844 - val_loss: 0.6991\n",
            "Epoch 30/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7271 - auc: 0.8069 - loss: 0.6794 - val_accuracy: 0.6880 - val_auc: 0.7847 - val_loss: 0.6954\n",
            "Epoch 31/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7271 - auc: 0.8081 - loss: 0.6758 - val_accuracy: 0.6880 - val_auc: 0.7862 - val_loss: 0.6919\n",
            "Epoch 32/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7279 - auc: 0.8093 - loss: 0.6723 - val_accuracy: 0.6880 - val_auc: 0.7890 - val_loss: 0.6885\n",
            "Epoch 33/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7278 - auc: 0.8095 - loss: 0.6690 - val_accuracy: 0.6880 - val_auc: 0.7885 - val_loss: 0.6859\n",
            "Epoch 34/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7296 - auc: 0.8091 - loss: 0.6663 - val_accuracy: 0.6880 - val_auc: 0.7885 - val_loss: 0.6831\n",
            "Epoch 35/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7334 - auc: 0.8102 - loss: 0.6638 - val_accuracy: 0.6880 - val_auc: 0.7865 - val_loss: 0.6802\n",
            "Epoch 36/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7334 - auc: 0.8099 - loss: 0.6613 - val_accuracy: 0.6880 - val_auc: 0.7863 - val_loss: 0.6776\n",
            "Epoch 37/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7337 - auc: 0.8099 - loss: 0.6588 - val_accuracy: 0.6880 - val_auc: 0.7876 - val_loss: 0.6750\n",
            "Epoch 38/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7326 - auc: 0.8107 - loss: 0.6564 - val_accuracy: 0.6880 - val_auc: 0.7871 - val_loss: 0.6727\n",
            "Epoch 39/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7330 - auc: 0.8105 - loss: 0.6542 - val_accuracy: 0.6880 - val_auc: 0.7874 - val_loss: 0.6707\n",
            "Epoch 40/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7325 - auc: 0.8119 - loss: 0.6522 - val_accuracy: 0.6880 - val_auc: 0.7890 - val_loss: 0.6685\n",
            "Epoch 41/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7368 - auc: 0.8127 - loss: 0.6501 - val_accuracy: 0.6960 - val_auc: 0.7915 - val_loss: 0.6666\n",
            "Epoch 42/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7364 - auc: 0.8122 - loss: 0.6483 - val_accuracy: 0.6960 - val_auc: 0.7929 - val_loss: 0.6648\n",
            "Epoch 43/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7388 - auc: 0.8132 - loss: 0.6467 - val_accuracy: 0.6960 - val_auc: 0.7927 - val_loss: 0.6627\n",
            "Epoch 44/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7395 - auc: 0.8144 - loss: 0.6448 - val_accuracy: 0.6960 - val_auc: 0.7946 - val_loss: 0.6610\n",
            "Epoch 45/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7412 - auc: 0.8161 - loss: 0.6430 - val_accuracy: 0.6960 - val_auc: 0.7960 - val_loss: 0.6592\n",
            "Epoch 46/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7426 - auc: 0.8167 - loss: 0.6415 - val_accuracy: 0.7000 - val_auc: 0.7997 - val_loss: 0.6579\n",
            "Epoch 47/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7478 - auc: 0.8159 - loss: 0.6402 - val_accuracy: 0.7040 - val_auc: 0.8004 - val_loss: 0.6563\n",
            "Epoch 48/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7478 - auc: 0.8172 - loss: 0.6387 - val_accuracy: 0.7040 - val_auc: 0.8028 - val_loss: 0.6552\n",
            "Epoch 49/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7490 - auc: 0.8172 - loss: 0.6376 - val_accuracy: 0.7080 - val_auc: 0.8045 - val_loss: 0.6537\n",
            "Epoch 50/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7469 - auc: 0.8181 - loss: 0.6363 - val_accuracy: 0.7080 - val_auc: 0.8035 - val_loss: 0.6526\n",
            "Epoch 51/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7469 - auc: 0.8174 - loss: 0.6352 - val_accuracy: 0.7120 - val_auc: 0.8017 - val_loss: 0.6514\n",
            "Epoch 52/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7469 - auc: 0.8194 - loss: 0.6341 - val_accuracy: 0.7120 - val_auc: 0.8016 - val_loss: 0.6502\n",
            "Epoch 53/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7470 - auc: 0.8195 - loss: 0.6330 - val_accuracy: 0.7080 - val_auc: 0.8043 - val_loss: 0.6490\n",
            "Epoch 54/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7470 - auc: 0.8194 - loss: 0.6319 - val_accuracy: 0.7120 - val_auc: 0.8070 - val_loss: 0.6482\n",
            "Epoch 55/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7488 - auc: 0.8209 - loss: 0.6311 - val_accuracy: 0.7160 - val_auc: 0.8076 - val_loss: 0.6468\n",
            "Epoch 56/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7526 - auc: 0.8222 - loss: 0.6299 - val_accuracy: 0.7160 - val_auc: 0.8078 - val_loss: 0.6462\n",
            "Epoch 57/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7526 - auc: 0.8222 - loss: 0.6292 - val_accuracy: 0.7200 - val_auc: 0.8098 - val_loss: 0.6451\n",
            "Epoch 58/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7510 - auc: 0.8240 - loss: 0.6283 - val_accuracy: 0.7200 - val_auc: 0.8110 - val_loss: 0.6442\n",
            "Epoch 59/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7547 - auc: 0.8231 - loss: 0.6274 - val_accuracy: 0.7200 - val_auc: 0.8123 - val_loss: 0.6434\n",
            "Epoch 60/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7547 - auc: 0.8239 - loss: 0.6266 - val_accuracy: 0.7240 - val_auc: 0.8146 - val_loss: 0.6425\n",
            "Epoch 61/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7537 - auc: 0.8241 - loss: 0.6258 - val_accuracy: 0.7280 - val_auc: 0.8162 - val_loss: 0.6417\n",
            "Epoch 62/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7543 - auc: 0.8252 - loss: 0.6250 - val_accuracy: 0.7280 - val_auc: 0.8126 - val_loss: 0.6409\n",
            "Epoch 63/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7548 - auc: 0.8265 - loss: 0.6243 - val_accuracy: 0.7320 - val_auc: 0.8134 - val_loss: 0.6401\n",
            "Epoch 64/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7548 - auc: 0.8269 - loss: 0.6236 - val_accuracy: 0.7360 - val_auc: 0.8141 - val_loss: 0.6393\n",
            "Epoch 65/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7563 - auc: 0.8275 - loss: 0.6228 - val_accuracy: 0.7400 - val_auc: 0.8154 - val_loss: 0.6386\n",
            "Epoch 66/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7574 - auc: 0.8278 - loss: 0.6221 - val_accuracy: 0.7400 - val_auc: 0.8170 - val_loss: 0.6378\n",
            "Epoch 67/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7573 - auc: 0.8284 - loss: 0.6214 - val_accuracy: 0.7400 - val_auc: 0.8153 - val_loss: 0.6372\n",
            "Epoch 68/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7618 - auc: 0.8302 - loss: 0.6208 - val_accuracy: 0.7440 - val_auc: 0.8166 - val_loss: 0.6365\n",
            "Epoch 69/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7618 - auc: 0.8304 - loss: 0.6202 - val_accuracy: 0.7480 - val_auc: 0.8173 - val_loss: 0.6357\n",
            "Epoch 70/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - auc: 0.8305 - loss: 0.6195 - val_accuracy: 0.7520 - val_auc: 0.8190 - val_loss: 0.6349\n",
            "Epoch 71/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7607 - auc: 0.8314 - loss: 0.6189 - val_accuracy: 0.7480 - val_auc: 0.8205 - val_loss: 0.6342\n",
            "Epoch 72/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7636 - auc: 0.8328 - loss: 0.6183 - val_accuracy: 0.7480 - val_auc: 0.8226 - val_loss: 0.6336\n",
            "Epoch 73/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7630 - auc: 0.8318 - loss: 0.6179 - val_accuracy: 0.7520 - val_auc: 0.8232 - val_loss: 0.6327\n",
            "Epoch 74/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7630 - auc: 0.8325 - loss: 0.6172 - val_accuracy: 0.7520 - val_auc: 0.8220 - val_loss: 0.6321\n",
            "Epoch 75/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7617 - auc: 0.8326 - loss: 0.6168 - val_accuracy: 0.7600 - val_auc: 0.8237 - val_loss: 0.6315\n",
            "Epoch 76/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7675 - auc: 0.8328 - loss: 0.6163 - val_accuracy: 0.7600 - val_auc: 0.8241 - val_loss: 0.6309\n",
            "Epoch 77/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7643 - auc: 0.8339 - loss: 0.6158 - val_accuracy: 0.7560 - val_auc: 0.8250 - val_loss: 0.6302\n",
            "Epoch 78/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7655 - auc: 0.8333 - loss: 0.6153 - val_accuracy: 0.7560 - val_auc: 0.8248 - val_loss: 0.6295\n",
            "Epoch 79/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7673 - auc: 0.8341 - loss: 0.6146 - val_accuracy: 0.7560 - val_auc: 0.8257 - val_loss: 0.6290\n",
            "Epoch 80/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7692 - auc: 0.8337 - loss: 0.6142 - val_accuracy: 0.7520 - val_auc: 0.8253 - val_loss: 0.6280\n",
            "Epoch 81/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7692 - auc: 0.8342 - loss: 0.6134 - val_accuracy: 0.7480 - val_auc: 0.8289 - val_loss: 0.6264\n",
            "Epoch 82/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7693 - auc: 0.8344 - loss: 0.6127 - val_accuracy: 0.7520 - val_auc: 0.8284 - val_loss: 0.6258\n",
            "Epoch 83/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7645 - auc: 0.8349 - loss: 0.6124 - val_accuracy: 0.7520 - val_auc: 0.8276 - val_loss: 0.6253\n",
            "Epoch 84/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7645 - auc: 0.8340 - loss: 0.6121 - val_accuracy: 0.7520 - val_auc: 0.8286 - val_loss: 0.6246\n",
            "Epoch 85/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7649 - auc: 0.8349 - loss: 0.6116 - val_accuracy: 0.7520 - val_auc: 0.8283 - val_loss: 0.6235\n",
            "Epoch 86/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7611 - auc: 0.8349 - loss: 0.6110 - val_accuracy: 0.7520 - val_auc: 0.8289 - val_loss: 0.6229\n",
            "Epoch 87/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7611 - auc: 0.8361 - loss: 0.6105 - val_accuracy: 0.7520 - val_auc: 0.8294 - val_loss: 0.6220\n",
            "Epoch 88/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7611 - auc: 0.8361 - loss: 0.6098 - val_accuracy: 0.7520 - val_auc: 0.8300 - val_loss: 0.6210\n",
            "Epoch 89/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7594 - auc: 0.8367 - loss: 0.6092 - val_accuracy: 0.7560 - val_auc: 0.8289 - val_loss: 0.6206\n",
            "Epoch 90/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7573 - auc: 0.8369 - loss: 0.6087 - val_accuracy: 0.7480 - val_auc: 0.8300 - val_loss: 0.6198\n",
            "Epoch 91/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7616 - auc: 0.8372 - loss: 0.6080 - val_accuracy: 0.7480 - val_auc: 0.8297 - val_loss: 0.6189\n",
            "Epoch 92/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7616 - auc: 0.8375 - loss: 0.6074 - val_accuracy: 0.7480 - val_auc: 0.8298 - val_loss: 0.6183\n",
            "Epoch 93/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7597 - auc: 0.8375 - loss: 0.6069 - val_accuracy: 0.7480 - val_auc: 0.8306 - val_loss: 0.6176\n",
            "Epoch 94/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - auc: 0.8373 - loss: 0.6065 - val_accuracy: 0.7520 - val_auc: 0.8304 - val_loss: 0.6171\n",
            "Epoch 95/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - auc: 0.8378 - loss: 0.6062 - val_accuracy: 0.7520 - val_auc: 0.8310 - val_loss: 0.6165\n",
            "Epoch 96/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7583 - auc: 0.8375 - loss: 0.6058 - val_accuracy: 0.7480 - val_auc: 0.8312 - val_loss: 0.6160\n",
            "Epoch 97/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7587 - auc: 0.8375 - loss: 0.6054 - val_accuracy: 0.7520 - val_auc: 0.8311 - val_loss: 0.6156\n",
            "Epoch 98/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7591 - auc: 0.8375 - loss: 0.6051 - val_accuracy: 0.7560 - val_auc: 0.8314 - val_loss: 0.6152\n",
            "Epoch 99/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7576 - auc: 0.8378 - loss: 0.6047 - val_accuracy: 0.7520 - val_auc: 0.8314 - val_loss: 0.6148\n",
            "Epoch 100/100\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7598 - auc: 0.8381 - loss: 0.6044 - val_accuracy: 0.7520 - val_auc: 0.8320 - val_loss: 0.6143\n"
          ]
        }
      ],
      "source": [
        "hypermodel = MyHyperModel_v2()\n",
        "model = hypermodel.build(best_hp)\n",
        "training = model.fit(x_train, y_train, epochs=100, validation_data=(x_train_val, y_train_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(\n",
        "                                      monitor='val_auc',\n",
        "                                      mode='max',\n",
        "                                      patience=15,\n",
        "                                      restore_best_weights=True)\n",
        "                   ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knWRmGLJyS8f"
      },
      "source": [
        "###Still looking good in terms of overfitting\n",
        "\n",
        "Train and validation scores roughly the same.\n",
        "\n",
        "<pre>\n",
        "Epoch 100/100\n",
        " accuracy: 0.7632 - auc: 0.8295 - loss: 0.6067 - val_accuracy: 0.7640 - val_auc: 0.8169 - val_loss: 0.6165\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "SGwzK4uGZUsS",
        "outputId": "0e3175b5-8428-4651-e3e5-7e7374e4112e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_0_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m85\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │            \u001b[38;5;34m66\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_3_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m48\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_4_dense (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_0_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_3_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_4_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,028\u001b[0m (4.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> (4.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m342\u001b[0m (1.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">342</span> (1.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m686\u001b[0m (2.68 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">686</span> (2.68 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmzsOPKukScr",
        "outputId": "89c7f8a7-c089-4e17-9e64-c4706ff3e3c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "len(training.history['auc'])  #100 - no early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGGtktN0kScr",
        "outputId": "27d549a6-a5a8-47c9-861e-0874da478114"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8292962312698364"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "training.history['auc'][-1]  #0.8220989108085632"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FbLwR2wxkScr",
        "outputId": "3a999013-1653-4c13-f682-fd68bb0cbfb5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(training.history['auc'])\n",
        "plt.plot(training.history['loss'])\n",
        "plt.title('ROC AUC')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['ROC AUC', 'loss'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIUeqfC7kScr"
      },
      "source": [
        "##Step 2.6 Check on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kcRhxjbkScs",
        "outputId": "ddb29eac-8401-4743-f43b-5f3799007760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x792777851e40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.40170518, 0.7951781 , 0.8718802 , 0.15905608, 0.24956107],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "yraw = model.predict(x_test)[:,0]\n",
        "\n",
        "yraw[:5]  #[0.52119124, 0.75168633, 0.8782108 , 0.2019367 , 0.32780498]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "-FiBqT9pkScs",
        "outputId": "64b8f3c1-d037-4ece-f123-39285a30b06d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x792776bf14d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_3d4ee th:not(.index_name) {\n",
              "  background-color: #800000;\n",
              "  color: white;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_3d4ee_row0_col0, #T_3d4ee_row0_col1, #T_3d4ee_row0_col3, #T_3d4ee_row0_col5, #T_3d4ee_row1_col0, #T_3d4ee_row1_col1, #T_3d4ee_row1_col3, #T_3d4ee_row1_col5, #T_3d4ee_row2_col0, #T_3d4ee_row2_col1, #T_3d4ee_row2_col3, #T_3d4ee_row2_col5, #T_3d4ee_row3_col0, #T_3d4ee_row3_col1, #T_3d4ee_row3_col2, #T_3d4ee_row3_col3, #T_3d4ee_row3_col5, #T_3d4ee_row4_col0, #T_3d4ee_row4_col1, #T_3d4ee_row4_col2, #T_3d4ee_row4_col3, #T_3d4ee_row4_col5, #T_3d4ee_row5_col0, #T_3d4ee_row5_col1, #T_3d4ee_row5_col2, #T_3d4ee_row5_col5, #T_3d4ee_row6_col0, #T_3d4ee_row6_col1, #T_3d4ee_row6_col2, #T_3d4ee_row6_col3, #T_3d4ee_row6_col5, #T_3d4ee_row7_col0, #T_3d4ee_row7_col1, #T_3d4ee_row7_col2, #T_3d4ee_row7_col3, #T_3d4ee_row7_col5, #T_3d4ee_row8_col0, #T_3d4ee_row8_col1, #T_3d4ee_row8_col2, #T_3d4ee_row8_col3, #T_3d4ee_row8_col5, #T_3d4ee_row9_col0, #T_3d4ee_row9_col1, #T_3d4ee_row9_col2, #T_3d4ee_row9_col3, #T_3d4ee_row9_col5, #T_3d4ee_row10_col0, #T_3d4ee_row10_col1, #T_3d4ee_row10_col2, #T_3d4ee_row10_col3, #T_3d4ee_row10_col5, #T_3d4ee_row11_col0, #T_3d4ee_row11_col1, #T_3d4ee_row11_col2, #T_3d4ee_row11_col3, #T_3d4ee_row12_col0, #T_3d4ee_row12_col1, #T_3d4ee_row12_col2, #T_3d4ee_row12_col3, #T_3d4ee_row12_col5, #T_3d4ee_row13_col0, #T_3d4ee_row13_col1, #T_3d4ee_row13_col2, #T_3d4ee_row13_col3, #T_3d4ee_row13_col5, #T_3d4ee_row14_col0, #T_3d4ee_row14_col1, #T_3d4ee_row14_col2, #T_3d4ee_row14_col3, #T_3d4ee_row14_col5, #T_3d4ee_row15_col0, #T_3d4ee_row15_col1, #T_3d4ee_row15_col2, #T_3d4ee_row15_col3, #T_3d4ee_row15_col5, #T_3d4ee_row16_col0, #T_3d4ee_row16_col1, #T_3d4ee_row16_col2, #T_3d4ee_row16_col3, #T_3d4ee_row16_col5, #T_3d4ee_row17_col0, #T_3d4ee_row17_col1, #T_3d4ee_row17_col2, #T_3d4ee_row17_col3, #T_3d4ee_row17_col5, #T_3d4ee_row18_col0, #T_3d4ee_row18_col2, #T_3d4ee_row18_col3, #T_3d4ee_row18_col5, #T_3d4ee_row19_col0, #T_3d4ee_row19_col1, #T_3d4ee_row19_col2, #T_3d4ee_row19_col3, #T_3d4ee_row19_col5, #T_3d4ee_row20_col1, #T_3d4ee_row20_col2, #T_3d4ee_row20_col3, #T_3d4ee_row20_col5 {\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_3d4ee_row0_col2, #T_3d4ee_row0_col4, #T_3d4ee_row1_col2, #T_3d4ee_row1_col4, #T_3d4ee_row2_col2, #T_3d4ee_row2_col4, #T_3d4ee_row3_col4, #T_3d4ee_row4_col4, #T_3d4ee_row5_col3, #T_3d4ee_row5_col4, #T_3d4ee_row6_col4, #T_3d4ee_row7_col4, #T_3d4ee_row8_col4, #T_3d4ee_row9_col4, #T_3d4ee_row10_col4, #T_3d4ee_row11_col4, #T_3d4ee_row11_col5, #T_3d4ee_row12_col4, #T_3d4ee_row13_col4, #T_3d4ee_row14_col4, #T_3d4ee_row15_col4, #T_3d4ee_row16_col4, #T_3d4ee_row17_col4, #T_3d4ee_row18_col1, #T_3d4ee_row18_col4, #T_3d4ee_row19_col4, #T_3d4ee_row20_col0, #T_3d4ee_row20_col4 {\n",
              "  background-color: pink;\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_3d4ee\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_3d4ee_level0_col0\" class=\"col_heading level0 col0\" >threshold</th>\n",
              "      <th id=\"T_3d4ee_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
              "      <th id=\"T_3d4ee_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
              "      <th id=\"T_3d4ee_level0_col3\" class=\"col_heading level0 col3\" >f1</th>\n",
              "      <th id=\"T_3d4ee_level0_col4\" class=\"col_heading level0 col4\" >auc</th>\n",
              "      <th id=\"T_3d4ee_level0_col5\" class=\"col_heading level0 col5\" >accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_3d4ee_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
              "      <td id=\"T_3d4ee_row0_col1\" class=\"data row0 col1\" >0.43</td>\n",
              "      <td id=\"T_3d4ee_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
              "      <td id=\"T_3d4ee_row0_col3\" class=\"data row0 col3\" >0.60</td>\n",
              "      <td id=\"T_3d4ee_row0_col4\" class=\"data row0 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row0_col5\" class=\"data row0 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_3d4ee_row1_col0\" class=\"data row1 col0\" >0.05</td>\n",
              "      <td id=\"T_3d4ee_row1_col1\" class=\"data row1 col1\" >0.43</td>\n",
              "      <td id=\"T_3d4ee_row1_col2\" class=\"data row1 col2\" >1.00</td>\n",
              "      <td id=\"T_3d4ee_row1_col3\" class=\"data row1 col3\" >0.60</td>\n",
              "      <td id=\"T_3d4ee_row1_col4\" class=\"data row1 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row1_col5\" class=\"data row1 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_3d4ee_row2_col0\" class=\"data row2 col0\" >0.10</td>\n",
              "      <td id=\"T_3d4ee_row2_col1\" class=\"data row2 col1\" >0.43</td>\n",
              "      <td id=\"T_3d4ee_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
              "      <td id=\"T_3d4ee_row2_col3\" class=\"data row2 col3\" >0.60</td>\n",
              "      <td id=\"T_3d4ee_row2_col4\" class=\"data row2 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row2_col5\" class=\"data row2 col5\" >0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_3d4ee_row3_col0\" class=\"data row3 col0\" >0.15</td>\n",
              "      <td id=\"T_3d4ee_row3_col1\" class=\"data row3 col1\" >0.45</td>\n",
              "      <td id=\"T_3d4ee_row3_col2\" class=\"data row3 col2\" >0.98</td>\n",
              "      <td id=\"T_3d4ee_row3_col3\" class=\"data row3 col3\" >0.62</td>\n",
              "      <td id=\"T_3d4ee_row3_col4\" class=\"data row3 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row3_col5\" class=\"data row3 col5\" >0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_3d4ee_row4_col0\" class=\"data row4 col0\" >0.20</td>\n",
              "      <td id=\"T_3d4ee_row4_col1\" class=\"data row4 col1\" >0.53</td>\n",
              "      <td id=\"T_3d4ee_row4_col2\" class=\"data row4 col2\" >0.91</td>\n",
              "      <td id=\"T_3d4ee_row4_col3\" class=\"data row4 col3\" >0.67</td>\n",
              "      <td id=\"T_3d4ee_row4_col4\" class=\"data row4 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row4_col5\" class=\"data row4 col5\" >0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_3d4ee_row5_col0\" class=\"data row5 col0\" >0.25</td>\n",
              "      <td id=\"T_3d4ee_row5_col1\" class=\"data row5 col1\" >0.59</td>\n",
              "      <td id=\"T_3d4ee_row5_col2\" class=\"data row5 col2\" >0.86</td>\n",
              "      <td id=\"T_3d4ee_row5_col3\" class=\"data row5 col3\" >0.70</td>\n",
              "      <td id=\"T_3d4ee_row5_col4\" class=\"data row5 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row5_col5\" class=\"data row5 col5\" >0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_3d4ee_row6_col0\" class=\"data row6 col0\" >0.30</td>\n",
              "      <td id=\"T_3d4ee_row6_col1\" class=\"data row6 col1\" >0.62</td>\n",
              "      <td id=\"T_3d4ee_row6_col2\" class=\"data row6 col2\" >0.75</td>\n",
              "      <td id=\"T_3d4ee_row6_col3\" class=\"data row6 col3\" >0.68</td>\n",
              "      <td id=\"T_3d4ee_row6_col4\" class=\"data row6 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row6_col5\" class=\"data row6 col5\" >0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_3d4ee_row7_col0\" class=\"data row7 col0\" >0.35</td>\n",
              "      <td id=\"T_3d4ee_row7_col1\" class=\"data row7 col1\" >0.65</td>\n",
              "      <td id=\"T_3d4ee_row7_col2\" class=\"data row7 col2\" >0.73</td>\n",
              "      <td id=\"T_3d4ee_row7_col3\" class=\"data row7 col3\" >0.69</td>\n",
              "      <td id=\"T_3d4ee_row7_col4\" class=\"data row7 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row7_col5\" class=\"data row7 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_3d4ee_row8_col0\" class=\"data row8 col0\" >0.40</td>\n",
              "      <td id=\"T_3d4ee_row8_col1\" class=\"data row8 col1\" >0.68</td>\n",
              "      <td id=\"T_3d4ee_row8_col2\" class=\"data row8 col2\" >0.68</td>\n",
              "      <td id=\"T_3d4ee_row8_col3\" class=\"data row8 col3\" >0.68</td>\n",
              "      <td id=\"T_3d4ee_row8_col4\" class=\"data row8 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row8_col5\" class=\"data row8 col5\" >0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_3d4ee_row9_col0\" class=\"data row9 col0\" >0.45</td>\n",
              "      <td id=\"T_3d4ee_row9_col1\" class=\"data row9 col1\" >0.76</td>\n",
              "      <td id=\"T_3d4ee_row9_col2\" class=\"data row9 col2\" >0.57</td>\n",
              "      <td id=\"T_3d4ee_row9_col3\" class=\"data row9 col3\" >0.65</td>\n",
              "      <td id=\"T_3d4ee_row9_col4\" class=\"data row9 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row9_col5\" class=\"data row9 col5\" >0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_3d4ee_row10_col0\" class=\"data row10 col0\" >0.50</td>\n",
              "      <td id=\"T_3d4ee_row10_col1\" class=\"data row10 col1\" >0.83</td>\n",
              "      <td id=\"T_3d4ee_row10_col2\" class=\"data row10 col2\" >0.51</td>\n",
              "      <td id=\"T_3d4ee_row10_col3\" class=\"data row10 col3\" >0.63</td>\n",
              "      <td id=\"T_3d4ee_row10_col4\" class=\"data row10 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row10_col5\" class=\"data row10 col5\" >0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_3d4ee_row11_col0\" class=\"data row11 col0\" >0.55</td>\n",
              "      <td id=\"T_3d4ee_row11_col1\" class=\"data row11 col1\" >0.90</td>\n",
              "      <td id=\"T_3d4ee_row11_col2\" class=\"data row11 col2\" >0.48</td>\n",
              "      <td id=\"T_3d4ee_row11_col3\" class=\"data row11 col3\" >0.63</td>\n",
              "      <td id=\"T_3d4ee_row11_col4\" class=\"data row11 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row11_col5\" class=\"data row11 col5\" >0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_3d4ee_row12_col0\" class=\"data row12 col0\" >0.60</td>\n",
              "      <td id=\"T_3d4ee_row12_col1\" class=\"data row12 col1\" >0.91</td>\n",
              "      <td id=\"T_3d4ee_row12_col2\" class=\"data row12 col2\" >0.45</td>\n",
              "      <td id=\"T_3d4ee_row12_col3\" class=\"data row12 col3\" >0.60</td>\n",
              "      <td id=\"T_3d4ee_row12_col4\" class=\"data row12 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row12_col5\" class=\"data row12 col5\" >0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_3d4ee_row13_col0\" class=\"data row13 col0\" >0.65</td>\n",
              "      <td id=\"T_3d4ee_row13_col1\" class=\"data row13 col1\" >0.92</td>\n",
              "      <td id=\"T_3d4ee_row13_col2\" class=\"data row13 col2\" >0.43</td>\n",
              "      <td id=\"T_3d4ee_row13_col3\" class=\"data row13 col3\" >0.59</td>\n",
              "      <td id=\"T_3d4ee_row13_col4\" class=\"data row13 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row13_col5\" class=\"data row13 col5\" >0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_3d4ee_row14_col0\" class=\"data row14 col0\" >0.70</td>\n",
              "      <td id=\"T_3d4ee_row14_col1\" class=\"data row14 col1\" >0.92</td>\n",
              "      <td id=\"T_3d4ee_row14_col2\" class=\"data row14 col2\" >0.40</td>\n",
              "      <td id=\"T_3d4ee_row14_col3\" class=\"data row14 col3\" >0.56</td>\n",
              "      <td id=\"T_3d4ee_row14_col4\" class=\"data row14 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row14_col5\" class=\"data row14 col5\" >0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_3d4ee_row15_col0\" class=\"data row15 col0\" >0.75</td>\n",
              "      <td id=\"T_3d4ee_row15_col1\" class=\"data row15 col1\" >0.91</td>\n",
              "      <td id=\"T_3d4ee_row15_col2\" class=\"data row15 col2\" >0.36</td>\n",
              "      <td id=\"T_3d4ee_row15_col3\" class=\"data row15 col3\" >0.52</td>\n",
              "      <td id=\"T_3d4ee_row15_col4\" class=\"data row15 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row15_col5\" class=\"data row15 col5\" >0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_3d4ee_row16_col0\" class=\"data row16 col0\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row16_col1\" class=\"data row16 col1\" >0.91</td>\n",
              "      <td id=\"T_3d4ee_row16_col2\" class=\"data row16 col2\" >0.27</td>\n",
              "      <td id=\"T_3d4ee_row16_col3\" class=\"data row16 col3\" >0.42</td>\n",
              "      <td id=\"T_3d4ee_row16_col4\" class=\"data row16 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row16_col5\" class=\"data row16 col5\" >0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_3d4ee_row17_col0\" class=\"data row17 col0\" >0.85</td>\n",
              "      <td id=\"T_3d4ee_row17_col1\" class=\"data row17 col1\" >0.90</td>\n",
              "      <td id=\"T_3d4ee_row17_col2\" class=\"data row17 col2\" >0.17</td>\n",
              "      <td id=\"T_3d4ee_row17_col3\" class=\"data row17 col3\" >0.28</td>\n",
              "      <td id=\"T_3d4ee_row17_col4\" class=\"data row17 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row17_col5\" class=\"data row17 col5\" >0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_3d4ee_row18_col0\" class=\"data row18 col0\" >0.90</td>\n",
              "      <td id=\"T_3d4ee_row18_col1\" class=\"data row18 col1\" >1.00</td>\n",
              "      <td id=\"T_3d4ee_row18_col2\" class=\"data row18 col2\" >0.03</td>\n",
              "      <td id=\"T_3d4ee_row18_col3\" class=\"data row18 col3\" >0.05</td>\n",
              "      <td id=\"T_3d4ee_row18_col4\" class=\"data row18 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row18_col5\" class=\"data row18 col5\" >0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_3d4ee_row19_col0\" class=\"data row19 col0\" >0.95</td>\n",
              "      <td id=\"T_3d4ee_row19_col1\" class=\"data row19 col1\" >0.00</td>\n",
              "      <td id=\"T_3d4ee_row19_col2\" class=\"data row19 col2\" >0.00</td>\n",
              "      <td id=\"T_3d4ee_row19_col3\" class=\"data row19 col3\" >0.00</td>\n",
              "      <td id=\"T_3d4ee_row19_col4\" class=\"data row19 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row19_col5\" class=\"data row19 col5\" >0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_3d4ee_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_3d4ee_row20_col0\" class=\"data row20 col0\" >1.00</td>\n",
              "      <td id=\"T_3d4ee_row20_col1\" class=\"data row20 col1\" >0.00</td>\n",
              "      <td id=\"T_3d4ee_row20_col2\" class=\"data row20 col2\" >0.00</td>\n",
              "      <td id=\"T_3d4ee_row20_col3\" class=\"data row20 col3\" >0.00</td>\n",
              "      <td id=\"T_3d4ee_row20_col4\" class=\"data row20 col4\" >0.80</td>\n",
              "      <td id=\"T_3d4ee_row20_col5\" class=\"data row20 col5\" >0.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "result_df, fancy_df = threshold_results(np.round(np.arange(0.0,1.01,.05), 2), y_test, yraw)\n",
        "fancy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "ut9g2lfpZLGU",
        "outputId": "65340b57-913d-4123-b672-9e0b3e00776a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    threshold  precision  recall    f1  auc  accuracy\n",
              "0        0.00       0.43    1.00  0.60  0.8      0.43\n",
              "1        0.05       0.43    1.00  0.60  0.8      0.43\n",
              "2        0.10       0.43    1.00  0.60  0.8      0.43\n",
              "3        0.15       0.45    0.98  0.62  0.8      0.48\n",
              "4        0.20       0.53    0.91  0.67  0.8      0.62\n",
              "5        0.25       0.59    0.86  0.70  0.8      0.68\n",
              "6        0.30       0.62    0.75  0.68  0.8      0.69\n",
              "7        0.35       0.65    0.73  0.69  0.8      0.71\n",
              "8        0.40       0.68    0.68  0.68  0.8      0.72\n",
              "9        0.45       0.76    0.57  0.65  0.8      0.74\n",
              "10       0.50       0.83    0.51  0.63  0.8      0.74\n",
              "11       0.55       0.90    0.48  0.63  0.8      0.75\n",
              "12       0.60       0.91    0.45  0.60  0.8      0.74\n",
              "13       0.65       0.92    0.43  0.59  0.8      0.74\n",
              "14       0.70       0.92    0.40  0.56  0.8      0.73\n",
              "15       0.75       0.91    0.36  0.52  0.8      0.71\n",
              "16       0.80       0.91    0.27  0.42  0.8      0.67\n",
              "17       0.85       0.90    0.17  0.28  0.8      0.63\n",
              "18       0.90       1.00    0.03  0.05  0.8      0.58\n",
              "19       0.95       0.00    0.00  0.00  0.8      0.57\n",
              "20       1.00       0.00    0.00  0.00  0.8      0.57"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93e2fe2c-845a-4589-b1af-1f2c34ded31b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>auc</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.90</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93e2fe2c-845a-4589-b1af-1f2c34ded31b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93e2fe2c-845a-4589-b1af-1f2c34ded31b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93e2fe2c-845a-4589-b1af-1f2c34ded31b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-38055339-345a-4598-b253-1e57d0a191c9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38055339-345a-4598-b253-1e57d0a191c9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-38055339-345a-4598-b253-1e57d0a191c9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b4fa796e-264b-49f5-81f3-665517999c15\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b4fa796e-264b-49f5-81f3-665517999c15 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3102418411497714,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.0,\n          0.85,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2906814653288274,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.9,\n          0.92,\n          0.43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33878142974911885,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          1.0,\n          0.98,\n          0.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22873877802294165,\n        \"min\": 0.0,\n        \"max\": 0.7,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.56,\n          0.42,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.137640067256873e-16,\n        \"min\": 0.8,\n        \"max\": 0.8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11244893020728079,\n        \"min\": 0.43,\n        \"max\": 0.75,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8KARoVJkScs"
      },
      "source": [
        "###My results\n",
        "\n",
        "|index|threshold|precision|recall|f1|accuracy|auc|\n",
        "|---|---|---|---|---|---|---|\n",
        "|0|0\\.0|0\\.43|1\\.0|0\\.6|0\\.43|0\\.79|\n",
        "|1|0\\.05|0\\.43|1\\.0|0\\.6|0\\.43|0\\.79|\n",
        "|2|0\\.1|0\\.44|1\\.0|0\\.61|0\\.44|0\\.79|\n",
        "|3|0\\.15|0\\.46|0\\.96|0\\.63|0\\.5|0\\.79|\n",
        "|4|0\\.2|0\\.5|0\\.93|0\\.65|0\\.57|0\\.79|\n",
        "|5|0\\.25|0\\.55|0\\.89|0\\.68|0\\.64|0\\.79|\n",
        "|6|0\\.3|0\\.61|0\\.82|0\\.7|0\\.69|0\\.79|\n",
        "|7|0\\.35|0\\.64|0\\.76|0\\.7|0\\.71|0\\.79|\n",
        "|8|0\\.4|0\\.69|0\\.63|0\\.66|0\\.71|0\\.79|\n",
        "|9|0\\.45|0\\.7|0\\.54|0\\.61|0\\.7|0\\.79|\n",
        "|10|0\\.5|0\\.77|0\\.52|0\\.62|0\\.72|0\\.79|\n",
        "|11|0\\.55|0\\.81|0\\.48|0\\.6|0\\.73|0\\.79|\n",
        "|12|0\\.6|0\\.91|0\\.45|0\\.6|0\\.74|0\\.79|\n",
        "|13|0\\.65|0\\.92|0\\.41|0\\.57|0\\.73|0\\.79|\n",
        "|14|0\\.7|0\\.91|0\\.38|0\\.53|0\\.71|0\\.79|\n",
        "|15|0\\.75|0\\.91|0\\.34|0\\.5|0\\.7|0\\.79|\n",
        "|16|0\\.8|0\\.9|0\\.23|0\\.36|0\\.65|0\\.79|\n",
        "|17|0\\.85|0\\.92|0\\.21|0\\.34|0\\.65|0\\.79|\n",
        "|18|0\\.9|0\\.83|0\\.04|0\\.08|0\\.58|0\\.79|\n",
        "|19|0\\.95|0\\.0|0\\.0|0\\.0|0\\.57|0\\.79|\n",
        "|20|1\\.0|0\\.0|0\\.0|0\\.0|0\\.57|0\\.79|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGQ5C_jX6LxG"
      },
      "source": [
        "##Step 2.7 Save your model and threshold table\n",
        "\n",
        "We will need them later. Eventually get them on GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "2OFfaZYLhDWr"
      },
      "outputs": [],
      "source": [
        "model.save('ann_model.keras')\n",
        "model2 = tf.keras.models.load_model('ann_model.keras') #load back in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "u-J-lb8J6VvS"
      },
      "outputs": [],
      "source": [
        "result_df.to_csv('ann_thresholds.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}