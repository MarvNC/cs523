{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Announcement\n",
        "\n",
        "I made a choice this quarter to value replicability over performance. It is not an easy choice! And when you get on a real project, you will have to make the same choice.\n",
        "\n",
        "This notebook (and subsequent notebooks that deal with ANNs) differs from the video in this choice. I have changed up the ANN architecture to guarantee your results match mine. This will also pay dividends in the next chapter when we get to tuning.\n",
        "\n",
        "I had to do this because the latest version of Tensorflow has introduced a new version of Dropout (discussed in more detail later) that has uncontrolled nondeterminism. In essence, setting seeds does no good: the new Dropout implementation has randomness not under your control. This is a known issue (bug?) to the Tensorflow developers but we have to deal with it until they fix it. Only choice I saw was to stop using Dropout if I wanted replicability.\n",
        "\n",
        "I have also changed the ANN compile-step, simplifying it in some ways but making it slightly more complex in others. I thought these changes better suited the relatively simple datasets we are working with. The video shows a more complex compile-step.\n",
        "\n",
        "There are other minor changes that I have made that try to modernize the code when I can. All of these changes give me different results than shown in the video. As always, your goal is to match the notebook, not the video."
      ],
      "metadata": {
        "id": "79WDBQoQndcL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDiYMkiYgRS"
      },
      "source": [
        "<center>\n",
        "<h1>Chapter 13 - Part 1</h1>\n",
        "</center>\n",
        "\n",
        "<hr>\n",
        "\n",
        "Our next machine learning model has various names, Artificial Neural Net (ANN), Deep Learning model. I'll stick with ANN.\n",
        "\n",
        "Before we get started, let's bring in the data we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZiquu_S3vZG"
      },
      "source": [
        "##Set-up\n",
        "\n",
        "First bring in your library."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "github_name = 'marvnc'\n",
        "repo_name = 'cs523'\n",
        "source_file = 'library.py'\n",
        "url = f'https://raw.githubusercontent.com/{github_name}/{repo_name}/main/{source_file}'\n",
        "!rm $source_file\n",
        "!wget $url\n",
        "%run -i $source_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYlq4xs-P7c9",
        "outputId": "059dd4a2-a8df-46e4-8cdd-13aec66ad7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'library.py': No such file or directory\n",
            "--2025-05-28 00:16:59--  https://raw.githubusercontent.com/marvnc/cs523/main/library.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48297 (47K) [text/plain]\n",
            "Saving to: ‘library.py’\n",
            "\n",
            "library.py          100%[===================>]  47.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-28 00:16:59 (50.4 MB/s) - ‘library.py’ saved [48297/48297]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cmd-m y to turn this into code cell, cmd-m m to go other way\n",
        "%%capture\n",
        "!pip install uo-puddles\n",
        "from uo_puddles.cis423 import *"
      ],
      "metadata": {
        "id": "v7XXG-E16ZxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVTLBYampYbo"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/fickas/asynch_models/main/datasets/titanic_trimmed.csv'  #trimmed version\n",
        "\n",
        "titanic_trimmed = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(titanic_trimmed)"
      ],
      "metadata": {
        "id": "CXKa0e52V4-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42dd14c-7554-42f6-9d00-71c69ca0b963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1313"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZZf7BkZpYbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0148273d-f423-49f7-f90b-14b4abed43f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Age Gender Class       Joined  Married  Fare\n",
              "0  41.0   Male    C3  Southampton      0.0   7.0\n",
              "1  21.0   Male  Crew  Southampton      0.0   0.0\n",
              "2  13.0   Male    C3  Southampton      NaN  20.0\n",
              "3  16.0   Male    C3  Southampton      0.0   NaN\n",
              "4   NaN   Male    C2    Cherbourg      0.0  24.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-852f41c9-a0bb-40f1-a414-4e7b7e015bda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Class</th>\n",
              "      <th>Joined</th>\n",
              "      <th>Married</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>C3</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Crew</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>C3</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>C3</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>C2</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-852f41c9-a0bb-40f1-a414-4e7b7e015bda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-852f41c9-a0bb-40f1-a414-4e7b7e015bda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-852f41c9-a0bb-40f1-a414-4e7b7e015bda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0ab831ab-dcc6-4612-be7e-0a1b6bd56036\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ab831ab-dcc6-4612-be7e-0a1b6bd56036')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0ab831ab-dcc6-4612-be7e-0a1b6bd56036 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "titanic_features",
              "summary": "{\n  \"name\": \"titanic_features\",\n  \"rows\": 1313,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.346944998228604,\n        \"min\": 1.0,\n        \"max\": 74.0,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          4.0,\n          41.0,\n          60.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Crew\",\n          \"C1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Joined\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Cherbourg\",\n          \"Queenstown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Married\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4751399890067327,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.58480450638799,\n        \"min\": 0.0,\n        \"max\": 512.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          19.0,\n          110.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "titanic_features = titanic_trimmed.drop(columns='Survived')\n",
        "titanic_features.head()  #print first 5 rows of the table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2_3TbldpYbw"
      },
      "source": [
        "labels = titanic_trimmed['Survived'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "x_train, x_test, y_train, y_test = titanic_setup(titanic_trimmed)"
      ],
      "metadata": {
        "id": "Bhhik6PZM9Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.std(axis=0)  #array([0.75333128, 0.47741652, 1.03590395, 0.0872873 , 0.47611519, 1.23157575])"
      ],
      "metadata": {
        "id": "UOcwOfoy16KD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d37d12-3fec-4fd8-ebc3-af9dc3a87689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.75333128, 0.47741652, 1.03590395, 0.0872873 , 0.47611519,\n",
              "       1.23157575])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[:1]  #[[ 0.78947368,  1.        ,  1.        ,  0.40075188,  0.        ,-0.26086957]]"
      ],
      "metadata": {
        "id": "dAaszQUlQ95l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa381c4-54ff-4584-f461-6cf6b9561c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.78947368,  1.        ,  1.        ,  0.40075188,  0.        ,\n",
              "        -0.26086957]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:1]"
      ],
      "metadata": {
        "id": "sdsIiE9lRDZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce62536-553e-40a8-ed42-ad106d5de6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bCGalueu_H8"
      },
      "source": [
        "#I. Neural networks were inspired by nature\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "In their 1943 paper, McCulloch and Pitts proposed a theoretical model that described the nervous system as a “net of neurons.” As a whole, the network is capable of extremely complex computations, but each individual neuron is inherently very simple. Instead of being connected to every single neuron in the entire network, each neuron is only connected to its neighbor neurons via “synapses.” By studying mappings of the human brain (see image below), we can see that neurons are often organized in consecutive “layers.”\n",
        "\n",
        "<img src='https://www.dropbox.com/s/93xj4iyvcav7b05/Screenshot%202020-04-28%2010.02.39.png?raw=1'>\n",
        "\n",
        "\n",
        "The gist of all of this is that each neuron has an input and an output and neurons are organized in layers. Let’s see how artificial neural networks in machine learning draw inspiration from this architecture we observe in nature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTGltGvbyrFk"
      },
      "source": [
        "#II. First neural nets were simple\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "<img src='https://miro.medium.com/max/1032/1*WswH2fPx0bf_JFRMm8V-HA.gif'>\n",
        "\n",
        "They had an input layer and an output layer. You can think of the input layer as accepting a vector. Each item in the vector gets placed on one of the nodes. These node/items are shown as X0, X1, X2, X3 in the figure. If we were working with our tweet data, we would have 29 input nodes, one for each value in the 29-element vector.\n",
        "\n",
        "There are a corresponding vector of weights for the input nodes. These are shown as W0, W1, W2, and W3 in above figure.\n",
        "\n",
        "There is one node in the ouput layer. It produces a result that sums the inputs times the weights. Yp shows this. BTW: in linear algebra terms, we are taking the dot product of the X vector and the weight vector.\n",
        "\n",
        "That's it! But the story does not end there. What someone noticed is that the equation for calculating Yp looks exactly like a linear regression problem. We discussed linear regression in an earlier chapter. As reminder, in a linear regression problem we are trying to find weight values that give us a linear transformation of the inputs, Xi, to the output Yp. In the case of a 2D problem, this will give us a line that will separate our data with minimal error (we hope optimistically).\n",
        "\n",
        "<img src='http://www.practicalai.io/wp-content/uploads/2017/06/admission-data-linear.png'  height=200>\n",
        "\n",
        "In the end, critics said that this neural net is just a hyped up version for linear regression which has been around forever. Unfortunately, they were right.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0du_FsyEWWaR"
      },
      "source": [
        "##Everyone was dissapointed\n",
        "\n",
        "The hope was that the perceptron could solve non-linear problems. Maybe with data that looks closer to this:\n",
        "\n",
        "<img src='https://www.dropbox.com/s/o27b5nagw1modc0/Screen%20Shot%202021-05-07%20at%208.03.21%20AM.png?raw=1' height=100>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EV5L7VoWUaj"
      },
      "source": [
        "\n",
        "To answer, some said we need to add more layers. Check this out.\n",
        "\n",
        "<img src='https://miro.medium.com/max/1028/1*cMlfLORZWxtK7fZBLx4DsQ.gif'>\n",
        "\n",
        "But have we really changed anything? We have made our linear equation more complex by splitting a single weight into smaller component weights. But it remains a linear transformation nevertheless.\n",
        "\n",
        "<img src='https://miro.medium.com/max/1016/1*g2HHjCkxeemizfLQC-BaAg.gif'>\n",
        "\n",
        "You may have noticed I slipped in a function `A` above. For the early simple nets, this was simply the identity function `A(x) = x`. More on this in a bit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7QOkczCFWt8"
      },
      "source": [
        "#III. Artificial Neural Nets (ANNs) allow us to study non-linear problems\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "\n",
        "The big jump in Neural Nets came from observing biological neurons a little more closely. We can see summation of inputs happening in the cell body. We can see values being transferred to the outputs.\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/4/44/Neuron3.png' height=150>\n",
        "\n",
        "But within the cell body, we can also see a threshold.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/eq5f44y8g3q9v6f/Screen%20Shot%202021-05-05%20at%207.38.36%20AM.png?raw=1' height=200>\n",
        "\n",
        "We will see in a minute this thresholding idea has been renamed an activation function. And it forms the basis for the first big advance in ANNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqouBELweOE6"
      },
      "source": [
        "#Picture of a simple ANN\n",
        "\n",
        "Check out the picture below.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/zdv3sjzssiewwf3/Screenshot%202020-02-18%2010.30.12.png?raw=1'>\n",
        "\n",
        "###Overview\n",
        "\n",
        "* The Input layer is simply a row from one of our tables, e.g., Titanic, ISP Customer. It's a row tilted on its side. So that 0.44 would be first number in our row, .33 the second, and so forth. It assumes numeric values and best if they have been scaled between 0 and 1.\n",
        "\n",
        "* Each input node (circle) is connected to every node (circle) in the hidden layer.\n",
        "\n",
        "* Each line between 2 nodes has a weight associated with it. Let's say there are 20 input nodes and 5 hidden nodes. We will 20*5=100 lines and hence 100 weights. These weights are not shown in the figure.\n",
        "\n",
        "* Each hidden node is connected to all output nodes. We only have one output node above.\n",
        "\n",
        "* There is nothing hidden about the hidden layer. A better term would be middle layer. But there you go.\n",
        "\n",
        "* We will have 5 lines between hidden and output and hence 5 more weights.\n",
        "\n",
        "* The whole net has 105 weights. And it is called dense because all nodes between layers are fully connected.\n",
        "\n",
        "* The output node shows a 0 or 1 output, but more accurately is a value between 0 and 1 where we use a decision rule to map it to binary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51EmSu0iYABR"
      },
      "source": [
        "##Yeah, so what?\n",
        "\n",
        "It looks like the example earlier. Just adding more layers does not give us any more power. And that is true!\n",
        "\n",
        "To see the big advance, we have to look inside a node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5JFdmXaefwC"
      },
      "source": [
        "##A node\n",
        "\n",
        "What are in the circles (i.e., nodes) on the diagram above? Each node has k input lines. The exceptions are the input nodes which have just 1 input line and no weights. They just pass through the value from the sample/row to the first hidden layer. Check out the diagram below for what the nodes look like in hidden layers and the output layer. (Notice someone needs to use a spelling corrector on their images. Fonction?)\n",
        "\n",
        "<img src='https://www.dropbox.com/scl/fi/96cj2pu8zxol05xf6pdk4/Screenshot-2025-01-22-at-4.31.41-PM.png?rlkey=wfd7x6uqkbzogdculk73qyafo&raw=1' height=300>\n",
        "\n",
        "Let's check out that `I-sub-j` summation piece in code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHf1quw_Amii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1677802-b3e2-42af-e8b4-bb8838607b02"
      },
      "source": [
        "output_list = [1,2,3,4]          #collect outputs O0, O1, ... into a list\n",
        "weight_list = [.3, .1, 0., -.1]  #collect weights into a list\n",
        "i_sub_j = np.dot(output_list, weight_list)  #result typically called z\n",
        "i_sub_j"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.09999999999999998)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tIYJ7irAjpk"
      },
      "source": [
        "\n",
        "It is a bit confusing given the diagram labels the node's input as O for output. This is meant to show the input is coming from output on layer on left. The values of the outputs are floats. Each input line has its own weight W (another float). The operation of the first part of the node is simple. If you view the outputs as in one vector and the weights in a separate vector, take the dot product of the 2 vectors. You can see that in the function computing I-sub-j, where j is the node number.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pLOcvBWYs7K"
      },
      "source": [
        "##Still don't see the big deal\n",
        "\n",
        "Taking the dot product is exactly what happens with the earlier perceptron. It gives us linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C_8ibmsYgB_"
      },
      "source": [
        "\n",
        "The more interesting part is what is called the Activation Function *f*. I showed this as the function `A` in an earlier diagram. It takes the result of the dot-product (typically called `Z`) and produces the actual output of the node. If you choose a linear activation function, e.g., `f(x) = cx`, you will end up with a network that computes a linear function no matter how many layers and nodes you have.\n",
        "\n",
        "The problems I typically want to study do not have a linear solution. Someone asked what if we used a non-linear activation function? Would that help? Uh, big yes. It was the breakthrough in ANNs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z2mze0taNaP"
      },
      "source": [
        "#VI. Activation functions\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqu7cnReaKcI"
      },
      "source": [
        "\n",
        "Here are a couple non-linear functions that have become popular. They could be the `f` in above diagram.\n",
        "\n",
        "##RELU\n",
        "\n",
        " The rectified linear activation function is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. Its implementation is trivial: `max(0,x)`.\n",
        "\n",
        "<img src='https://cdn-images-1.medium.com/freeze/max/1000/1*aIgTWE1223EGTqmi8lYBlA.png?q=20' height=200>\n",
        "\n",
        "To me it is the closest to mimic a biological neuron that waits for some threshold to be reached before activating.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M7BQ2uKiCYq"
      },
      "source": [
        "\n",
        "##Sigmoid\n",
        "\n",
        "We have seen this function when discussing Logistic Regression. Same function. It produces a sigmoid or \"S\" curve:\n",
        "\n",
        "<img src='https://www.dropbox.com/s/58hr9e4iusnmapc/Screenshot%202020-02-18%2014.02.06.png?raw=1'>\n",
        "\n",
        "<img src='https://www.dropbox.com/s/wdqdl22m2l7jruo/Screenshot%202020-02-18%2014.02.21.png?raw=1'>\n",
        "\n",
        "\n",
        "##Others\n",
        "\n",
        "\n",
        "See https://medium.com/@himanshuxd/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e for a nice table of activation functions you have to choose from. We will use RELU and SIGMOID for our examples to keep it simple. But RELU in particular is getting kind of worn around the edges at this point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVbWDytiQBd8"
      },
      "source": [
        "#V. Using an ANN is truly an exploration process\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "This is a hyperparameter-rich environment. So many choices! It is hard to think of anything that we have discussed so far that is not a choice you can make. Activation functions for sure. But also:\n",
        "\n",
        "* The number of hidden layers and the number of nodes in each layer.\n",
        "\n",
        "* How to choose the initial weights is a choice.\n",
        "\n",
        "* The feedforward mechanism itself has variations.\n",
        "\n",
        "* Computing the error has different methods you can choose.\n",
        "\n",
        "* How slight to make weight changes is a choice.\n",
        "\n",
        "* Even back propogation has variants.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7us3Q4Ncvna1"
      },
      "source": [
        "##Let's get set-up to build a model\n",
        "\n",
        "I'll use the tensorflow package from Google although pytorch is a popular alternative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpnZFnTOv2Mx"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E5_fO5F-_Iu"
      },
      "source": [
        "#VI. Build an ANN\n",
        "\n",
        "I'll build an ANN then discuss. I'll go into more detail in the next chapter. Here I am just trying to get something up and running quickly.\n",
        "\n",
        "Briefly, I am going to build up a net, one layer at a time:\n",
        "\n",
        "* The Input layer will have 6 nodes (called units here) for 6 features.\n",
        "* The first hidden layer will have 4 nodes. Just a guess.\n",
        "* The second hidden layer will have 2 nodes. Another guess.\n",
        "* The Output layer will have 1 node given this is a binary classification problem. It could have more if needed.\n",
        "* I'll discuss Dropout nodes a little later.\n",
        "\n",
        "The code looks semi-complicated because I am doing all in my power to manage randomness. I want your code to match mine and for that we need to be using the same random starting point, i.e., seeds. And we want different seeds for different layers so we don't always get the same random numbers for every layer. I am converting the layer name (unique string) to an int seed to guarantee this.\n",
        "\n",
        "Another benefit of managing randomness is that you should get the same results if you rerun the code. This is way useful when we get to tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "act_fn = 'relu'  #many others possible\n",
        "feature_n = len(x_train[0])  #or x_train.shape[1] - how many features are we using?\n",
        "feature_n"
      ],
      "metadata": {
        "id": "ZZUbnIekz23X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be86ab3-5739-475c-8788-3e2d30fc39a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Now Jump through some hoops to get replicable results\n",
        "\n",
        "Even with setting all the random seeds, you need the `enable_op_determinism` to get replicable results.\n",
        "\n",
        "And bad news: that still might be enough. Stay tuned."
      ],
      "metadata": {
        "id": "ivBo351kjx1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#update from video to add more replication control\n",
        "\n",
        "tf.keras.utils.set_random_seed(1234)  #need this for replication - sets multiple seeds\n",
        "tf.config.experimental.enable_op_determinism()  #ditto - https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism\n",
        "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "tf.config.threading.set_intra_op_parallelism_threads(1)"
      ],
      "metadata": {
        "id": "9UH8coL34r2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib  #will need this below to set seeds\n",
        "\n",
        "def string_to_seed(string):\n",
        "    # Create a hash of the string using SHA-256\n",
        "    hash_object = hashlib.sha256(string.encode())\n",
        "    # Convert first 8 bytes of hash to integer\n",
        "    hash_int = int.from_bytes(hash_object.digest()[:8], 'big')\n",
        "    return hash_int % (2**32 - 1)"
      ],
      "metadata": {
        "id": "EjB5COVHStgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Note several things that differ from video:\n",
        "# * use of regularizer\n",
        "# * weight initialization\n",
        "# * Dropout not used (commented out)\n",
        "\n",
        "ann_model = Sequential()\n",
        "\n",
        "# Input layer - a more modern way to deal with Input layer than shown in video\n",
        "ann_model.add(Input(shape=(feature_n,), name=\"input_layer\"))\n",
        "#could add Dropout here\n",
        "\n",
        "#hidden layer 1\n",
        "layer_name = \"hidden_layer_1\"\n",
        "ann_model.add(Dense(units=8,\n",
        "                   activation=act_fn,\n",
        "                   name=layer_name+'_dense',\n",
        "                   kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "                   kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense'))\n",
        "))\n",
        "#ann_model.add(Dropout(.2, name=layer_name+'_dropout', seed=string_to_seed(layer_name+'_dropout')))  #Setting seed still does not control nondeterminism in latest version\n",
        "\n",
        "#hidden layer 2\n",
        "layer_name = \"hidden_layer_2\"\n",
        "ann_model.add(Dense(units=4,\n",
        "                   activation=act_fn,\n",
        "                   name=layer_name+'_dense',\n",
        "                   kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "                   kernel_initializer=tf.keras.initializers.HeNormal(seed=string_to_seed(layer_name+'_dense'))\n",
        "))\n",
        "#ann_model.add(Dropout(.2, name=layer_name+'_dropout', seed=string_to_seed(layer_name+'_dropout')))\n",
        "\n",
        "#could add more hidden layers if you wanted.\n",
        "\n",
        "#hidden layer 3\n",
        "\n",
        "#hidden layer 4\n",
        "\n",
        "#etc\n",
        "\n",
        "#output layer for binary classification\n",
        "ann_model.add(Dense(units=1, name='output', activation='sigmoid'))  #only 1 node and using sigmoid (just like with logistic regression!)\n"
      ],
      "metadata": {
        "id": "My4-o5wwzyYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##I am making a tradeoff with the model above\n",
        "\n",
        "I was not getting replicable results. I traced the problem to the `Dropout` layer. Even with seeds set, TF's `Dropout` implementation relies on underlying hardware random number generators that TF's seeding mechanisms may not fully control. On a CPU, especially, the hardware RNG implementation can introduce non-determinism that persists despite software-level seeds. This is a known issue in TF's CPU operations.\n",
        "\n",
        "On the plus side, both Dropout and L2 regularization combat overfitting. So in place of `Dropout`, I chose *L2 regularization*, the same thing we saw when looking at logistic regression (see chapter 9). I included this in each `Dense` layer. It will **not** introduce new nondeterminism. And given the small size of our dataset in terms of features and rows, we don't need both `Dropout` and `L2`. I chose to comment out `Dropout`. In a real setting (e.g., when you are working with a large dataset on your own project), you may need to experiment and make your own choice here. And by that time, the Tensorflow folks may have figured out how to eliminate the uncontrolled nondeterminism in Dropout as a sticking point in replication.\n"
      ],
      "metadata": {
        "id": "ksaskvo5G1py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compile step\n",
        "\n",
        "At this point the ANN is configured.\n",
        "We now need to get it ready for training. That requires a compilation step. I'll discuss this step in more detail in the next chapter. But briefly, I need to specify:\n",
        "\n",
        "* a loss function. We saw the need for this back when looking at logistic regression. Same idea: compute how far off our prediction is from actual label. BinaryCrossEntropy is standard for binary classification. I'll talk about smoothing later.\n",
        "* an optimizer. Several choices here but Adam perhaps most standard.\n",
        "* metrics to track during training. A history of these values will be kept per epoch. We can then plot them later. The 'loss' metric is automatically included."
      ],
      "metadata": {
        "id": "804T4w3wPOST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=.1),  #Differs from video\n",
        "                  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),    #Differs from video\n",
        "                  metrics=['auc', 'accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "EXR6sEQBPLhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Code to test if we have replicable results\n",
        "\n",
        "Differs from the video showing my paranoia about replicability.\n",
        "You might want to remember this code for when you get to your own projects after the course."
      ],
      "metadata": {
        "id": "luHQ_EMnsl9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch = x_train[:32]\n",
        "y_batch = y_train[:32].reshape(-1, 1)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    pred1 = ann_model(x_batch, training=True)\n",
        "    loss1 = tf.keras.losses.binary_crossentropy(y_batch, pred1)\n",
        "grads1 = tape.gradient(loss1, ann_model.trainable_variables)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    pred2 = ann_model(x_batch, training=True)\n",
        "    loss2 = tf.keras.losses.binary_crossentropy(y_batch, pred2)\n",
        "grads2 = tape.gradient(loss2, ann_model.trainable_variables)\n",
        "\n",
        "print(\"Gradients match:\", all(np.array_equal(g1, g2) for g1, g2 in zip(grads1, grads2)))  #should be True if replicable"
      ],
      "metadata": {
        "id": "pcHqBe9AjgN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bcc91a-aed8-4758-f068-5cab93ba425e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients match: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aH5oWWxDi72"
      },
      "source": [
        "#VII. Train an ANN\n",
        "\n",
        "Note that training an ANN is very similar to training a Linear Regression model. We keep trying different values of weights and try to minimize a loss function. And we use differential equations and the chain-rule to change weights to do loss-minimization. And we can do L2 Regularization of the weights, just like with Linear Regression.\n",
        "\n",
        "We also have the same notion of batch and epochs. Really the only thing that has changed is the non-linear activation function. And I suppose the added layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrudgWPiv2M0"
      },
      "source": [
        "##Set-up a callback\n",
        "\n",
        "You can control runtime aspects of training with callbacks. Here is an [overview article on callbacks](https://www.analyticsvidhya.com/blog/2021/08/quick-start-with-tensorflow-callbacks). Let's use one now just to see how it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj81PHG3v2M1"
      },
      "source": [
        "###EarlyStopping callback\n",
        "\n",
        "When we are training our models, we can look at the loss in order to monitor how well the model is performing. Usually, if we see a loss that is not improving (often getting worse) over k epochs, we may conclude that our model is as good as it is going to get and any more training may lead to overfitting.\n",
        "The EarlyStopping callback allows us to monitor for this occurence. It is called after each epoch ends.\n",
        "\n",
        "<pre>\n",
        "early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                patience=15,\n",
        "                                verbose=0,\n",
        "                                restore_best_weights=True)\n",
        "</pre>\n",
        "* `monitor`: The metric you want to monitor while training. In this case, loss.\n",
        "\n",
        "* `patience`: The number of epochs to wait for the metric to improve. Else, stop the training.\n",
        "\n",
        "* `verbose` : 0: don’t print anything, 1: show a progress bar, 2: print only epoch number\n",
        "\n",
        "* `restore_best_weights`: remember the epoch with smallest loss and keep it as final fitted model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYoX6JDRv2M7"
      },
      "source": [
        "early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                patience=15,\n",
        "                                verbose=0,\n",
        "                                restore_best_weights=True)  #if early stop, will set model weights to best found so far"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Roughly 20 seconds"
      ],
      "metadata": {
        "id": "lcQbjNUdIfVZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUfp0WGwDnCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48508058-ccda-4837-8764-965c618562b3"
      },
      "source": [
        "%%time\n",
        "\n",
        "batch = 32   #typical\n",
        "epochs = 100  #guess\n",
        "training = ann_model.fit(x=x_train,\n",
        "                        y=y_train,\n",
        "                         batch_size=batch,\n",
        "                         epochs=epochs,\n",
        "                         verbose=0,\n",
        "                         shuffle=True,  #shuffles the training set after each epoch\n",
        "                         callbacks=[early_stop_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13 s, sys: 497 ms, total: 13.5 s\n",
            "Wall time: 15.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(training.history['loss'])  #100 - I did not stop early"
      ],
      "metadata": {
        "id": "m_vzLLH_nI-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f8c72a-6ae0-4405-93ce-3d8e7b00f690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIUZ1u74FcvY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "107a16c6-40f0-4c40-99d3-dea659399e64"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(training.history['auc'])\n",
        "plt.plot(training.history['loss'])\n",
        "plt.title('model performance')\n",
        "plt.ylabel('auc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['auc', 'loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###My results\n",
        "\n",
        "<img src='' height=300>"
      ],
      "metadata": {
        "id": "A8e-Ezi1r9B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max(training.history['auc']), min(training.history['loss'])  #(0.8047691583633423, 0.5954418182373047)"
      ],
      "metadata": {
        "id": "WKTreYhzY0Be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36731458-a689-46c6-875d-a91ca16ec13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8047691583633423, 0.5954418182373047)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdiWtaxvJ8Br",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b88388f-f173-4ff0-cdd0-0a7ae57342b7"
      },
      "source": [
        "training.history['auc'][-20:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8028106093406677,\n",
              " 0.8032148480415344,\n",
              " 0.8035212755203247,\n",
              " 0.8035858869552612,\n",
              " 0.8037409782409668,\n",
              " 0.803877592086792,\n",
              " 0.8038018941879272,\n",
              " 0.8037317395210266,\n",
              " 0.8037077784538269,\n",
              " 0.8039089441299438,\n",
              " 0.8038609623908997,\n",
              " 0.8037742376327515,\n",
              " 0.8038665056228638,\n",
              " 0.8043925762176514,\n",
              " 0.80446457862854,\n",
              " 0.80442214012146,\n",
              " 0.8046971559524536,\n",
              " 0.80467689037323,\n",
              " 0.8045679330825806,\n",
              " 0.8047691583633423]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###My results\n",
        "\n",
        "<pre>\n",
        "[0.8028106093406677,\n",
        " 0.8032148480415344,\n",
        " 0.8035212755203247,\n",
        " 0.8035858869552612,\n",
        " 0.8037409782409668,\n",
        " 0.803877592086792,\n",
        " 0.8038018941879272,\n",
        " 0.8037317395210266,\n",
        " 0.8037077784538269,\n",
        " 0.8039089441299438,\n",
        " 0.8038609623908997,\n",
        " 0.8037742376327515,\n",
        " 0.8038665056228638,\n",
        " 0.8043925762176514,\n",
        " 0.80446457862854,\n",
        " 0.80442214012146,\n",
        " 0.8046971559524536,\n",
        " 0.80467689037323,\n",
        " 0.8045679330825806,\n",
        " 0.8047691583633423]\n",
        " </pre>"
      ],
      "metadata": {
        "id": "WYFF26RqrjTS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NcPtOmfKFcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77676a1b-0d45-4360-e7c0-bdd359de1531"
      },
      "source": [
        "training.history['loss'][-20:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5996474027633667,\n",
              " 0.5993703603744507,\n",
              " 0.5991257429122925,\n",
              " 0.5988380312919617,\n",
              " 0.5985915064811707,\n",
              " 0.5983326435089111,\n",
              " 0.5981044769287109,\n",
              " 0.597854733467102,\n",
              " 0.5976247191429138,\n",
              " 0.5973939895629883,\n",
              " 0.597191333770752,\n",
              " 0.5969778299331665,\n",
              " 0.5967769026756287,\n",
              " 0.5965700149536133,\n",
              " 0.5963735580444336,\n",
              " 0.5961760878562927,\n",
              " 0.5959934592247009,\n",
              " 0.59579998254776,\n",
              " 0.5956194996833801,\n",
              " 0.5954418182373047]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How to inperpret all this\n",
        "\n",
        "Early stopping did not kick in. That might imply that we should add more epochs. But I am going to stop at this point given very marginal gains.\n",
        "\n",
        "That said, there is another callback that often goes with early stopping, one that also watches validation results: `ReduceLROnPlateau`. If it sees lack of improvement, it will try to adjust training parameters on the fly to improve things. Kind of cool: adapt as you go. I am not sure we will have time to get to it."
      ],
      "metadata": {
        "id": "AMzztpH0UCrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate on test set\n",
        "\n",
        "There is no `score` method. And `predict_proba` has been replaced with just `predict`. And `predict` just gives you probabilities of 1 (positive case).\n",
        "\n",
        "And remember our `ann_model` is not from the last epoch, but the one with the smallest loss as found by early stopping."
      ],
      "metadata": {
        "id": "Icr1yxgRNjZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ypos = ann_model.predict(x_test)[:,0]  #replaces predict_proba but only pos case (each value wrapped in array so need of [:,0])\n",
        "ypos[:5]  #[0.60781306, 0.7760794 , 0.8345735 , 0.24593781, 0.28484714]"
      ],
      "metadata": {
        "id": "zPQpadYUKgLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a720e16b-e9fb-4366-ab5b-4bcd1734a87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60781306, 0.7760794 , 0.8345735 , 0.24593781, 0.28484714],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df, fancy_df = threshold_results(np.round(np.arange(0.0,1.01,.05), 2), y_test, ypos)\n",
        "fancy_df"
      ],
      "metadata": {
        "id": "AzuVWryTM71o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "6bd589fa-bebf-4238-cc8c-6c923cf35b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x788281bad290>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_a9dd8 th:not(.index_name) {\n",
              "  background-color: #800000;\n",
              "  color: white;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_a9dd8_row0_col0, #T_a9dd8_row0_col1, #T_a9dd8_row0_col3, #T_a9dd8_row0_col4, #T_a9dd8_row1_col0, #T_a9dd8_row1_col1, #T_a9dd8_row1_col3, #T_a9dd8_row1_col4, #T_a9dd8_row2_col0, #T_a9dd8_row2_col1, #T_a9dd8_row2_col3, #T_a9dd8_row2_col4, #T_a9dd8_row3_col0, #T_a9dd8_row3_col1, #T_a9dd8_row3_col2, #T_a9dd8_row3_col3, #T_a9dd8_row3_col4, #T_a9dd8_row4_col0, #T_a9dd8_row4_col1, #T_a9dd8_row4_col2, #T_a9dd8_row4_col3, #T_a9dd8_row4_col4, #T_a9dd8_row5_col0, #T_a9dd8_row5_col1, #T_a9dd8_row5_col2, #T_a9dd8_row5_col3, #T_a9dd8_row5_col4, #T_a9dd8_row6_col0, #T_a9dd8_row6_col1, #T_a9dd8_row6_col2, #T_a9dd8_row6_col3, #T_a9dd8_row6_col4, #T_a9dd8_row7_col0, #T_a9dd8_row7_col1, #T_a9dd8_row7_col2, #T_a9dd8_row7_col4, #T_a9dd8_row8_col0, #T_a9dd8_row8_col1, #T_a9dd8_row8_col2, #T_a9dd8_row8_col3, #T_a9dd8_row8_col4, #T_a9dd8_row9_col0, #T_a9dd8_row9_col1, #T_a9dd8_row9_col2, #T_a9dd8_row9_col3, #T_a9dd8_row10_col0, #T_a9dd8_row10_col1, #T_a9dd8_row10_col2, #T_a9dd8_row10_col3, #T_a9dd8_row10_col4, #T_a9dd8_row11_col0, #T_a9dd8_row11_col1, #T_a9dd8_row11_col2, #T_a9dd8_row11_col3, #T_a9dd8_row11_col4, #T_a9dd8_row12_col0, #T_a9dd8_row12_col1, #T_a9dd8_row12_col2, #T_a9dd8_row12_col3, #T_a9dd8_row13_col0, #T_a9dd8_row13_col1, #T_a9dd8_row13_col2, #T_a9dd8_row13_col3, #T_a9dd8_row13_col4, #T_a9dd8_row14_col0, #T_a9dd8_row14_col1, #T_a9dd8_row14_col2, #T_a9dd8_row14_col3, #T_a9dd8_row14_col4, #T_a9dd8_row15_col0, #T_a9dd8_row15_col1, #T_a9dd8_row15_col2, #T_a9dd8_row15_col3, #T_a9dd8_row15_col4, #T_a9dd8_row16_col0, #T_a9dd8_row16_col2, #T_a9dd8_row16_col3, #T_a9dd8_row16_col4, #T_a9dd8_row17_col0, #T_a9dd8_row17_col1, #T_a9dd8_row17_col2, #T_a9dd8_row17_col3, #T_a9dd8_row17_col4, #T_a9dd8_row18_col0, #T_a9dd8_row18_col1, #T_a9dd8_row18_col2, #T_a9dd8_row18_col3, #T_a9dd8_row18_col4, #T_a9dd8_row19_col0, #T_a9dd8_row19_col1, #T_a9dd8_row19_col2, #T_a9dd8_row19_col3, #T_a9dd8_row19_col4, #T_a9dd8_row20_col1, #T_a9dd8_row20_col2, #T_a9dd8_row20_col3, #T_a9dd8_row20_col4 {\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_a9dd8_row0_col2, #T_a9dd8_row0_col5, #T_a9dd8_row1_col2, #T_a9dd8_row1_col5, #T_a9dd8_row2_col2, #T_a9dd8_row2_col5, #T_a9dd8_row3_col5, #T_a9dd8_row4_col5, #T_a9dd8_row5_col5, #T_a9dd8_row6_col5, #T_a9dd8_row7_col3, #T_a9dd8_row7_col5, #T_a9dd8_row8_col5, #T_a9dd8_row9_col4, #T_a9dd8_row9_col5, #T_a9dd8_row10_col5, #T_a9dd8_row11_col5, #T_a9dd8_row12_col4, #T_a9dd8_row12_col5, #T_a9dd8_row13_col5, #T_a9dd8_row14_col5, #T_a9dd8_row15_col5, #T_a9dd8_row16_col1, #T_a9dd8_row16_col5, #T_a9dd8_row17_col5, #T_a9dd8_row18_col5, #T_a9dd8_row19_col5, #T_a9dd8_row20_col0, #T_a9dd8_row20_col5 {\n",
              "  background-color: pink;\n",
              "  border: 1px solid black;\n",
              "  width: 65px;\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_a9dd8\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_a9dd8_level0_col0\" class=\"col_heading level0 col0\" >threshold</th>\n",
              "      <th id=\"T_a9dd8_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
              "      <th id=\"T_a9dd8_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
              "      <th id=\"T_a9dd8_level0_col3\" class=\"col_heading level0 col3\" >f1</th>\n",
              "      <th id=\"T_a9dd8_level0_col4\" class=\"col_heading level0 col4\" >accuracy</th>\n",
              "      <th id=\"T_a9dd8_level0_col5\" class=\"col_heading level0 col5\" >auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_a9dd8_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
              "      <td id=\"T_a9dd8_row0_col1\" class=\"data row0 col1\" >0.43</td>\n",
              "      <td id=\"T_a9dd8_row0_col2\" class=\"data row0 col2\" >1.00</td>\n",
              "      <td id=\"T_a9dd8_row0_col3\" class=\"data row0 col3\" >0.60</td>\n",
              "      <td id=\"T_a9dd8_row0_col4\" class=\"data row0 col4\" >0.43</td>\n",
              "      <td id=\"T_a9dd8_row0_col5\" class=\"data row0 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_a9dd8_row1_col0\" class=\"data row1 col0\" >0.05</td>\n",
              "      <td id=\"T_a9dd8_row1_col1\" class=\"data row1 col1\" >0.43</td>\n",
              "      <td id=\"T_a9dd8_row1_col2\" class=\"data row1 col2\" >1.00</td>\n",
              "      <td id=\"T_a9dd8_row1_col3\" class=\"data row1 col3\" >0.60</td>\n",
              "      <td id=\"T_a9dd8_row1_col4\" class=\"data row1 col4\" >0.43</td>\n",
              "      <td id=\"T_a9dd8_row1_col5\" class=\"data row1 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_a9dd8_row2_col0\" class=\"data row2 col0\" >0.10</td>\n",
              "      <td id=\"T_a9dd8_row2_col1\" class=\"data row2 col1\" >0.43</td>\n",
              "      <td id=\"T_a9dd8_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
              "      <td id=\"T_a9dd8_row2_col3\" class=\"data row2 col3\" >0.60</td>\n",
              "      <td id=\"T_a9dd8_row2_col4\" class=\"data row2 col4\" >0.43</td>\n",
              "      <td id=\"T_a9dd8_row2_col5\" class=\"data row2 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_a9dd8_row3_col0\" class=\"data row3 col0\" >0.15</td>\n",
              "      <td id=\"T_a9dd8_row3_col1\" class=\"data row3 col1\" >0.44</td>\n",
              "      <td id=\"T_a9dd8_row3_col2\" class=\"data row3 col2\" >0.99</td>\n",
              "      <td id=\"T_a9dd8_row3_col3\" class=\"data row3 col3\" >0.61</td>\n",
              "      <td id=\"T_a9dd8_row3_col4\" class=\"data row3 col4\" >0.44</td>\n",
              "      <td id=\"T_a9dd8_row3_col5\" class=\"data row3 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_a9dd8_row4_col0\" class=\"data row4 col0\" >0.20</td>\n",
              "      <td id=\"T_a9dd8_row4_col1\" class=\"data row4 col1\" >0.46</td>\n",
              "      <td id=\"T_a9dd8_row4_col2\" class=\"data row4 col2\" >0.97</td>\n",
              "      <td id=\"T_a9dd8_row4_col3\" class=\"data row4 col3\" >0.62</td>\n",
              "      <td id=\"T_a9dd8_row4_col4\" class=\"data row4 col4\" >0.49</td>\n",
              "      <td id=\"T_a9dd8_row4_col5\" class=\"data row4 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_a9dd8_row5_col0\" class=\"data row5 col0\" >0.25</td>\n",
              "      <td id=\"T_a9dd8_row5_col1\" class=\"data row5 col1\" >0.50</td>\n",
              "      <td id=\"T_a9dd8_row5_col2\" class=\"data row5 col2\" >0.93</td>\n",
              "      <td id=\"T_a9dd8_row5_col3\" class=\"data row5 col3\" >0.65</td>\n",
              "      <td id=\"T_a9dd8_row5_col4\" class=\"data row5 col4\" >0.57</td>\n",
              "      <td id=\"T_a9dd8_row5_col5\" class=\"data row5 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_a9dd8_row6_col0\" class=\"data row6 col0\" >0.30</td>\n",
              "      <td id=\"T_a9dd8_row6_col1\" class=\"data row6 col1\" >0.56</td>\n",
              "      <td id=\"T_a9dd8_row6_col2\" class=\"data row6 col2\" >0.82</td>\n",
              "      <td id=\"T_a9dd8_row6_col3\" class=\"data row6 col3\" >0.66</td>\n",
              "      <td id=\"T_a9dd8_row6_col4\" class=\"data row6 col4\" >0.64</td>\n",
              "      <td id=\"T_a9dd8_row6_col5\" class=\"data row6 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_a9dd8_row7_col0\" class=\"data row7 col0\" >0.35</td>\n",
              "      <td id=\"T_a9dd8_row7_col1\" class=\"data row7 col1\" >0.62</td>\n",
              "      <td id=\"T_a9dd8_row7_col2\" class=\"data row7 col2\" >0.75</td>\n",
              "      <td id=\"T_a9dd8_row7_col3\" class=\"data row7 col3\" >0.68</td>\n",
              "      <td id=\"T_a9dd8_row7_col4\" class=\"data row7 col4\" >0.69</td>\n",
              "      <td id=\"T_a9dd8_row7_col5\" class=\"data row7 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_a9dd8_row8_col0\" class=\"data row8 col0\" >0.40</td>\n",
              "      <td id=\"T_a9dd8_row8_col1\" class=\"data row8 col1\" >0.66</td>\n",
              "      <td id=\"T_a9dd8_row8_col2\" class=\"data row8 col2\" >0.65</td>\n",
              "      <td id=\"T_a9dd8_row8_col3\" class=\"data row8 col3\" >0.65</td>\n",
              "      <td id=\"T_a9dd8_row8_col4\" class=\"data row8 col4\" >0.70</td>\n",
              "      <td id=\"T_a9dd8_row8_col5\" class=\"data row8 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_a9dd8_row9_col0\" class=\"data row9 col0\" >0.45</td>\n",
              "      <td id=\"T_a9dd8_row9_col1\" class=\"data row9 col1\" >0.72</td>\n",
              "      <td id=\"T_a9dd8_row9_col2\" class=\"data row9 col2\" >0.59</td>\n",
              "      <td id=\"T_a9dd8_row9_col3\" class=\"data row9 col3\" >0.65</td>\n",
              "      <td id=\"T_a9dd8_row9_col4\" class=\"data row9 col4\" >0.72</td>\n",
              "      <td id=\"T_a9dd8_row9_col5\" class=\"data row9 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_a9dd8_row10_col0\" class=\"data row10 col0\" >0.50</td>\n",
              "      <td id=\"T_a9dd8_row10_col1\" class=\"data row10 col1\" >0.71</td>\n",
              "      <td id=\"T_a9dd8_row10_col2\" class=\"data row10 col2\" >0.57</td>\n",
              "      <td id=\"T_a9dd8_row10_col3\" class=\"data row10 col3\" >0.63</td>\n",
              "      <td id=\"T_a9dd8_row10_col4\" class=\"data row10 col4\" >0.71</td>\n",
              "      <td id=\"T_a9dd8_row10_col5\" class=\"data row10 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_a9dd8_row11_col0\" class=\"data row11 col0\" >0.55</td>\n",
              "      <td id=\"T_a9dd8_row11_col1\" class=\"data row11 col1\" >0.72</td>\n",
              "      <td id=\"T_a9dd8_row11_col2\" class=\"data row11 col2\" >0.50</td>\n",
              "      <td id=\"T_a9dd8_row11_col3\" class=\"data row11 col3\" >0.59</td>\n",
              "      <td id=\"T_a9dd8_row11_col4\" class=\"data row11 col4\" >0.70</td>\n",
              "      <td id=\"T_a9dd8_row11_col5\" class=\"data row11 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_a9dd8_row12_col0\" class=\"data row12 col0\" >0.60</td>\n",
              "      <td id=\"T_a9dd8_row12_col1\" class=\"data row12 col1\" >0.84</td>\n",
              "      <td id=\"T_a9dd8_row12_col2\" class=\"data row12 col2\" >0.43</td>\n",
              "      <td id=\"T_a9dd8_row12_col3\" class=\"data row12 col3\" >0.57</td>\n",
              "      <td id=\"T_a9dd8_row12_col4\" class=\"data row12 col4\" >0.72</td>\n",
              "      <td id=\"T_a9dd8_row12_col5\" class=\"data row12 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_a9dd8_row13_col0\" class=\"data row13 col0\" >0.65</td>\n",
              "      <td id=\"T_a9dd8_row13_col1\" class=\"data row13 col1\" >0.91</td>\n",
              "      <td id=\"T_a9dd8_row13_col2\" class=\"data row13 col2\" >0.35</td>\n",
              "      <td id=\"T_a9dd8_row13_col3\" class=\"data row13 col3\" >0.51</td>\n",
              "      <td id=\"T_a9dd8_row13_col4\" class=\"data row13 col4\" >0.70</td>\n",
              "      <td id=\"T_a9dd8_row13_col5\" class=\"data row13 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_a9dd8_row14_col0\" class=\"data row14 col0\" >0.70</td>\n",
              "      <td id=\"T_a9dd8_row14_col1\" class=\"data row14 col1\" >0.90</td>\n",
              "      <td id=\"T_a9dd8_row14_col2\" class=\"data row14 col2\" >0.32</td>\n",
              "      <td id=\"T_a9dd8_row14_col3\" class=\"data row14 col3\" >0.47</td>\n",
              "      <td id=\"T_a9dd8_row14_col4\" class=\"data row14 col4\" >0.69</td>\n",
              "      <td id=\"T_a9dd8_row14_col5\" class=\"data row14 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_a9dd8_row15_col0\" class=\"data row15 col0\" >0.75</td>\n",
              "      <td id=\"T_a9dd8_row15_col1\" class=\"data row15 col1\" >0.94</td>\n",
              "      <td id=\"T_a9dd8_row15_col2\" class=\"data row15 col2\" >0.26</td>\n",
              "      <td id=\"T_a9dd8_row15_col3\" class=\"data row15 col3\" >0.41</td>\n",
              "      <td id=\"T_a9dd8_row15_col4\" class=\"data row15 col4\" >0.67</td>\n",
              "      <td id=\"T_a9dd8_row15_col5\" class=\"data row15 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_a9dd8_row16_col0\" class=\"data row16 col0\" >0.80</td>\n",
              "      <td id=\"T_a9dd8_row16_col1\" class=\"data row16 col1\" >0.96</td>\n",
              "      <td id=\"T_a9dd8_row16_col2\" class=\"data row16 col2\" >0.19</td>\n",
              "      <td id=\"T_a9dd8_row16_col3\" class=\"data row16 col3\" >0.32</td>\n",
              "      <td id=\"T_a9dd8_row16_col4\" class=\"data row16 col4\" >0.65</td>\n",
              "      <td id=\"T_a9dd8_row16_col5\" class=\"data row16 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_a9dd8_row17_col0\" class=\"data row17 col0\" >0.85</td>\n",
              "      <td id=\"T_a9dd8_row17_col1\" class=\"data row17 col1\" >0.94</td>\n",
              "      <td id=\"T_a9dd8_row17_col2\" class=\"data row17 col2\" >0.14</td>\n",
              "      <td id=\"T_a9dd8_row17_col3\" class=\"data row17 col3\" >0.24</td>\n",
              "      <td id=\"T_a9dd8_row17_col4\" class=\"data row17 col4\" >0.62</td>\n",
              "      <td id=\"T_a9dd8_row17_col5\" class=\"data row17 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_a9dd8_row18_col0\" class=\"data row18 col0\" >0.90</td>\n",
              "      <td id=\"T_a9dd8_row18_col1\" class=\"data row18 col1\" >0.83</td>\n",
              "      <td id=\"T_a9dd8_row18_col2\" class=\"data row18 col2\" >0.04</td>\n",
              "      <td id=\"T_a9dd8_row18_col3\" class=\"data row18 col3\" >0.08</td>\n",
              "      <td id=\"T_a9dd8_row18_col4\" class=\"data row18 col4\" >0.58</td>\n",
              "      <td id=\"T_a9dd8_row18_col5\" class=\"data row18 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_a9dd8_row19_col0\" class=\"data row19 col0\" >0.95</td>\n",
              "      <td id=\"T_a9dd8_row19_col1\" class=\"data row19 col1\" >0.00</td>\n",
              "      <td id=\"T_a9dd8_row19_col2\" class=\"data row19 col2\" >0.00</td>\n",
              "      <td id=\"T_a9dd8_row19_col3\" class=\"data row19 col3\" >0.00</td>\n",
              "      <td id=\"T_a9dd8_row19_col4\" class=\"data row19 col4\" >0.57</td>\n",
              "      <td id=\"T_a9dd8_row19_col5\" class=\"data row19 col5\" >0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9dd8_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_a9dd8_row20_col0\" class=\"data row20 col0\" >1.00</td>\n",
              "      <td id=\"T_a9dd8_row20_col1\" class=\"data row20 col1\" >0.00</td>\n",
              "      <td id=\"T_a9dd8_row20_col2\" class=\"data row20 col2\" >0.00</td>\n",
              "      <td id=\"T_a9dd8_row20_col3\" class=\"data row20 col3\" >0.00</td>\n",
              "      <td id=\"T_a9dd8_row20_col4\" class=\"data row20 col4\" >0.57</td>\n",
              "      <td id=\"T_a9dd8_row20_col5\" class=\"data row20 col5\" >0.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "8gybdaCBJW9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "outputId": "3fb6bce6-7afd-4967-daf7-1ce2df6b5c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    threshold  precision  recall    f1  accuracy   auc\n",
              "0        0.00       0.43    1.00  0.60      0.43  0.78\n",
              "1        0.05       0.43    1.00  0.60      0.43  0.78\n",
              "2        0.10       0.43    1.00  0.60      0.43  0.78\n",
              "3        0.15       0.44    0.99  0.61      0.44  0.78\n",
              "4        0.20       0.46    0.97  0.62      0.49  0.78\n",
              "5        0.25       0.50    0.93  0.65      0.57  0.78\n",
              "6        0.30       0.56    0.82  0.66      0.64  0.78\n",
              "7        0.35       0.62    0.75  0.68      0.69  0.78\n",
              "8        0.40       0.66    0.65  0.65      0.70  0.78\n",
              "9        0.45       0.72    0.59  0.65      0.72  0.78\n",
              "10       0.50       0.71    0.57  0.63      0.71  0.78\n",
              "11       0.55       0.72    0.50  0.59      0.70  0.78\n",
              "12       0.60       0.84    0.43  0.57      0.72  0.78\n",
              "13       0.65       0.91    0.35  0.51      0.70  0.78\n",
              "14       0.70       0.90    0.32  0.47      0.69  0.78\n",
              "15       0.75       0.94    0.26  0.41      0.67  0.78\n",
              "16       0.80       0.96    0.19  0.32      0.65  0.78\n",
              "17       0.85       0.94    0.14  0.24      0.62  0.78\n",
              "18       0.90       0.83    0.04  0.08      0.58  0.78\n",
              "19       0.95       0.00    0.00  0.00      0.57  0.78\n",
              "20       1.00       0.00    0.00  0.00      0.57  0.78"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3b4149b-5775-4cf4-a232-9b997f7add2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3b4149b-5775-4cf4-a232-9b997f7add2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3b4149b-5775-4cf4-a232-9b997f7add2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3b4149b-5775-4cf4-a232-9b997f7add2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e0ffe51c-1dea-4ea2-bbe7-25507f721c9e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0ffe51c-1dea-4ea2-bbe7-25507f721c9e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e0ffe51c-1dea-4ea2-bbe7-25507f721c9e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0ade9bca-aaae-48a1-acc6-3953233f9b3a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0ade9bca-aaae-48a1-acc6-3953233f9b3a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3102418411497714,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.0,\n          0.85,\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27912192249812195,\n        \"min\": 0.0,\n        \"max\": 0.96,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.43,\n          0.44,\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3607894782543521,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          1.0,\n          0.99,\n          0.57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22262396225794873,\n        \"min\": 0.0,\n        \"max\": 0.68,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.6,\n          0.61,\n          0.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10566794351038675,\n        \"min\": 0.43,\n        \"max\": 0.72,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.62,\n          0.67,\n          0.43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.275280134513746e-16,\n        \"min\": 0.78,\n        \"max\": 0.78,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.78\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###My results\n",
        "\n",
        "Not great compared to last chapter. But really need to tune to get better picture. We will do that in next chapter.\n",
        "\n",
        "<img src='' height=400>"
      ],
      "metadata": {
        "id": "YLwmhIaRr2yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving and loading for future reference\n",
        "\n",
        "Code below is just to show you you can  save and load your ANN models. Next chapter will do it for real."
      ],
      "metadata": {
        "id": "nRGALg3WSgyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model.save('my_model.keras')\n",
        "\n",
        "model2 = tf.keras.models.load_model('my_model.keras') #load back in"
      ],
      "metadata": {
        "id": "0b9TFiAwLktf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypos = model2.predict(x_test)[:,0]\n",
        "ypos[:5]  #[0.60781306, 0.7760794 , 0.8345735 , 0.24593781, 0.28484714] - matches original"
      ],
      "metadata": {
        "id": "IyNskcElX3Fr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7cdab1-836b-4573-e4f4-b80690ff9c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60781306, 0.7760794 , 0.8345735 , 0.24593781, 0.28484714],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P49357M2GqES"
      },
      "source": [
        "#VIII. Dropout\n",
        "\n",
        "Even though I commented it out, it is an interesting idea. In an attempt to avoid a network overfitting, and making it more resilient, you can add a layer that  randomly \"turns off\" some percentage of nodes in the upstream layer (!) Check this out:\n",
        "\n",
        "<img src='https://miro.medium.com/max/518/0*EY8R7nS10y5kQzOx'>\n",
        "\n",
        "The consequence is that by turning off the output of a node (shown as red), we in essence come up with a new network missing that node. This is taken care of behind the scenes. The result is we train N separate networks. Kind of wild.\n",
        "\n",
        "Notice I can also turn off input nodes. So eliminating a feature in a row. Maybe this is the most obvious case of resiliency. The network cannot rely solely on one or two features of a row; they may be dropped out. It has to adapt to use all the features. I decided not to do this given our already small set of features: 6.\n",
        "\n",
        "When training is over, actual testing removes the dropout layers so you get the full model back.\n",
        "\n",
        "This has proven quite powerful. It forces the network to be resilient.\n",
        "\n",
        "###Relation to neuroscience\n",
        "\n",
        "I've seen at least one paper that claims to find the use of dropout in an ANN as similar to results from brain study: https://www.frontiersin.org/articles/10.3389/fnagi.2020.00273/full.\n",
        "\n",
        "###Problems in Tensorflow\n",
        "\n",
        "It introduces uncontrollable nondeterminism. Hence, you cannot get replicable results on repeated runs. I see no real barrier to the Tensorflow developers fixing this. They just have not yet."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenges\n",
        "\n",
        "I'm going to give you a set of challenges to build a feedforward network then try it out on a couple of examples.\n",
        "\n",
        "Here is test network to play with.\n",
        "\n",
        "<img src='https://codingvision.net/imgs/posts/c-backpropagation-tutorial-xor/1.png'>"
      ],
      "metadata": {
        "id": "OadUMIk4J4gA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Just as an aside\n",
        "\n",
        "We can train this model to learn the XOR function.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/oeud4lstd84l88d/Screenshot%202020-02-21%2013.27.25.png?raw=1' height=300>\n",
        "\n",
        "You can see that no linear solution is going to work. I think it is kind of cool that a simple net like this can learn XOR."
      ],
      "metadata": {
        "id": "nkOJglKo11hi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's add some weights\n",
        "\n",
        "Note that I am using a uniform random distribution to set weights. In the next chapter, we will see there are more sophisticated algorithms for initializing the weights."
      ],
      "metadata": {
        "id": "ZIKvYFJe3AyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=1234)  #so we will get same random numbers\n",
        "hidden1 = list(np.random.uniform(-1,1,2))  #create list of 2 random items with uniform distribution between -1 and 1\n",
        "hidden2 = list(np.random.uniform(-1,1,2))  #ditto\n",
        "output = list(np.random.uniform(-1,1,2))   #ditto"
      ],
      "metadata": {
        "id": "WGj2NO4TL_eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7ig1OTMcuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9afb97-640c-4beb-aac5-52431036f5e1"
      },
      "source": [
        "hidden1  #W11 and W21  [-0.6169610992422154, 0.24421754207966373]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(-0.6169610992422154), np.float64(0.24421754207966373)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7iy24loMcuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c569c43-2555-4fb3-f222-42af8aeed888"
      },
      "source": [
        "hidden2  #W12 and W22  [-0.12454452198577104, 0.5707171674275384]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(-0.12454452198577104), np.float64(0.5707171674275384)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output  #w13 and w23  [0.559951616237607, -0.45481478943471676]"
      ],
      "metadata": {
        "id": "oWEXQkJMMq0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad169e75-8983-4957-baaf-434c4a856595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.559951616237607), np.float64(-0.45481478943471676)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwGcKwuPNFrW"
      },
      "source": [
        "test_network = [\n",
        "    # hidden layer\n",
        "    [hidden1, # weights for hidden node 1 = [w11,w21]\n",
        "     hidden2], # weights for hidden node 2 = [w12,w22]\n",
        "   # output layer\n",
        "   [output]]  # w13 and w23 - notice not output but [output], i.e., a list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj5vnvirNFrX"
      },
      "source": [
        "###Why is `output` a list?\n",
        "\n",
        "The output layer only has one node. Why put it in a list, i.e., `[output]`?\n",
        "\n",
        "Because the output layer can have one **or more** nodes. If you are classifying 3 things, it might have 3 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwYR3ci1NFrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e2c0fb-8baf-445c-f49d-f54468904699"
      },
      "source": [
        "len(test_network)  #2 and not 3. Hidden layers are in their own nested list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIBXiQpDNFrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9300c0b3-9f26-44ee-ca8b-b2da68d0219e"
      },
      "source": [
        "test_network"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[np.float64(-0.6169610992422154), np.float64(0.24421754207966373)],\n",
              "  [np.float64(-0.12454452198577104), np.float64(0.5707171674275384)]],\n",
              " [[np.float64(0.559951616237607), np.float64(-0.45481478943471676)]]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKYNHAcTNFrX"
      },
      "source": [
        "Here it is in relation to our diagram.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/a8s43c314op5qg8/Screenshot%202020-05-13%2015.11.06.png?raw=1' height=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPMRqFnFNFrX"
      },
      "source": [
        "##Did you notice anything interesting?\n",
        "\n",
        "The entire network is now represented as a list of lists. No nodes. No lines. Just lists of weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp4w4plKnWbj"
      },
      "source": [
        "#Challenge 1\n",
        "\n",
        "Define `sigmoid` and `relu` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSiFpUSDnZnG"
      },
      "source": [
        "import math\n",
        "def sigmoid(z):\n",
        "  return 1 / (1 + math.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld_dZAc3nZnG"
      },
      "source": [
        "assert sigmoid(-0.155) == 0.46132739479349205"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJh6rnbonZnH"
      },
      "source": [
        "def relu(z):\n",
        "  return max(0,z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4_QBZLnjQr"
      },
      "source": [
        "assert relu(-.002) == 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert relu(.002)  == 0.002"
      ],
      "metadata": {
        "id": "bC0o1gcTE3kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkdgcKIJOgUx"
      },
      "source": [
        "#Challenge 2\n",
        "\n",
        "Define a function that implements a neuron.\n",
        "\n",
        "Note that I am requiring all parameters to be keyword by adding `*` in front."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34vgK1uPp5-5"
      },
      "source": [
        "def neuron_output(*, inputs, weights, af=relu):\n",
        "  assert isinstance(weights, list), f'weights should be a list but is instead a {type(weights)}'\n",
        "  assert isinstance(inputs, list), f'inputs should be a list but is instead a {type(inputs)}'\n",
        "  assert len(weights) == len(inputs), f'weights and inputs should be the same length, but are {len(weights)} and {len(inputs)}'\n",
        "  assert callable(af), f'af must be a function but is instead {type(af)}'\n",
        "  return af(np.dot(inputs, weights))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "lxlkh3RwGKiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert neuron_output(inputs=[1,1], weights=hidden1)  == 0.0"
      ],
      "metadata": {
        "id": "Kj3zw3UAFEr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert neuron_output(inputs=[1,3], weights=hidden1)  == 0.11569152699677576"
      ],
      "metadata": {
        "id": "v-vVFPP7GDid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert neuron_output(inputs=[1,1], weights=hidden2)  == 0.4461726454417674\n"
      ],
      "metadata": {
        "id": "U4Tp2Z97F60d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5m3-0BZzNNF"
      },
      "source": [
        "#Challenge 3\n",
        "\n",
        "We already have the `neuron_output` function. So use it to get the values for all the nodes in a layer and put them in a list. That list is the layer output, a value for each node in the layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SGCyT1GjNPO"
      },
      "source": [
        " def layer_output(*, inputs, layer, af=relu):\n",
        "  assert isinstance(layer, list), f'layer must be a list but is a {type(layer)}'\n",
        "  assert all([isinstance(item, list) for item in layer]), f'layer must be a list of lists'\n",
        "  assert isinstance(inputs, list), f'inputs must be a list but is a {type(inputs)}'\n",
        "  assert callable(af)\n",
        "\n",
        "  #get the value for each node in layer and put in new list - use list comprehension\n",
        "  return [neuron_output(inputs=inputs, weights=node, af=af) for node in layer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "iu38loKlHZIR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ccxl6lylGpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b8caa8c-3c77-4730-e9c0-dc9169de90ac"
      },
      "source": [
        "layer1 = test_network[0]  #first hidden layer\n",
        "layer1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[np.float64(-0.6169610992422154), np.float64(0.24421754207966373)],\n",
              " [np.float64(-0.12454452198577104), np.float64(0.5707171674275384)]]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "[[-0.6169610992422154, 0.24421754207966373],\n",
        " [-0.12454452198577104, 0.5707171674275384]]\n",
        " </pre>"
      ],
      "metadata": {
        "id": "Y4iG3VpW30Mf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ6cx5hqPq1k"
      },
      "source": [
        "So layer has list of 2 weights for hidden1 and list of 2 weights for hidden2. They are the 2 nodes in the layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SPy-pPN0LzE"
      },
      "source": [
        "Now produce the output for the first layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Gs2c-lkjg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07eb88d2-4baa-4d48-b9a8-f9cd1e2534cb"
      },
      "source": [
        "hidden1_output = layer_output(inputs=[1,3], layer=layer1)\n",
        "hidden1_output  #[0.11569152699677576, 1.5876069802968442]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(0.11569152699677576), np.float64(1.5876069802968442)]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLgQJXHq0R9h"
      },
      "source": [
        "There are 2 nodes in the hidden layer so we get an output from each. Here is a picture.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/mbnbw3s3sdp4tnj/Screen%20Shot%202021-05-05%20at%208.20.00%20AM.png?raw=1' height=200>\n",
        "\n",
        "Now here is the cool part. We take the output and make it the input to the 2nd layer, i.e., the output layer.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/6tvf33ezo2g7k6i/Screen%20Shot%202021-05-05%20at%208.23.11%20AM.png?raw=1' height=200>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsJa0JFTmFh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08eea81c-71a4-4d6e-9aec-1cac2473f7be"
      },
      "source": [
        "input_vector = hidden1_output  #tricky - taking output and making it new input!\n",
        "layer2 = test_network[1]  #next layer, i.e., output layer\n",
        "layer2  #[[0.559951616237607, -0.45481478943471676]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[np.float64(0.559951616237607), np.float64(-0.45481478943471676)]]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqWxrb9o1Mos"
      },
      "source": [
        "Now ready to produce next output, which is the actual output of the entire network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUOxIUBKlsKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39f856d-8a22-4475-bd00-28d64b57b906"
      },
      "source": [
        "output = layer_output(inputs=input_vector, layer=layer2, af=sigmoid)\n",
        "output  #[0.34134965486093866]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34134965486093866]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmvUgoIlJM8G"
      },
      "source": [
        "#Challenge 4\n",
        "\n",
        "Create the full feedforward function. Should only need calls on `layer_output` at this point.\n",
        "\n",
        "I needed one non-nested loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gweFMWkpQe0"
      },
      "source": [
        "def feed_forward(*, neural_network, input_vector):\n",
        "  # process hidden layer(s) one layer at a time\n",
        "  # slide left to right\n",
        "\n",
        "  for layer in neural_network[:-1]:  #all but last layer\n",
        "    input_vector = layer_output(inputs=input_vector, layer=layer)\n",
        "\n",
        "  #output layer is last layer and uses sigmoid\n",
        "  output_layer = neural_network[-1]\n",
        "  return layer_output(inputs=input_vector, layer=output_layer, af=sigmoid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NodWkqoV2WbN"
      },
      "source": [
        "Try it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsbSc85H2Ypa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f707b6-3c20-4b61-ef8e-9c90716ec11b"
      },
      "source": [
        "raw_prediction = feed_forward(neural_network=test_network, input_vector=[1,3])\n",
        "raw_prediction  #[0.34134965486093866] - same as in challenge 3\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34134965486093866]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMdl5goJYGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c152f633-0b6e-4daf-bb87-c5bde4fc4839"
      },
      "source": [
        "raw_prediction = feed_forward(neural_network=test_network, input_vector=[0,0])\n",
        "raw_prediction  #[0.5]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenge 5\n",
        "\n",
        "Try it out on a new network."
      ],
      "metadata": {
        "id": "bvn1VGgzPuFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=1234)\n",
        "#hidden layer 1\n",
        "hidden1_1 = list(np.random.uniform(-1,1,2))  #create list of 2 random items with uniform distribution between -1 and 1\n",
        "hidden1_2 = list(np.random.uniform(-1,1,2))  #ditto\n",
        "hidden1_3 = list(np.random.uniform(-1,1,2))  #ditto\n",
        "#hidden layer 2\n",
        "hidden2_1 = list(np.random.uniform(-1,1,3))  #create list of 3 random items with uniform distribution between -1 and 1\n",
        "hidden2_2 = list(np.random.uniform(-1,1,3))  #ditto\n",
        "#output\n",
        "output = list(np.random.uniform(-1,1,2))   #back to 2 random items"
      ],
      "metadata": {
        "id": "DM912haeP5pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgnEaLDUP5pG"
      },
      "source": [
        "test_network2 = [\n",
        "    # hidden layer 1 with 3 nodes\n",
        "    [hidden1_1, hidden1_2, hidden1_3],\n",
        "    # hidden layer 2 with 2 nodes\n",
        "    [hidden2_1, hidden2_2],\n",
        "   # output layer\n",
        "   [output]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXpBSOolRbl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcaf66c-ec93-4b4d-dff9-9abd889ff653"
      },
      "source": [
        "raw_prediction = feed_forward(neural_network=test_network2, input_vector=[1,3])\n",
        "raw_prediction  #[0.5824218686667751]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5824218686667751]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1hmUGFNJQVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e555019-fd61-4f6c-fdeb-0b5841eaa344"
      },
      "source": [
        "raw_prediction = feed_forward(neural_network=test_network2, input_vector=[0,0])\n",
        "raw_prediction  #[0.5]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    }
  ]
}