{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDiYMkiYgRS"
      },
      "source": [
        "<center>\n",
        "<h1>Chapter Nine</h1>\n",
        "</center>\n",
        "\n",
        "<hr>\n",
        "\n",
        "* Semi-deep dive into our first machine learning algorithm, Logistic Regression.\n",
        "\n",
        "* Bring in idea of cross-validation.\n",
        "\n",
        "* Start to look at \"explainable\" AI using LIME."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npa06nZLAvs-"
      },
      "source": [
        "#I. Set-up our data and splits\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZiquu_S3vZG"
      },
      "source": [
        "##Set-up\n",
        "\n",
        "First bring in your library."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "github_name = 'smith'\n",
        "repo_name = 'cis423'\n",
        "source_file = 'library.py'\n",
        "url = f'https://raw.githubusercontent.com/{github_name}/{repo_name}/main/{source_file}'\n",
        "!rm $source_file\n",
        "!wget $url\n",
        "%run -i $source_file"
      ],
      "metadata": {
        "id": "AZ6MOQmuVewi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this should be in your library but just making sure\n",
        "titanic_variance_based_split = 107\n",
        "customer_variance_based_split = 113"
      ],
      "metadata": {
        "id": "Hje9GNDR5bvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpc1PfunSdiv"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/fickas/asynch_models/refs/heads/main/datasets/titanic_trimmed.csv'\n",
        "\n",
        "titanic_trimmed = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JXOj2s9VXHC"
      },
      "outputs": [],
      "source": [
        "titanic_features = titanic_trimmed.drop(columns='Survived')\n",
        "titanic_features.head()  #print first 5 rows of the table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s50JGZMKcCUF"
      },
      "source": [
        "labels = titanic_trimmed['Survived'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJJ_RornLXy"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(titanic_features, labels, test_size=0.2, shuffle=True,\n",
        "                                                    random_state=titanic_variance_based_split, stratify=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwGhOZdaoc0m"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6rHzNYJuN4B"
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds9lMStb0f1H"
      },
      "source": [
        "##Remember want to transform train and test separately\n",
        "\n",
        "To avoid data leakage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl_YHIhK0TLW"
      },
      "source": [
        "%%capture\n",
        "X_train_transformed = titanic_transformer.fit_transform(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBZJCM0I1X0O"
      },
      "source": [
        "X_train_transformed.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlD7cdqlfK2A"
      },
      "source": [
        "%%capture\n",
        "X_test_transformed = titanic_transformer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK9BeNXPfK2B"
      },
      "source": [
        "X_test_transformed.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXXskTkZlavd"
      },
      "source": [
        "## Convert to numpy\n",
        "\n",
        "Many (but not all) of the machine learning algorithms we use will choke on a dataframe. Luckily, it is easy to convert to `numpy` matrix form, which they all accept. But note we lose the column names. Now just have a plain old matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIaoi8X3lavd"
      },
      "source": [
        "X_train_numpy = X_train_transformed.to_numpy()\n",
        "X_test_numpy = X_test_transformed.to_numpy()\n",
        "y_train_numpy = np.array(y_train)\n",
        "y_test_numpy = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Could add new step to pipeline but will not\n",
        "\n",
        "I wanted to mention this pretty cool `sklearn` transformer. It is called the `FunctionTransformer`, and it is an empty vessel. You pass it the function you want called and it is called to get the return value.\n",
        "\n",
        "Check it out below. I want to convert a dataframe (X) to a numpy matrix."
      ],
      "metadata": {
        "id": "4nA8Yc5-dXsn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iyufp74VX1i"
      },
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "#here is my custom function. Has to have this signature line.\n",
        "def numpy_converter(X, y=None):\n",
        "  assert isinstance(X, pd.core.frame.DataFrame)\n",
        "  return X.to_numpy()\n",
        "\n",
        "#Now I pass the function in\n",
        "numpy_transformer = FunctionTransformer(numpy_converter)\n",
        "\n",
        "# Plug into a pipeline\n",
        "p = Pipeline(steps=[('numpy', numpy_transformer)])\n",
        "\n",
        "p.transform(X_test_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I won't add it as a new pipeline step but I could."
      ],
      "metadata": {
        "id": "GHexouVeotja"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZThyDCWjUuc"
      },
      "source": [
        "#II. We will be using Logistic Regression\n",
        "\n",
        "We have seen it before but now let's look at it in more detail.\n",
        "\n",
        "When you google you may come across this first:\n",
        "\n",
        "<img src='https://www.dropbox.com/s/oqhwz22r6gfbvvc/Screen%20Shot%202022-02-02%20at%202.04.45%20PM.png?raw=1'>\n",
        "\n",
        "That is not the one we want! Confusing. But the one we want is this one. Note it has CV added on to end. More on that shortly.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/yln5e02q1gfiq9a/Screen%20Shot%202021-09-24%20at%2011.41.40%20AM.png?raw=1' height=200>\n",
        "\n",
        "I count 17 parameters! All have default values. I'm going to suggest we use those default parameters. I have found them to work ok in past. And frankly, it would likely take another chapter or two to delve into all of the options offered, e.g., see the [User Guide](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression). [And this article discusses the solvers](https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451). So I'm going with defaults with exceptions: (a) I'll set the `random_state` so we get repeatable results; (b) I'll set epochs to 5000 using `max_iter`.\n",
        "\n",
        "I'll also set `cv`  (`cv=5`). It stands for *Cross Validation* and I'll explain that a little later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eiLt_I8A6Bl"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "model = LogisticRegressionCV(cv=5, random_state=1, max_iter=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDatm4y3apwK"
      },
      "source": [
        "##A brief word about the `Cs` parameter\n",
        "\n",
        "I know I said I would skip most parameters, but this one is kind of key. It is part of what is called *Regularization* in regression problems. And it crops up in Neural Nets as well. The general idea is we are worried about weight outliers. If there is noise in our training set, we might end up with weights that are overfitted to that noise. Weight overfitting leads to large values for some weights.\n",
        "\n",
        "For instance, if we end up with a large weight for `Married`, then we are saying `Married` is really important and is outweighing other columns, e.g., `Gender`. This could be true: `Married` is the key parameter and should carry a high weight. But more often it is noisiness in our training set that is making `Married` so important. This can give us poor accuracy on the test set.\n",
        "\n",
        "So what the regression folks decided was to add a \"Regularization function\", `R`, to the loss. So we now have this:\n",
        "\n",
        "<img src='https://www.dropbox.com/s/vus4cm5mmv7fw5c/Screen%20Shot%202021-09-27%20at%203.38.41%20PM.png?raw=1' height=50>\n",
        "\n",
        "The general idea is that we want to penalize large weights with the new term on the right. In essence, we are now trying to minimize both the loss function (as usual) but also that new term. And that new term will be large if some set of weights are large. Hence we will penalize large weights during gradient descent.\n",
        "\n",
        "The `R` function itself can take on several forms, the most common uses the `L2` or *Euclidean norm*. You can see that is the default under the `penalty` parameter.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/9f7x156k5stb2k5/Screen%20Shot%202021-09-27%20at%203.45.21%20PM.png?raw=1' height=50>\n",
        "\n",
        "So `||wi||`, the L2 norm, says square all `wi`, sum then take the square root. The R function then squares that  (so undo the square root in essence). I hope you can see that large weights will be magnified by squaring them. So I believe we have our function that will give us large values for large weights.\n",
        "\n",
        "That leaves that `lambda` term. It allows you to choose how much value to place on `R`. Maybe you are ok with large weights because you believe your data is not noisy and if `Married` should be key, let its weight be big. Then make lambda small. The smaller the lambda, the less weight size will factor into gradient descent. In other words, weights will not be penalized for growing large.\n",
        "\n",
        "The cool thing is that the model will search for a lambda that makes the most sense for the data we have.\n",
        "Not unlike Box Cox, the model will search through a set of lambda values for you. You get to choose how many using the\n",
        "`Cs` paramater. The general idea is that the algorithm will try different values for `lambda`, building a separate model for each value. So it does a search for you, looking for best value. With `Cs`, if you give an integer `n`, the algorithm will build a list of lambda candidates of size `n` with values it chooses for you: in a logarithmic scale between `1e-4` and `1e4`. You can see the default is `10`, so it will build a list of `10` candidates. And you will get `10` different models built, looking for best value of lambda out of `10`.\n",
        "\n",
        "The final twist is the values in `Cs` are `1/lambda`, so the inverse of lambda above or *reverse regularization strength*.\n",
        "\n",
        "The big takeaway is what you are doing with this parameter. If you really trust that your  data is non-noisy, then you want to minimize `lambda` values. Or maximize `Cs` values given they are `1/lambda`. If you are worried your training data is noisy, then the opposite: increase `lambda` values (or decrease `Cs` values which is inverse).\n",
        "\n",
        "Sorry, I think it is important to know given it is baked into this algorithm and linked strongly to regression, and deep learning with neural nets for that matter.\n",
        "\n",
        "I am going to let the model do the search for us using 10 possible reverse lambda values.\n",
        "\n",
        "And BTW, I really like this set of slides for going through the topic in more detail: [slides](https://cmci.colorado.edu/classes/INFO-4604/files/slides-6_regularization.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Another name for the L2 style of regularization is Ridge Regression\n",
        "\n",
        "[Here is short article if interested](https://medium.com/@minions.k/ridge-regression-l1-regularization-method-31b6bc03cbf)."
      ],
      "metadata": {
        "id": "8wPr2v659w15"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqhoan4qmRwd"
      },
      "source": [
        "##At this point we have the algorithm\n",
        "\n",
        "We have done no training yet. That comes next. So this is the general process we will follow. First build model. Then train. Then test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_12uzwvnqsJ"
      },
      "source": [
        "## Training options\n",
        "\n",
        "We have a `model`. Let's look at the methods available.\n",
        "\n",
        "<img src='https://www.dropbox.com/s/hvfscyjzdcwe4hy/Screen%20Shot%202021-09-24%20at%2011.21.32%20AM.png?raw=1' height=200>\n",
        "\n",
        "The method of interest to us for training is `fit` which has 2 required arguments, `X` and `y` and an optional `sample_weight` argument. All of these are expected to be numpy arrays and all have the same length. We won't be weighting samples so can ignore the optional argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG_isEjeFXDp"
      },
      "source": [
        "model.fit(X_train_numpy, y_train_numpy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The `model` is an object\n",
        "\n",
        "Notice I did **not** do this:\n",
        "\n",
        "<pre>\n",
        "model = model.fit(...)\n",
        "</pre>\n",
        "\n",
        "The `model` is an object and when I call its methods, it keeps track of data internally."
      ],
      "metadata": {
        "id": "5DDR3QljSp9G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdNbel1eORbu"
      },
      "source": [
        "#III. Cross-validation\n",
        "<img src='https://www.dropbox.com/s/9fcc1crlxp19ijt/major_section.png?raw=1' width='300'>\n",
        "\n",
        "Remember when I set `cv=5`? I was asking for 5 \"folds\".\n",
        "What the heck is a \"fold\"? And why 5 of them? I think it is easier to introduce the idea of cross-validation (CV) more broadly first. The general idea is that we do not want to wait until testing to see our results. We want to test during training! We don't touch the test set. It remains the gold-standard. Instead, we break off pieces of the training set as a \"validation\" set. It is bascially a test set used during training. Here is a picture. While it is titled `Total dataset`, it should be `Total training dataset`.\n",
        "\n",
        "<img src='https://i.imgur.com/9k60cVA.png'>\n",
        "\n",
        "Why are there 5 rows, called Experiments in the diagram? We decided that we wanted to do this validation split 5 times. Where did 5 come from? Well, I set `cv=5`. Yet another hyperparameter.\n",
        "\n",
        "How it works. I first divide up the training set into 5 folds. Each fold is just a slice of the traing data. So I'll have 5 slices.\n",
        "\n",
        "Next, I build the model and train on slices 2 through 4 conjoined into a training set then test on slice 1. I remember the accuracy I got.\n",
        "\n",
        "I repeat the process 4 more times, each time with a new model and a new training set and a new slice I use for testing.\n",
        "\n",
        "At the end, I average all 5 accuracies and that is my final result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAXDweiwrkk7"
      },
      "source": [
        "##Yet another hyperparameter: fold distribution\n",
        "\n",
        "If I look under the description of the cv parameter, I see this:\n",
        "<pre>\n",
        "cv int or cross-validation generator, default=None\n",
        "\n",
        "The default cross-validation generator used is Stratified K-Folds.\n",
        "</pre>\n",
        "What is `Stratified K-Folds`?\n",
        "The way we take the folds is a choice. We could use a simple CV where I just slice things up sequentially into folds. A more sophisticated approach would try to choose folds that carry the same distribution as the entire set. This is called \"stratified\" k-fold. See below.\n",
        "\n",
        "<img src='https://i.stack.imgur.com/B9CCp.png'>\n",
        "\n",
        "This is what we get by default. Cool.\n",
        "\n",
        "And it is quite similar to what `train_test_split` gives us for the target column."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IV. Back to the `Cs` parameter and cross-validation\n",
        "\n",
        "The cool thing about `LogisticRegressionCV` is that it uses cross-validation to help to search for best `Cs` value. So for each fold, it tries each `Cs` value. Let's say we have a list of 10 alternatives for `Cs` - we let the model choose these 10 for us. Then for each fold, we will build 10 separate models, one for each `Cs` value. And record the accuracy of each of those models. If `cv=5`, then we will end up building 50 models: `5 x 10`, right? And compute the 10 accuracies for each of 10 models per fold.\n",
        "\n",
        "This table may help. The rows are folds and the columns are alternative `Cs` values.\n",
        "\n",
        "Note we are switching over to accuracy here and away from loss or error.\n"
      ],
      "metadata": {
        "id": "tpsKyW2pY0n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df = pd.DataFrame(model.scores_[1], columns=range(1,11))  #accuracies across folds and Cs values\n",
        "scores_df"
      ],
      "metadata": {
        "id": "paFewtOgdWAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The model then chooses the `Cs` value that performs the best, on average, across the 5 folds. This value can be seen below.\n"
      ],
      "metadata": {
        "id": "qn8vqRiEeGNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df.describe().T"
      ],
      "metadata": {
        "id": "p5yDx16wfTbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like 7 is the best. Differs from video."
      ],
      "metadata": {
        "id": "F1s8E63kgHdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.Cs_  #the 10 alternatives that were tried - 2.15443469e+01 is the 7th"
      ],
      "metadata": {
        "id": "Uf1caYtWgd3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first among the tied best is chosen."
      ],
      "metadata": {
        "id": "G_Iyq0COgxY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.C_  #final Cs chosen agrees with 7th as best"
      ],
      "metadata": {
        "id": "ji6fsf6bbTGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember this is the reverse-lambda value so actually `0.046415888336814703`."
      ],
      "metadata": {
        "id": "FpWtKyK-boF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1/21.5443469"
      ],
      "metadata": {
        "id": "axoQ_F_si63Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We can also see the expected accuracy\n",
        "\n",
        "Remember this was the original purpose we stated for cross-validation: give a more realistic accuracy for the training set. From table above, we can see that is `0.736190`.\n",
        "\n",
        "Is this the highest accuracy from the table? No. We have values close to `.8` on the first fold. The argument is that that is not realistic. It rests on a specific way we divided the data. What we want is the average across all folds. It is not unlike what we did with using variance to chose train-test split. We do not want a \"special\" split that gives us fabulous results. We want a split that gives us the average variance. The argument is that by using special splits we are falling  into magical thinking: we will do better than reality when we actually put our models into production with new and unseen data."
      ],
      "metadata": {
        "id": "3Hq0O-kliQVF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Zskn7hJKTP"
      },
      "source": [
        "##We will switch from loss to accuracy\n",
        "\n",
        "From now on, we will be looking at some form of accuracy. So instead of errors, what did we get correct.\n",
        "\n",
        "The score method simply counts how many times we predicted correctly out of all predictions made. Simple accuracy, which we will see later is typically too crude a measure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvBfCDimMFmw"
      },
      "source": [
        "model.score(X_train_numpy, y_train_numpy)  #simple accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVj4VTrDRVFx"
      },
      "source": [
        "We were correct `74%` of the time on the training set in predicting `Survived` value based on 6 feature values.\n",
        "\n",
        "How about now on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KZlKwAWMR6t"
      },
      "source": [
        "model.score(X_test_numpy, y_test_numpy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhn_RmDMRkA_"
      },
      "source": [
        "This is not bad. Typically, the test score is lower and often much lower than training. Having two scores roughly equal signals that we may be avoiding overfitting, a huge problem that we will discuss later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFsMGP9qIRAp"
      },
      "source": [
        "##We can see the weights `wi`\n",
        "\n",
        "In last chapter we only had one feature column so only one weight. Now we have 6 feature columns so 6 weights:\n",
        "<pre>\n",
        "yraw = w1*f1 + w2*f2 ... + w6*f6 + b\n",
        "</pre>\n",
        "We can see the final weights produced for the features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(X_train_transformed.columns.to_list(), model.coef_[0]))"
      ],
      "metadata": {
        "id": "o3WR-WA6zFC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think about this for a minute. We know that negative values for `yraw` will turn into predictions of 0 (or perished) once sent through the `sigmoid` function. Vice versa for positive values.\n",
        "\n",
        "We can see that one of the highest survival weights belongs to `Joined` at `3.1`. But `Age` has a moderate negative weight; in essence, the higher the Age the more likekly to perish.\n",
        "\n",
        "We will get back to this in a more principled way later."
      ],
      "metadata": {
        "id": "KDtf5vImzY_X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJohRCinlDaW"
      },
      "source": [
        "#V. Probability output\n",
        "\n",
        "Let's say I want to know a bit more about predictions.\n",
        "Here is what we get with the `predict` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOGveNNZlmgc"
      },
      "source": [
        "yhat = model.predict(X_test_numpy)\n",
        "yhat[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBt2cAN4l2TK"
      },
      "source": [
        "I can get accuracy on my own, right?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3DOPMyfl5pS"
      },
      "source": [
        "sum([a==b for a,b in zip(yhat, y_test_numpy)])/len(yhat)  #accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH2y3WeRmal6"
      },
      "source": [
        "##Let's take even more control\n",
        "\n",
        "I am going to ask for the output from the sigmoid function, itself. It should be a value between 0 and 1. I am going to treat that as a probability that the yhat value is 1. Check it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chs-Tvujmvj7"
      },
      "source": [
        "yprob = model.predict_proba(X_test_numpy)  #output from sigmoid as pair (perished, survived)\n",
        "yprob[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7gb7kmxnELJ"
      },
      "source": [
        "I actually get a pair of values, the 0 prob and the 1 prob. I only want the 1 prob."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6fyc1A5nZ64"
      },
      "source": [
        "yprob = yprob[:,1]  #grab the 2nd (1) column\n",
        "yprob[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWu1tflpntsw"
      },
      "source": [
        "Now I will create the yhat array. I'll use a threshold of .5: less that or equal to that is perished (0) and greater is survived (1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmkJoD-pnzUz"
      },
      "source": [
        "threshold = .5  #might want to explore different values - see below\n",
        "yhat2 = [0 if v<=threshold else 1 for v in yprob]\n",
        "all(yhat2==yhat)  #yhat is what we got from model.predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum([a==b for a,b in zip(yhat2, y_test_numpy)])/len(yhat2)  #accuary on test set"
      ],
      "metadata": {
        "id": "gBdgCmhTLiBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOljw4mCoKTY"
      },
      "source": [
        "#VI. We can explore that threshold!\n",
        "\n",
        "You may be asking why go through all this trouble when we could just use the `predict` method to get predictions of `0` and `1`. The reason is that we may want to move that threshold of `.5`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mEXEBVUotWP"
      },
      "source": [
        "##The \"value\" of correctly predicting 1\n",
        "\n",
        "We can think about this for the Titanic, although it is admittedly a bit academic. If we had a time machine and could take our logistic model back with us, we could interview passengers as they board. We could ask our model if it predicts they will survive. It seems there are 4 possibilities:\n",
        "\n",
        "1. We predict they survive and they do survive, i.e., we predict 1  and it was a 1. Good for us (and them).\n",
        "\n",
        "2. We predict they survive and they perish. Kind of bad. In fact, maybe the worst.\n",
        "\n",
        "3. We predict they perish and they do perish. Again, good for us.\n",
        "\n",
        "4. We predict they perish and they survive. So they don't board even though they could have and survived. Inconvenience.\n",
        "\n",
        "We will look at these 4 cases more later. But for now think about the 2 errors we can make above. I postulate that we may way want to make sure we avoid #2. And are much more accepting of #4. One way to do that is to increase the threshold. What if I increase from .5 to .8? We will likely make fewer #2 errors at the cost of making more #4 errors.\n",
        "\n",
        "This whole idea of moving the threshold around has a formal basis in machine learning. We will get to it later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld5U6hqJgKzk"
      },
      "source": [
        "<img src='https://www.dropbox.com/s/8x575mvbi1xumje/cash_line.png?raw=1' height=3 width=500><br>\n",
        "<img src='https://www.gannett-cdn.com/-mm-/56cbeec8287997813f287995de67747ba5e101d5/c=9-0-1280-718/local/-/media/2018/02/15/Phoenix/Phoenix/636542954131413889-image.jpg'\n",
        "height=50 align=center>\n",
        "\n",
        "\n",
        "Compute accuracy when lower threshold to `.2` using `yprob` we have already computed.\n",
        "\n",
        "I get `0.4790874524714829`.\n",
        "`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reminder that yprob holds probablity predictions for a 1 value\n",
        "print(yprob[:10])"
      ],
      "metadata": {
        "id": "vvdjZyk-EkM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute new yhat3 using threshold of .2\n",
        "threshold = .2\n",
        "yhat3 =\n"
      ],
      "metadata": {
        "id": "saXy2Bj2E4XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(yhat3[:10])  #[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   a lot more 1 values"
      ],
      "metadata": {
        "id": "k9BG0y0bcEaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum([a==b for a,b in zip(yhat3, y_test_numpy)])/len(yhat3)  #accuracy 0.4790874524714829"
      ],
      "metadata": {
        "id": "FzdOw_N2FqCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##It went down\n",
        "\n",
        "Here is a question: is every threshold other than .5 guaranteed to be worse?\n",
        "\n",
        "That would be a big no. It depends on the dataset. We will see where we get better results with thresholds different than `.5`. We will also see that \"results\" are nuanced. We may wish to look beyond simple accuracy.\n",
        "\n",
        "In following chapters we will explore the threshold value and how it impacts the goodness of our model's output."
      ],
      "metadata": {
        "id": "ihWri3rKYj6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VII. Lime Explainer\n",
        "\n",
        "We are at a spot that we can get ready to explain our predictions in our web server. We will still have to do more work in the server code, but we can capture some useful information now and save it to file.\n",
        "\n",
        "I have chosen to demo explantation with Lime. I like Lime because it works with any model, e.g., LogisticRegression, XGBoost, etc. I dislike Lime because its explanations can be hard to align with the actual predictions coming from our models.\n",
        "\n",
        "First let's get set up then discuss."
      ],
      "metadata": {
        "id": "vNOkr05uQwp3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S-Te5VSvMgV"
      },
      "source": [
        "%%capture\n",
        "!pip install lime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "from lime import lime_tabular"
      ],
      "metadata": {
        "id": "6tcUkahpax_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names  = X_train_transformed.columns.to_list()\n",
        "print(feature_names)"
      ],
      "metadata": {
        "id": "w-5gCRU1SHEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set up the explainer before using in server\n",
        "\n",
        "We only have to do this once here. Then save to file."
      ],
      "metadata": {
        "id": "Q68oGAkzHwFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = lime.lime_tabular.LimeTabularExplainer(X_train_numpy,\n",
        "                    feature_names=feature_names,\n",
        "                    training_labels=y_train_numpy,\n",
        "                    class_names=[0,1], #Outcome values\n",
        "                    verbose=True,\n",
        "                    mode='classification')"
      ],
      "metadata": {
        "id": "7W0wZRRJWP7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving\n",
        "\n",
        "I'll leave it as a challenge to save the explainer to GitHub. We can later load it into our server."
      ],
      "metadata": {
        "id": "WK2yvvm1dMF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill\n",
        "import dill as pickle\n",
        "with open('lime_explainer.pkl', 'wb') as file:\n",
        "    pickle.dump(explainer, file)\n"
      ],
      "metadata": {
        "id": "sVm4Yuw3JCSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###You should now see this in your Colab folder\n",
        "\n",
        "<img src='https://www.dropbox.com/scl/fi/7sbhuagywvjgdqe9tlriv/Screenshot-2025-01-16-at-10.26.01-AM.png?rlkey=9oce6z30a5virrvo6m02pqvy7&raw=1' height=200>\n",
        "\n",
        "Download the pkl file to your computer then upload it to your GitHub repository. We will need it later."
      ],
      "metadata": {
        "id": "EOZTAt03Xa1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Small example\n",
        "\n",
        "Lime accepts a single row/sample as input and explains how it believes each feature contributes to a prediction of 0 or 1. My problem is with these explanations, and in particular the weights it shows us. Let's check it out.\n",
        "\n",
        "I'll make up a new passenger/row/sample then ask for an explantation. Remember, this is to be used with unlabeled rows - we do not know what the real classification is."
      ],
      "metadata": {
        "id": "61Xx2kxmdUIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#['Age', 'Gender', 'Class', 'Married', 'Fare', 'Joined']\n",
        "new_row = np.array([.25, 0, 0, 0, .26, .4])\n",
        "logreg_explanation = explainer.explain_instance(new_row, model.predict_proba, num_features=len(feature_names))"
      ],
      "metadata": {
        "id": "4xhx6cDiEQs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model agnostic\n",
        "\n",
        "Notice I used `model.predict_proba` as a parameter. This can be any model we build! So it takes the model in as an argument."
      ],
      "metadata": {
        "id": "_96VB_dIeDE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Probabilities\n",
        "\n",
        "These are the probabilities that Lime comes up with for `new_row`. You should not view that as alternatives to an actual model output."
      ],
      "metadata": {
        "id": "ZAWGCL4UeaNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_explanation.predict_proba  #perishing vs surviving - predicting perished at .93"
      ],
      "metadata": {
        "id": "HQUuaXtBHgQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A graphical view\n",
        "\n",
        "The real value of Lime to me is the middle chart. It is providing the \"strength\" of each feature in swaying the prediction one way or the other. These are not probabilities and do not add up to 1.\n",
        "\n",
        "What I read from chart below is that the person being Male (0) was a big contributor to them not surviving. The person being Married (0<) has a small contribution to them surviving.\n",
        "\n",
        "My take away is that I can see how each feature is contributing in relative strength but can't use as absolute strength."
      ],
      "metadata": {
        "id": "LKExEWy9eswZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_explanation.show_in_notebook()"
      ],
      "metadata": {
        "id": "YCCG-atkWoG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Here is what we will use on the server\n",
        "\n",
        "When we build our actual web-server, I'll display this simpler list."
      ],
      "metadata": {
        "id": "EfALLQU5gBUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_explanation.as_list()"
      ],
      "metadata": {
        "id": "nYtARV_DGQg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that values on left of chart have simply been made negative in the pair of values in the list form. In essence, the only feature \"voting\" for survival (i.e., is positive) is Married.  All other features have a negative (perished) vote. This is what we will show the user of our system for an explanation of how features affect the prediction a model produces."
      ],
      "metadata": {
        "id": "TVxl4GuUgJvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##chatGPT\n",
        "\n",
        "For what it is worth, I gave chatGPT (4) a try to find how it would explain the pecularities of Lime. See this link for my chat results: https://chat.openai.com/share/579f2751-e482-48cd-8ae4-ba868c16e042."
      ],
      "metadata": {
        "id": "VyaR91FCgiea"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFLqnx8VDqM8"
      },
      "source": [
        "#Challenge 1\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Save `lime_explainer.pkl` (should be in your folder on left) on your GitHub site. You will need to read it in later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqxrBIvaHZwc"
      },
      "source": [
        "#Challenge 2\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Let's define a data set-up function to avoid tedium of the steps we normally have to do manually. I'll give you the signature line.\n",
        "\n",
        "It should return: `x_train_numpy, x_test_numpy, y_train_numpy,  y_test_numpy`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_setup(original_table, label_column_name:str, the_transformer, rs, ts=.2):\n",
        "  #your code below\n"
      ],
      "metadata": {
        "id": "z1V2VonaI_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test it\n",
        "\n",
        "Note you will need to have `titanic_transformer` defined for this test."
      ],
      "metadata": {
        "id": "MOk-808XC2x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "x_train_numpy, x_test_numpy, y_train_numpy,  y_test_numpy = dataset_setup(titanic_trimmed, 'Survived',  titanic_transformer, titanic_variance_based_split)"
      ],
      "metadata": {
        "id": "qihHZP5_B2jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_numpy[:2]"
      ],
      "metadata": {
        "id": "TQ-Eq2QhCL9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "array([[ 0.78947368,  1.        ,  1.        ,  0.40075188,  0.        ,\n",
        "        -0.26086957],\n",
        "       [-1.31578947,  0.        ,  1.        ,  0.40075188,  0.        ,\n",
        "         0.60869565]])\n",
        "</pre>"
      ],
      "metadata": {
        "id": "Itt5irT_CL9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_numpy[:10])  #[0 0 1 1 0 1 0 1 1 0]"
      ],
      "metadata": {
        "id": "21_NJPt3CuhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs2QQIB3K4FQ"
      },
      "source": [
        "#Challenge 3\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Let's define two new setup functions that are specific to Titanic and Customer datasets. They \"wrap\" the more general function from challenge 1.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def titanic_setup(titanic_table, transformer=titanic_transformer, rs=titanic_variance_based_split, ts=.2):\n"
      ],
      "metadata": {
        "id": "tHIrLLxdH_u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def customer_setup(customer_table, transformer=customer_transformer, rs=customer_variance_based_split, ts=.2):\n"
      ],
      "metadata": {
        "id": "2Pvd9lxcVI9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Go ahead and test Titanic"
      ],
      "metadata": {
        "id": "M_wqEv_TNkIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "x_train_numpy, x_test_numpy, y_train_numpy, y_test_numpy = titanic_setup(titanic_trimmed)"
      ],
      "metadata": {
        "id": "Rnwl8cJdMaXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_numpy[:2]"
      ],
      "metadata": {
        "id": "UKLSXi1QNMsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "array([[ 0.78947368,  1.        ,  1.        ,  0.40075188,  0.        ,\n",
        "        -0.26086957],\n",
        "       [-1.31578947,  0.        ,  1.        ,  0.40075188,  0.        ,\n",
        "         0.60869565]])\n",
        "</pre>"
      ],
      "metadata": {
        "id": "KjSiKp6ANUTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_numpy[:10])  #[0 0 1 1 0 1 0 1 1 0]"
      ],
      "metadata": {
        "id": "9KrkVhVFNY_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Now test Customers"
      ],
      "metadata": {
        "id": "-X6Hx3e1RbtP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mV_4aTzo1Bi"
      },
      "source": [
        "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQPM6PqZXgmAHfRYTcDZseyALRyVwkBtKEo_rtaKq_C7T0jycWxH6QVEzTzJCRA0m8Vz0k68eM9tDm-/pub?output=csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YK6LCfHsCSt"
      },
      "source": [
        "customers_df = pd.read_csv(url)\n",
        "customers_trimmed = customers_df.drop(columns='ID')  #this is a useless column which we will drop early\n",
        "customers_trimmed = customers_trimmed.drop_duplicates(ignore_index=True)  #get rid of any duplicates\n",
        "customers_trimmed.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "x_train_numpy, x_test_numpy, y_train_numpy,  y_test_numpy = customer_setup(customers_trimmed)"
      ],
      "metadata": {
        "id": "kyEdU1FONyyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_numpy[:2]"
      ],
      "metadata": {
        "id": "Y3PoDsufNyyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "array([[ 0.4       ,  1.        , -0.08922509,  0.        ,  0.25708227,\n",
        "        -0.21333333],\n",
        "       [ 0.        ,  1.        , -0.25675277,  1.        ,  0.27826316,\n",
        "        -0.6       ]])\n",
        "</pre>"
      ],
      "metadata": {
        "id": "r3SdzOThNyyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_numpy[:10])  #[0 0 0 1 1 0 1 0 0 0]"
      ],
      "metadata": {
        "id": "yVCaBMHyNyyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUcGH3rmDyR1"
      },
      "source": [
        "#Challenge 4\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Add these 3 functions to your library. We can use them in following chapters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BwFhWpcD6b8"
      },
      "source": [
        "#Challenge 5\n",
        "<img src='https://www.dropbox.com/s/3uyvp722kp5to2r/assignment.png?raw=1' width='300'>\n",
        "\n",
        "Go ahead and use `LogisticRegressionCV` to compute training and testing accuracy for the Customer dataset using a threshold of `.5`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m6sX3T1ke9K"
      },
      "source": [
        "##Step 1. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G5aMtozkiUd"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "model = LogisticRegressionCV(cv=5, random_state=1, max_iter=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbTjm1u_kiUd"
      },
      "source": [
        "#training code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBDTH-akkiUe"
      },
      "source": [
        "#How well do predicting from training?\n",
        "\n",
        "model.score(x_train_numpy, y_train_numpy)  #0.8245838668373879  _ changes slightly on different runs, unclear why"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUmVVEIXkvLH"
      },
      "source": [
        "##Step 2. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHGm8Cvlk_vV"
      },
      "source": [
        "#produce probabilities\n",
        "\n",
        "yprob = model.predict_proba(x_test_numpy)\n",
        "yprob[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ditto. Slight changes on different runs.\n",
        "<pre>\n",
        "array([[0.88908012, 0.11091988],\n",
        "       [0.84899054, 0.15100946],\n",
        "       [0.9934116 , 0.0065884 ],\n",
        "       [0.52382151, 0.47617849],\n",
        "       [0.65730416, 0.34269584],\n",
        "       [0.1207584 , 0.8792416 ],\n",
        "       [0.59773494, 0.40226506],\n",
        "       [0.12899046, 0.87100954],\n",
        "       [0.34580037, 0.65419963],\n",
        "       [0.71286386, 0.28713614]])\n",
        "</pre>"
      ],
      "metadata": {
        "id": "y-zpzsC0FVOo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYkLUGuEk_vW"
      },
      "source": [
        "#carve off 2nd column\n",
        "\n",
        "yprob = yprob[:,1]  #grab the 2nd column\n",
        "yprob[:5]  #array([0.11091988, 0.15100946, 0.0065884 , 0.47617849, 0.34269584])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn6mMNRSk_vW"
      },
      "source": [
        "Now create the yhat array using threshold of .5. Use it to compute overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLz5VPBEk_vW"
      },
      "source": [
        "#your code\n",
        "\n",
        "threshold = .5\n",
        "yhat = [0 if v<=threshold else 1 for v in yprob]\n",
        "sum([a==b for a,b in zip(yhat, y_test_numpy)])/len(yhat)  #accuracy np.float64(0.8112244897959183)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropped a bit on test set."
      ],
      "metadata": {
        "id": "Vb0tknBLfWr8"
      }
    }
  ]
}